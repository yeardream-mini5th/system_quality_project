{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1abb8cda-a8b3-4664-9f4c-63411d5d7469",
   "metadata": {},
   "source": [
    "   - 학습 데이터 (user_id : 10000 ~ 24999, 15000명)\n",
    "\n",
    "\n",
    "\t\t\t- train_err_data.csv : 시스템에 발생한 에러 로그\n",
    "\n",
    "\t\t\t- train_quality_data.csv : 시스템 퀄리티 로그\n",
    "\n",
    "\t\t\t- train_problem_data.csv : 사용자 불만 및 불만이 접수된 시간\n",
    "\n",
    "\n",
    "   - 테스트 데이터(user_id : 30000 ~ 44998, 14999명)\n",
    "\n",
    "\n",
    "\t\t\t- test_err_data.csv : 시스템에 발생한 에러 로그\n",
    "\n",
    "\t\t\t- test_quality_data.csv : 시스템 퀄리티 로그\n",
    "\n",
    "\t\t\t- sample_submission.csv : 사용자 불만 확률(0~1) (제출용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcae7e-9280-4035-a676-121321a8b662",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 사용할 Module & Data 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c297c9-42c2-4173-84d4-892afef240b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krc/miniforge3/envs/mini-project/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score ,f1_score, roc_auc_score\n",
    "# from sklearn.model_selection import KFold\n",
    "from xgboost import plot_importance ## Feature Importance 를 불러오기 위함이다\n",
    "import missingno as msno\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead4ae8c-e088-4a43-968f-4424a71ab4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/'\n",
    "train_err =pd.read_csv(PATH+'train_err.csv')\n",
    "train_problem =pd.read_csv(PATH+'train_problem.csv')\n",
    "train_quality =pd.read_csv(PATH+'train_quality.csv')\n",
    "test_err = pd.read_csv(PATH+'test_err.csv')\n",
    "test_quality = pd.read_csv(PATH+'test_quality.csv')\n",
    "\n",
    "\n",
    "# err data 는 user_id 15000 명의 대한것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988eab7-2a77-4db3-be89-dc9793e11b65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### time datetime으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22652e26-7e19-411e-a342-f522e72a1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 을 datetime 타입으로 바꾸고 바뀐지 확인\n",
    "# train_err.info()\n",
    "# test_err.info()\n",
    "# test_quality.info()\n",
    "# train_quality.info()\n",
    "# train_problem.info()\n",
    "# train_problem.time = train_problem.time.map(make_datetime)\n",
    "# train_quality.time = train_quality.time.map(make_datetime)\n",
    "# test_quality.time = test_quality.time.map(make_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07386882-d492-4aa2-a952-b102f60821ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꾼 csv 저장\n",
    "\n",
    "# train_quality.to_csv('../data/train_quality.csv')\n",
    "# train_problem.to_csv('../data/train_problem.csv')\n",
    "# test_quality.to_csv('../data/test_quality.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b08bc09-8970-4c4a-ac8b-b62f8147a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 을 datetime 타입으로 바꾸고 바뀐지 확인\n",
    "train_quality.time = pd.to_datetime(train_quality.time)\n",
    "test_err.time = pd.to_datetime(test_err.time)\n",
    "train_problem.time = pd.to_datetime( train_problem.time)\n",
    "train_err.time = pd.to_datetime(train_err.time)\n",
    "test_quality.time = pd.to_datetime(test_quality.time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cd4682-267f-47fd-99f0-c8d87cec7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(train_err_df.time)\n",
    "# pd.set_option('display.max_rows)\n",
    "# pandas display 할때 보여주는 최대 로우수와 컬럼수 지정  \n",
    "pd.options.display.max_rows = 70\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f803652-c83e-4d69-8c31-7ca4b0c1761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(x):\n",
    "    x = str(x)\n",
    "    year = int(x[:4])\n",
    "    month = int(x[4:6])\n",
    "    day = int(x[6:8])\n",
    "    hour = int(x[8:10])\n",
    "    mim = int(x[10:12])\n",
    "    sec = int(x[12:])\n",
    "    return dt.datetime(year,month,day,hour,mim,sec)\n",
    "# make_datetime(20201101025616)\n",
    "# train_err_df['time']= train_err_df.time.map(make_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b8696-16ee-47c1-8da9-13e2f431655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.MINYEAR\n",
    "dt.MAXYEAR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e559463-5f78-4fca-870e-8dbea0485c05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d54052-4cab-4143-91d7-efcbc1a93c25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "- 불만접수를 err 데이터의 있는 모든 유저 가 불만접수를 했는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cf480-62a2-4ecb-892b-ee5596ccc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_df.user_id.value_counts()\n",
    "train_problem_df.user_id.value_counts()\n",
    "train_quality_df.user_id.value_counts()\n",
    "#quality user_id 8281\n",
    "#problem user_id 5000\n",
    "#err user_id     15000\n",
    "#에러가 발생한 모든 유저가 불만 접수를 한것이 아님\n",
    "# 그러면 특정 유저"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97898e-e195-4df1-8829-34af3191751d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0609 한것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54c7ac-98e4-4159-a065-4e727f26b792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ff7b0-8d26-42fa-8bfa-2660ec8d83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df.info() \n",
    "train_problem_df.info()\n",
    "train_err_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fef2a-117c-4dab-b62a-25d3f4a12022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_columns = train_quality_df.columns[train_quality_df.isnull().sum() > 0].to_list()\n",
    "# 이거 왜 되지 ;; 여러개 의 행의 빈값 있는 것만 찾으려했는데 조건식 만들기가 힘드네 \n",
    "for column in null_columns:\n",
    "    display(train_quality_df[train_quality_df[column].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511df59-6519-4715-82e6-f82bf0187727",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_df.set_index(['user_id','errtype','model_nm']).loc[10000,'errcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264fc62-d0d2-4d0c-af33-5a8a814783cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(train_err_df.errtype.unique())\n",
    "# 29제외 1부터 42까지 41가지 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0d9ed-6271-4985-94e5-1bfda7338c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_error = train_err_df[['user_id','errtype']].values\n",
    "id_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81a794-e1c9-472d-9c14-1ebe11f29c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_err_df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4ee23-5400-4192-a950-78488719d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(train_err_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf891dc7-5d06-4eff-a0ff-6a9a261fd272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df[train_quality_df.user_id == 10693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad4043-7951-40f6-82d1-21087f06d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_df[train_err_df.user_id == 10693]\n",
    "# user_id 10693 은 model_6 만 사용했는지는 모르지만 error 이것만떳어 fwver 이 10 이라고 error 데이터에서는 보이는 그러면\n",
    "# error 가 발생하고 quality 를 2시간동안 10분마다 수집하니까  근데 보면 20일에 발생한 에러는 없어 에러를 거의 2 분 3분마다 발생시키는데 \n",
    "# 무슨 에러인지 모르겠네 어차피 이건 model_6 fwver 10에 대한 에러들이야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988d1cd-6a4e-43c2-be6a-45854163121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# quailty 에서 fwver 가 nan인게 뭐뭐가 있는지 fwver 가 빈것들은 다 퀄리티 0 과 2가 비어있는지 봐보자\n",
    "train_quality_df.loc[train_quality_df.fwver.isnull(),['quality_0','quality_2']].notnull().sum()\n",
    "# 다 비어 있다 그러면 모델이 같은지 한번 봐보자\n",
    "null_qual_0_1 = train_quality_df.loc[train_quality_df.fwver.isnull(),'user_id'].unique() # 개수는 59개\n",
    "\n",
    "def isin_null_0_1(x):\n",
    "    if x in null_qual_0_1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "null_0_1 = train_err_df[train_err_df.user_id.map(isin_null_0_1)]\n",
    "'''\n",
    "model_6    1639\n",
    "model_0    1630\n",
    "model_2     783\n",
    "model_3      43\n",
    "'''\n",
    "null_0_1[null_0_1.model_nm == \"model_6\"].fwver.value_counts()\n",
    "#array(['model_6', 'model_3', 'model_0', 'model_2'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecee83-2fe2-4b2b-9144-c40c07739138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 종류가 몇가지나 있나 한번 봐보자 \n",
    "train_err_df.model_nm.value_counts()\n",
    "# 빈것들의 에러코드는 같은지 or model 이 같은지 \n",
    "# 퀄리티 별 숫자가 같은지 로봐보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c30af-9ea7-4719-a7a1-1efba142a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df[train_quality_df.columns[3:]].iloc[:,0].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200468a3-3122-47af-ad7b-69b5b5b3cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_0_1.errtype.value_counts()\n",
    "# model_nm 과 error 타입을 연결시키는건 좀 힘들고\n",
    "# user_id 별로 무슨 error type 이나 error code에 대한 불만을 많이 썻는지\n",
    "# 그 에러들의 퀄리티 점수 분포는 어떻게 되는지 로 보면 될거같은데\n",
    "# 결측 치 채우기는 다음에 위에꺼 부터\n",
    "plt.figure(figsize =(10,5))\n",
    "train_problem_df.user_id.value_counts().hist()\n",
    "# plt.ylim(0,100)\n",
    "plt.show()\n",
    "# 대부분 의 고객이 불만은 한번 표시 했다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2814a-10c9-4eab-9171-8c5fa6de1412",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b9024-2142-4246-b0ad-d9bdaff865f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err.info()\n",
    "train_problem_df.info()\n",
    "train_quality_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60407342-69c1-4f39-b6cf-f57792005a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복값 확인해서 똑같은걸 처리해준다\n",
    "#왜냐 왜냐 음 왜일까 수학적으로 가중치를 더주게 될거라는 느낌은 무엇을 보고 느낀걸까 아마 그럴거라고 듣기만해서 일텐데 \n",
    "#오차를 구하는 방식에서 똑같은 것만 있다면 우린 loss를 줄이는 방식인가 ? lgbm 이 어떤식으로 작동했던건지 기억이 안나서 잘안돼네\n",
    "\n",
    "# train_err_df # 16553663row\n",
    "# train_err= train_err_df.drop_duplicates(keep= 'last', ignore_index = True)\n",
    "# train_problem_df.duplicated().sum()# 중복값 불만접수 데이터에는 없고\n",
    "\n",
    "# 어 그러면 2시간 동안 한번씩 찍힌다고 했는데 한번만 찍힌것도 있나\n",
    "# train_quality_df[train_quality_df.time.duplicated(keep=False)]\n",
    "# 확인 결과 없고 당연하네\n",
    "\n",
    "# dup_user = train_quality_df.loc[:,'user_id'].unique()\n",
    "# dup_user # 처음 중복되는 값을 여기도 확인하려했었는데 반복된다고했고 time 을 에러가 뜬순간으로 처리해놔서 구별이 되게했구나 아아아아아 분 초를 없앴어\n",
    "# 분초를 진짜 없앴는지 봐보자\n",
    "#train_err # 일단 에러는 시분초 다 세세히 적혀있어\n",
    "\n",
    "# train_quality_df.time.map(lambda x: x.minute).value_counts()\n",
    "# quality는\n",
    "'''\n",
    "20    151224\n",
    "0     145920\n",
    "10    140652\n",
    "30    133896\n",
    "50    131316\n",
    "40    125616\n",
    "'''\n",
    "# train_quality_df.time.map(lambda x: x.second).value_counts()\n",
    "#0    828624 초는 다없애고 분은 10분 단위에 맞춰서 한거같다 하나하나 비교해야되는데 능력부족\n",
    "\n",
    "# train_quality_df[train_quality_df['user_id'] ==dup_user[2]]\n",
    "# 이건 에러가 뜨고 quality_0~12 가 점수가 같은지 같은에러에는 같은지 봐볼라고했다 \n",
    "# 에러가 같은건 같은 시간대에 같은 user_id fwver 으로 같은 에러라고 판단했고\n",
    "# 거의 같은 양상을 보이지만 완전히 같지 않기에 항상 quality가 똑같다고 볼수없다 에러가 안떳는데도 퀄리티가 찍히는 데이터는 아닌거같은데 확인은 해봐야겠고\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 품질 이 양수와 음수를 보고 품질이 음수일때 불만 접수를 하는지 \n",
    "# 아 근데 에러가 떳을때 quality log 를 찍는단 말이야 그러면 그래도 의미 있을거같애\n",
    "# 모델이 뭔지를 안다면 안찍히는것은 기능 유추를 해볼수 있을텐데 그것도 모르겠고\n",
    "# LG 는 가전제품 생산하는 회사야 그러면 log 를 찍을수있는건가 ? 당연한건가 품질로그를?\n",
    "\n",
    "# 불만을 표한 error 가 무엇일까 그걸 찾고 그 순간에 퀄리티 점수 는 ? ㅇㅋ 이걸로 간다 \n",
    "# merge_df = pd.merge(train_problem_df,train_err , on = 'user_id')\n",
    "# merge_df[merge_df['user_id'] == 19224][:100]\n",
    "# 19224 \t2020-11-02 20:00:00\n",
    "\n",
    "# outlier 여부 확인도 해야겠네\n",
    "# quality 유저별 펌웨어별 그리고 시간별 평균 합  분산 ? ㅇ\n",
    "train_err.to_csv('train_err.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fba57c-d766-40c9-ba7e-41f2ce11dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errtype = np.sort(train_err.errtype.unique())\n",
    "train_errtype\n",
    "test_errtype = np.sort(test_err.errtype.unique())\n",
    "test_errtype == train_errtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45ed21-f4d6-4293-b0e6-9205d9e5dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id_max= 14999\n",
    "train_user_id_min= 10000\n",
    "train_user_id_num= 15000\n",
    "\n",
    "labels = np.zeros(train_user_id_num)\n",
    "# print(labels.dtype)\n",
    "labels[train_problem_df.user_id.unique()-10000] = 1\n",
    "labels = labels.astype('int16')\n",
    "\n",
    "def labeling(x):\n",
    "    return labels[x -10000]\n",
    "\n",
    "train_err['problem'] = train_err.user_id.map(labeling)\n",
    "train_err\n",
    "train_quality_df['problem']= train_quality_df.user_id.map(labeling)\n",
    "train_quality_df\n",
    "# 각 user_id 보고 거기다 라벨 붙이기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee23854-88a3-4242-8680-1c7b66124a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_number = re.compile(\"\\d\")\n",
    "# re_number.search('6a')\n",
    "# 확실히 에러 가 뜬다고 다 적은게 아니다 결측값이 있다 \n",
    "# 없어 불리 할수밖에없다 \n",
    "# 합쳐져 사용하고싶다 빈게 많을것이다 맞냐 틀리냐 \n",
    "# 빈것을 어떻게 합쳐서 쓰냐 하면\n",
    "# train Err 랑 problem 만쓴거 보다 성능이 안좋다 그러면 \n",
    "# 여러개 시간별로 다양한 데이터가 있다 그러면 어떻게 사용할것이냐 ?\n",
    "# 이데이터에 대해서 얼마나 이해하고있는지 고민해보고 \n",
    "# 왜 이문제를 선택했는지 \n",
    "# 시간 차이 테스트 랑 트레인 \n",
    "# 시간차이를 봐봐야돼 퀄리티랑 에러도 보고 그렇게 다봐봐야돼\n",
    "# 원하는 데이터 타입의 컬럼만 뽑기\n",
    "# train_quality_df.select_dtypes('object')\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (21,7))\n",
    "\n",
    "sns.heatmap(train_err.corr(), ax= axs[0], annot = True)\n",
    "sns.heatmap(train_problem_df.corr(), ax= axs[1], annot = True)\n",
    "sns.heatmap(train_quality_df.corr(), ax= axs[2], annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5535c1d-c94f-4ff6-8944-027cadb5df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df.corr().iloc[:,2:]\n",
    "# 영향을 끼친다를 어떻게 판단하는지 영향이 있다 느껴지면 그걸 어떻게 활용하는지 모르겠다\n",
    "train_quality_df.describe()\n",
    "train_quality_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0ed0d-a7f6-420c-ade9-d29af67b960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_quality_df['quality_5'].apply(lambda x :  0 if type(x) != str and math.isnan(x)   else int(x.replace(',','')) )\n",
    "# train_quality_df[train_quality_df.iloc[:,8].isna()]\n",
    "# type(train_quality_df.loc[58907].loc['quality_5'])\n",
    "train_quality_df.select_dtypes('object').iloc[:,2].apply(lambda x :  0 if (type(x) != str and math.isnan(x)) int(x.replace(',','')) elif type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f7aca-c059-48dd-8746-b4b5437dbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f548ac-a407-428a-aee2-d2599ce317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# b = math.nan\n",
    "# print(np.isnan(b))\n",
    "\n",
    "# a = np.nan\n",
    "# print(np.isnan(a))\n",
    "\n",
    "# (lambda x : 0.0 if math.isnan(x) else x)(train_quality_df.loc[58907].loc['quality_5'])\n",
    "# train_quality_df.loc[58907].loc['quality_5']\n",
    "type('str') == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcba693-bb6a-4f35-9e16-2bca4fb6a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "b = math.nan\n",
    "print(math.isnan(b))\n",
    "\n",
    "a = np.nan\n",
    "print(math.isnan(0.1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fd9aa-00b4-4801-9523-350c6fc34c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0ecac75-a0e4-40d8-8946-faaacab3be93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbe5d1-91b3-49c4-9499-01055482c869",
   "metadata": {},
   "source": [
    "### 초기 Errtype만을 이용하여 데이터를 학습시키기는 것으로 시작\n",
    "- label 은 problem set 이 불만 접수를 한 유저 이다\n",
    "  시계열 데이터인 이 데이터에서 시간 에 대한 활용은 아직 못하였기때문에 시간은 사용하지않음\n",
    "  그러므로 problem 의 존재하는 user_id 불만접수 유저 label = 1로 지정 나머지는 0 \n",
    "\n",
    "- user_id 별로 errtype 별 발생 횟수만을 학습 데이터로 전처리하여 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5623141c-4348-4de3-afac-6d300caff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_err_data 의 유저 아이디는 15000명이고 10000~24999이기 때문에\n",
    "# 더 연산이 빠르게 ndarray를 새로만들어서 0을 user_id 10000으로 해서 레이블을 붙인다\n",
    "def make_label(df):\n",
    "    problem = np.zeros(15000)\n",
    "    problem[df.user_id -10000] = 1\n",
    "    return problem\n",
    "# np.zeros(15000)\n",
    "# train_problem[train_problem.user_id==10001]\n",
    "\n",
    "problem = make_label(train_problem)\n",
    "train_y = problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3101c747-0ec7-4fc3-9735-f667762653d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 16532648/16532648 [00:14<00:00, 1112356.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14999, 42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(np.sort(train_err.errtype.unique())) # 이전 EDA에서도 봤지만 1~42 중 29가 빠진 41개의 errtype이 있다\n",
    "\n",
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999\n",
    "train_user_id_max = 24999\n",
    "train_user_id_min = 10000\n",
    "train_user_number = 15000\n",
    "def data_pre(err, min_num , max_num , user_number):\n",
    "    # user_errtype = np.zeros((15000,41))\n",
    "    user_errtype2= np.zeros((user_number,42))\n",
    "    \n",
    "\n",
    "    for user_id , type_num in tqdm(err[['user_id','errtype']].values):  # colmuns 명들을 변수로 바꿔놓을까 했는데 여기서만 쓸거같네 이함수는\n",
    "        # if type_num > 28:\n",
    "        #     user_errtype[user_id-10000,type_num-2] += 1\n",
    "        # else:\n",
    "        # user_errtype[user_id-10000,type_num-1] += 1\n",
    "        user_errtype2[user_id-min_num,type_num-1] += 1\n",
    "    return user_errtype2\n",
    "\n",
    "# test_X = data_pre(test_err, test_user_id_min, test_user_id_max, test_user_number)\n",
    "# test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01beab17-e5be-400b-95c1-2fa49a6a76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_X)\n",
    "test_df.to_csv(PATH + 'test_X.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec2667e-faf5-4fef-96bd-6140ab478327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16532648 entries, 0 to 16532647\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   Unnamed: 0  int64         \n",
      " 1   user_id     int64         \n",
      " 2   model_nm    object        \n",
      " 3   fwver       object        \n",
      " 4   errtype     int64         \n",
      " 5   errcode     object        \n",
      " 6   time        datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(3), object(3)\n",
      "memory usage: 882.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-11-01 03:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:02:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532643</th>\n",
       "      <td>16532643</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-30 21:00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532644</th>\n",
       "      <td>16532644</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30 21:18:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532645</th>\n",
       "      <td>16532645</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30 21:18:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532646</th>\n",
       "      <td>16532646</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30 21:22:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532647</th>\n",
       "      <td>16532647</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-30 21:23:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16532648 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  user_id model_nm       fwver  errtype errcode  \\\n",
       "0                  0    30000  model_1  04.16.3553       31       1   \n",
       "1                  1    30000  model_1  04.16.3553       33       2   \n",
       "2                  2    30000  model_1  04.16.3553       15       1   \n",
       "3                  3    30000  model_1  04.16.3553       22       1   \n",
       "4                  4    30000  model_1  04.16.3553       11       1   \n",
       "...              ...      ...      ...         ...      ...     ...   \n",
       "16532643    16532643    44998  model_1  04.16.3553       40       0   \n",
       "16532644    16532644    44998  model_1  04.16.3553       31       1   \n",
       "16532645    16532645    44998  model_1  04.16.3553       15       1   \n",
       "16532646    16532646    44998  model_1  04.16.3553       16       1   \n",
       "16532647    16532647    44998  model_1  04.16.3553       31       0   \n",
       "\n",
       "                        time  \n",
       "0        2020-11-01 03:02:27  \n",
       "1        2020-11-01 03:02:27  \n",
       "2        2020-11-01 03:02:28  \n",
       "3        2020-11-01 03:02:56  \n",
       "4        2020-11-01 03:03:00  \n",
       "...                      ...  \n",
       "16532643 2020-11-30 21:00:50  \n",
       "16532644 2020-11-30 21:18:31  \n",
       "16532645 2020-11-30 21:18:32  \n",
       "16532646 2020-11-30 21:22:59  \n",
       "16532647 2020-11-30 21:23:16  \n",
       "\n",
       "[16532648 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(test_err.info())\n",
    "# test_err.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8d18a7-89b9-4f23-b272-7862f4aaa6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2      3     4    5    6    7    8    9  ...    32    33  \\\n",
       "0      0.0  0.0  8.0  104.0   0.0  1.0  1.0  0.0  0.0  7.0  ...   0.0   0.0   \n",
       "1      0.0  0.0  0.0    0.0  48.0  1.0  1.0  0.0  0.0  0.0  ...  10.0  18.0   \n",
       "2      0.0  0.0  2.0  131.0   1.0  2.0  1.0  0.0  0.0  1.0  ...   0.0   0.0   \n",
       "3      0.0  0.0  0.0    0.0   2.0  1.0  1.0  0.0  0.0  0.0  ...   8.0   0.0   \n",
       "4      0.0  0.0  0.0    1.0   0.0  3.0  4.0  0.0  0.0  0.0  ...  16.0   0.0   \n",
       "...    ...  ...  ...    ...   ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "14995  0.0  0.0  0.0    0.0   2.0  5.0  5.0  0.0  0.0  0.0  ...   5.0   0.0   \n",
       "14996  0.0  0.0  0.0    0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "14997  0.0  0.0  0.0    1.0   8.0  1.0  1.0  0.0  0.0  0.0  ...  16.0  12.0   \n",
       "14998  0.0  0.0  0.0    0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  15.0   2.0   \n",
       "14999  0.0  0.0  4.0  188.0   7.0  5.0  4.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "        34   35   36   37   38     39    40   41  \n",
       "0      0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "1      0.0  1.0  1.0  0.0  0.0  113.0  56.0  1.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "3      0.0  1.0  1.0  2.0  0.0   17.0   1.0  0.0  \n",
       "4      0.0  1.0  1.0  0.0  0.0    4.0   0.0  2.0  \n",
       "...    ...  ...  ...  ...  ...    ...   ...  ...  \n",
       "14995  0.0  0.0  0.0  0.0  0.0    9.0   7.0  4.0  \n",
       "14996  0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "14997  0.0  1.0  1.0  0.0  0.0   58.0   7.0  5.0  \n",
       "14998  0.0  1.0  1.0  0.0  0.0    6.0   0.0  0.0  \n",
       "14999  0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "\n",
       "[15000 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      0.0\n",
       "1      1.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      1.0\n",
       "...    ...\n",
       "14995  0.0\n",
       "14996  0.0\n",
       "14997  1.0\n",
       "14998  1.0\n",
       "14999  0.0\n",
       "\n",
       "[15000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_X = pd.DataFrame(data_pre(train_err,train_user_id_min,train_user_id_max,train_user_number))\n",
    "# train_data2 = pd.DataFrame(user_errtype)\n",
    "# train_label = pd.Series(train_y)\n",
    "\n",
    "# train_X.to_csv(PATH+'train_X.csv',index = False) # index 까지 저장하면 불러올때 unnamed 로 컬럼이 하나 더생겨버린다\n",
    "# train_data2.to_csv('../data/train_data2.csv', index= False)\n",
    "# train_label.to_csv('../data/label.csv', index= False)\n",
    "PATH = '../data/'\n",
    "train_X = pd.read_csv(PATH+'train_X.csv')\n",
    "train_y = pd.read_csv(PATH+'label.csv')\n",
    "test_X = pd.read_csv(PATH +'test_X.csv')\n",
    "display(train_X)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9c5d3-0b08-4d91-b566-766ccbf8109b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73447bfb-a5ef-4995-b1ed-aa68b30061d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LightBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa38cd-fd52-420a-936f-c1462c310b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels = y_true.get_label()\n",
    "    p ,r , _ = precision_recall_curve(labels, probas_pred)\n",
    "    score = auc(r,p)\n",
    "    return \"pr_auc\", score, True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd4d3f-5e73-43f9-8546-3192dbf43854",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "auc_scores = []\n",
    "threshold = 0.5\n",
    "# parameter 설정\n",
    "params= {'boosting_type' : 'gbdt',\n",
    "         'objective' : 'binary',\n",
    "         'metric' : 'auc',\n",
    "         'seed':1015\n",
    "        }\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "# 5 fold cross validation\n",
    "for train_idx, val_idx in k_fold.split(train_x):\n",
    "    \n",
    "    #split train, validation set\n",
    "    X = train_x[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "    \n",
    "    d_train = lgb.Dataset(X,y)\n",
    "    d_val = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    # run training\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set = d_train , \n",
    "        num_boost_round = 1000, # num_trees 와 똑같이 보면된다\n",
    "        valid_sets = d_val, \n",
    "        feval = f_pr_auc,  #customized evaluation function\n",
    "        # verbose_eval = 20 ,\n",
    "        early_stopping_rounds = 3\n",
    "    )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    \n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold,1,0)\n",
    "    \n",
    "    # cal scores\n",
    "    \n",
    "    recall = recall_score( valid_y, valid_pred)\n",
    "    precision = precision_score(valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(valid_y, valid_prob)\n",
    "    \n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "    \n",
    "    print('='*38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e6ee5-3aeb-4573-8ec8-f69458a267ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def funcSample():\n",
    "#     print('sample')\n",
    "# callable(funcSample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31e22a-8747-4300-bd8a-50a0a7d59948",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07d058-6337-4a77-8aed-c14aa330558f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 훈련 모델 ver 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ce93f-1dae-4d91-ac75-0bfe7a6603e4",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 20%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "           - 이건 학습할 데이터를 train 으로 명시해주고 평가할 데이터를 eval를 명시해줘서 넣는것\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6cf73b-88f6-477a-a89c-457eda4e17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7b53f3e-7da8-426b-b254-14824fa660dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 42), (3000, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2 , random_state= 42)\n",
    "\n",
    "# xgb.DMatrix(train_x,train_y)\n",
    "X_train.shape , y_train.shape\n",
    "X_val.shape , y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "259071a0-800a-4057-b9b1-9dbb1566a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train,y_train)\n",
    "d_val = xgb.DMatrix(X_val, y_val) \n",
    "d_test = xgb.DMatrix(test_X)\n",
    "# Dmatrix는 XGBoost python wrapper(이게 정확히 무슨뜻인지는모름) 데이터셋을 만드는 메소드\n",
    "# xgb_model = xgb.XGBClassifier(silent=0)\n",
    "# print(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140b9fd7-53fc-41d7-ac1d-ad189a4a4e87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68973\teval-logloss:0.69068\n",
      "[1]\ttrain-logloss:0.68637\teval-logloss:0.68828\n",
      "[2]\ttrain-logloss:0.68308\teval-logloss:0.68594\n",
      "[3]\ttrain-logloss:0.67985\teval-logloss:0.68365\n",
      "[4]\ttrain-logloss:0.67669\teval-logloss:0.68143\n",
      "[5]\ttrain-logloss:0.67359\teval-logloss:0.67925\n",
      "[6]\ttrain-logloss:0.67054\teval-logloss:0.67714\n",
      "[7]\ttrain-logloss:0.66755\teval-logloss:0.67505\n",
      "[8]\ttrain-logloss:0.66463\teval-logloss:0.67301\n",
      "[9]\ttrain-logloss:0.66175\teval-logloss:0.67102\n",
      "[10]\ttrain-logloss:0.65893\teval-logloss:0.66908\n",
      "[11]\ttrain-logloss:0.65613\teval-logloss:0.66718\n",
      "[12]\ttrain-logloss:0.65338\teval-logloss:0.66533\n",
      "[13]\ttrain-logloss:0.65068\teval-logloss:0.66352\n",
      "[14]\ttrain-logloss:0.64804\teval-logloss:0.66177\n",
      "[15]\ttrain-logloss:0.64545\teval-logloss:0.66004\n",
      "[16]\ttrain-logloss:0.64290\teval-logloss:0.65837\n",
      "[17]\ttrain-logloss:0.64040\teval-logloss:0.65672\n",
      "[18]\ttrain-logloss:0.63795\teval-logloss:0.65510\n",
      "[19]\ttrain-logloss:0.63553\teval-logloss:0.65353\n",
      "[20]\ttrain-logloss:0.63317\teval-logloss:0.65198\n",
      "[21]\ttrain-logloss:0.63085\teval-logloss:0.65045\n",
      "[22]\ttrain-logloss:0.62857\teval-logloss:0.64900\n",
      "[23]\ttrain-logloss:0.62632\teval-logloss:0.64754\n",
      "[24]\ttrain-logloss:0.62412\teval-logloss:0.64612\n",
      "[25]\ttrain-logloss:0.62196\teval-logloss:0.64474\n",
      "[26]\ttrain-logloss:0.61983\teval-logloss:0.64339\n",
      "[27]\ttrain-logloss:0.61774\teval-logloss:0.64204\n",
      "[28]\ttrain-logloss:0.61568\teval-logloss:0.64075\n",
      "[29]\ttrain-logloss:0.61367\teval-logloss:0.63944\n",
      "[30]\ttrain-logloss:0.61168\teval-logloss:0.63820\n",
      "[31]\ttrain-logloss:0.60974\teval-logloss:0.63697\n",
      "[32]\ttrain-logloss:0.60781\teval-logloss:0.63578\n",
      "[33]\ttrain-logloss:0.60592\teval-logloss:0.63461\n",
      "[34]\ttrain-logloss:0.60407\teval-logloss:0.63350\n",
      "[35]\ttrain-logloss:0.60225\teval-logloss:0.63237\n",
      "[36]\ttrain-logloss:0.60045\teval-logloss:0.63127\n",
      "[37]\ttrain-logloss:0.59869\teval-logloss:0.63020\n",
      "[38]\ttrain-logloss:0.59694\teval-logloss:0.62915\n",
      "[39]\ttrain-logloss:0.59523\teval-logloss:0.62811\n",
      "[40]\ttrain-logloss:0.59356\teval-logloss:0.62710\n",
      "[41]\ttrain-logloss:0.59190\teval-logloss:0.62613\n",
      "[42]\ttrain-logloss:0.59028\teval-logloss:0.62516\n",
      "[43]\ttrain-logloss:0.58868\teval-logloss:0.62424\n",
      "[44]\ttrain-logloss:0.58711\teval-logloss:0.62333\n",
      "[45]\ttrain-logloss:0.58557\teval-logloss:0.62247\n",
      "[46]\ttrain-logloss:0.58405\teval-logloss:0.62161\n",
      "[47]\ttrain-logloss:0.58256\teval-logloss:0.62073\n",
      "[48]\ttrain-logloss:0.58106\teval-logloss:0.61989\n",
      "[49]\ttrain-logloss:0.57962\teval-logloss:0.61909\n",
      "[50]\ttrain-logloss:0.57819\teval-logloss:0.61831\n",
      "[51]\ttrain-logloss:0.57679\teval-logloss:0.61750\n",
      "[52]\ttrain-logloss:0.57541\teval-logloss:0.61675\n",
      "[53]\ttrain-logloss:0.57405\teval-logloss:0.61599\n",
      "[54]\ttrain-logloss:0.57271\teval-logloss:0.61527\n",
      "[55]\ttrain-logloss:0.57140\teval-logloss:0.61458\n",
      "[56]\ttrain-logloss:0.57011\teval-logloss:0.61389\n",
      "[57]\ttrain-logloss:0.56883\teval-logloss:0.61324\n",
      "[58]\ttrain-logloss:0.56758\teval-logloss:0.61257\n",
      "[59]\ttrain-logloss:0.56634\teval-logloss:0.61190\n",
      "[60]\ttrain-logloss:0.56512\teval-logloss:0.61123\n",
      "[61]\ttrain-logloss:0.56392\teval-logloss:0.61064\n",
      "[62]\ttrain-logloss:0.56275\teval-logloss:0.61004\n",
      "[63]\ttrain-logloss:0.56159\teval-logloss:0.60944\n",
      "[64]\ttrain-logloss:0.56043\teval-logloss:0.60883\n",
      "[65]\ttrain-logloss:0.55930\teval-logloss:0.60824\n",
      "[66]\ttrain-logloss:0.55819\teval-logloss:0.60768\n",
      "[67]\ttrain-logloss:0.55710\teval-logloss:0.60714\n",
      "[68]\ttrain-logloss:0.55603\teval-logloss:0.60658\n",
      "[69]\ttrain-logloss:0.55494\teval-logloss:0.60604\n",
      "[70]\ttrain-logloss:0.55390\teval-logloss:0.60552\n",
      "[71]\ttrain-logloss:0.55287\teval-logloss:0.60501\n",
      "[72]\ttrain-logloss:0.55186\teval-logloss:0.60454\n",
      "[73]\ttrain-logloss:0.55087\teval-logloss:0.60405\n",
      "[74]\ttrain-logloss:0.54985\teval-logloss:0.60356\n",
      "[75]\ttrain-logloss:0.54889\teval-logloss:0.60312\n",
      "[76]\ttrain-logloss:0.54794\teval-logloss:0.60267\n",
      "[77]\ttrain-logloss:0.54698\teval-logloss:0.60220\n",
      "[78]\ttrain-logloss:0.54605\teval-logloss:0.60177\n",
      "[79]\ttrain-logloss:0.54515\teval-logloss:0.60133\n",
      "[80]\ttrain-logloss:0.54425\teval-logloss:0.60092\n",
      "[81]\ttrain-logloss:0.54336\teval-logloss:0.60050\n",
      "[82]\ttrain-logloss:0.54250\teval-logloss:0.60009\n",
      "[83]\ttrain-logloss:0.54163\teval-logloss:0.59966\n",
      "[84]\ttrain-logloss:0.54078\teval-logloss:0.59927\n",
      "[85]\ttrain-logloss:0.53996\teval-logloss:0.59889\n",
      "[86]\ttrain-logloss:0.53913\teval-logloss:0.59857\n",
      "[87]\ttrain-logloss:0.53832\teval-logloss:0.59823\n",
      "[88]\ttrain-logloss:0.53752\teval-logloss:0.59784\n",
      "[89]\ttrain-logloss:0.53673\teval-logloss:0.59748\n",
      "[90]\ttrain-logloss:0.53595\teval-logloss:0.59715\n",
      "[91]\ttrain-logloss:0.53519\teval-logloss:0.59681\n",
      "[92]\ttrain-logloss:0.53443\teval-logloss:0.59652\n",
      "[93]\ttrain-logloss:0.53369\teval-logloss:0.59619\n",
      "[94]\ttrain-logloss:0.53296\teval-logloss:0.59588\n",
      "[95]\ttrain-logloss:0.53220\teval-logloss:0.59554\n",
      "[96]\ttrain-logloss:0.53149\teval-logloss:0.59524\n",
      "[97]\ttrain-logloss:0.53079\teval-logloss:0.59495\n",
      "[98]\ttrain-logloss:0.53009\teval-logloss:0.59471\n",
      "[99]\ttrain-logloss:0.52941\teval-logloss:0.59442\n",
      "[100]\ttrain-logloss:0.52873\teval-logloss:0.59420\n",
      "[101]\ttrain-logloss:0.52804\teval-logloss:0.59387\n",
      "[102]\ttrain-logloss:0.52739\teval-logloss:0.59361\n",
      "[103]\ttrain-logloss:0.52675\teval-logloss:0.59335\n",
      "[104]\ttrain-logloss:0.52610\teval-logloss:0.59309\n",
      "[105]\ttrain-logloss:0.52547\teval-logloss:0.59283\n",
      "[106]\ttrain-logloss:0.52486\teval-logloss:0.59263\n",
      "[107]\ttrain-logloss:0.52424\teval-logloss:0.59239\n",
      "[108]\ttrain-logloss:0.52363\teval-logloss:0.59214\n",
      "[109]\ttrain-logloss:0.52301\teval-logloss:0.59191\n",
      "[110]\ttrain-logloss:0.52242\teval-logloss:0.59170\n",
      "[111]\ttrain-logloss:0.52185\teval-logloss:0.59148\n",
      "[112]\ttrain-logloss:0.52128\teval-logloss:0.59125\n",
      "[113]\ttrain-logloss:0.52069\teval-logloss:0.59104\n",
      "[114]\ttrain-logloss:0.52011\teval-logloss:0.59081\n",
      "[115]\ttrain-logloss:0.51956\teval-logloss:0.59063\n",
      "[116]\ttrain-logloss:0.51898\teval-logloss:0.59037\n",
      "[117]\ttrain-logloss:0.51844\teval-logloss:0.59018\n",
      "[118]\ttrain-logloss:0.51790\teval-logloss:0.59001\n",
      "[119]\ttrain-logloss:0.51738\teval-logloss:0.58983\n",
      "[120]\ttrain-logloss:0.51687\teval-logloss:0.58964\n",
      "[121]\ttrain-logloss:0.51636\teval-logloss:0.58947\n",
      "[122]\ttrain-logloss:0.51584\teval-logloss:0.58932\n",
      "[123]\ttrain-logloss:0.51536\teval-logloss:0.58917\n",
      "[124]\ttrain-logloss:0.51483\teval-logloss:0.58895\n",
      "[125]\ttrain-logloss:0.51434\teval-logloss:0.58882\n",
      "[126]\ttrain-logloss:0.51383\teval-logloss:0.58859\n",
      "[127]\ttrain-logloss:0.51334\teval-logloss:0.58843\n",
      "[128]\ttrain-logloss:0.51288\teval-logloss:0.58829\n",
      "[129]\ttrain-logloss:0.51242\teval-logloss:0.58813\n",
      "[130]\ttrain-logloss:0.51195\teval-logloss:0.58799\n",
      "[131]\ttrain-logloss:0.51146\teval-logloss:0.58779\n",
      "[132]\ttrain-logloss:0.51104\teval-logloss:0.58768\n",
      "[133]\ttrain-logloss:0.51057\teval-logloss:0.58749\n",
      "[134]\ttrain-logloss:0.51014\teval-logloss:0.58739\n",
      "[135]\ttrain-logloss:0.50971\teval-logloss:0.58724\n",
      "[136]\ttrain-logloss:0.50930\teval-logloss:0.58710\n",
      "[137]\ttrain-logloss:0.50885\teval-logloss:0.58693\n",
      "[138]\ttrain-logloss:0.50842\teval-logloss:0.58678\n",
      "[139]\ttrain-logloss:0.50801\teval-logloss:0.58668\n",
      "[140]\ttrain-logloss:0.50762\teval-logloss:0.58659\n",
      "[141]\ttrain-logloss:0.50720\teval-logloss:0.58643\n",
      "[142]\ttrain-logloss:0.50679\teval-logloss:0.58627\n",
      "[143]\ttrain-logloss:0.50639\teval-logloss:0.58615\n",
      "[144]\ttrain-logloss:0.50600\teval-logloss:0.58606\n",
      "[145]\ttrain-logloss:0.50564\teval-logloss:0.58597\n",
      "[146]\ttrain-logloss:0.50524\teval-logloss:0.58582\n",
      "[147]\ttrain-logloss:0.50487\teval-logloss:0.58574\n",
      "[148]\ttrain-logloss:0.50451\teval-logloss:0.58566\n",
      "[149]\ttrain-logloss:0.50413\teval-logloss:0.58552\n",
      "[150]\ttrain-logloss:0.50376\teval-logloss:0.58540\n",
      "[151]\ttrain-logloss:0.50343\teval-logloss:0.58534\n",
      "[152]\ttrain-logloss:0.50308\teval-logloss:0.58525\n",
      "[153]\ttrain-logloss:0.50274\teval-logloss:0.58515\n",
      "[154]\ttrain-logloss:0.50238\teval-logloss:0.58501\n",
      "[155]\ttrain-logloss:0.50201\teval-logloss:0.58495\n",
      "[156]\ttrain-logloss:0.50166\teval-logloss:0.58490\n",
      "[157]\ttrain-logloss:0.50135\teval-logloss:0.58482\n",
      "[158]\ttrain-logloss:0.50101\teval-logloss:0.58476\n",
      "[159]\ttrain-logloss:0.50068\teval-logloss:0.58469\n",
      "[160]\ttrain-logloss:0.50036\teval-logloss:0.58458\n",
      "[161]\ttrain-logloss:0.50004\teval-logloss:0.58451\n",
      "[162]\ttrain-logloss:0.49971\teval-logloss:0.58442\n",
      "[163]\ttrain-logloss:0.49940\teval-logloss:0.58435\n",
      "[164]\ttrain-logloss:0.49908\teval-logloss:0.58431\n",
      "[165]\ttrain-logloss:0.49878\teval-logloss:0.58425\n",
      "[166]\ttrain-logloss:0.49847\teval-logloss:0.58418\n",
      "[167]\ttrain-logloss:0.49817\teval-logloss:0.58411\n",
      "[168]\ttrain-logloss:0.49784\teval-logloss:0.58398\n",
      "[169]\ttrain-logloss:0.49753\teval-logloss:0.58387\n",
      "[170]\ttrain-logloss:0.49723\teval-logloss:0.58383\n",
      "[171]\ttrain-logloss:0.49695\teval-logloss:0.58377\n",
      "[172]\ttrain-logloss:0.49664\teval-logloss:0.58364\n",
      "[173]\ttrain-logloss:0.49635\teval-logloss:0.58360\n",
      "[174]\ttrain-logloss:0.49605\teval-logloss:0.58354\n",
      "[175]\ttrain-logloss:0.49577\teval-logloss:0.58346\n",
      "[176]\ttrain-logloss:0.49547\teval-logloss:0.58337\n",
      "[177]\ttrain-logloss:0.49520\teval-logloss:0.58330\n",
      "[178]\ttrain-logloss:0.49491\teval-logloss:0.58325\n",
      "[179]\ttrain-logloss:0.49463\teval-logloss:0.58316\n",
      "[180]\ttrain-logloss:0.49436\teval-logloss:0.58311\n",
      "[181]\ttrain-logloss:0.49408\teval-logloss:0.58303\n",
      "[182]\ttrain-logloss:0.49381\teval-logloss:0.58294\n",
      "[183]\ttrain-logloss:0.49355\teval-logloss:0.58289\n",
      "[184]\ttrain-logloss:0.49329\teval-logloss:0.58284\n",
      "[185]\ttrain-logloss:0.49302\teval-logloss:0.58276\n",
      "[186]\ttrain-logloss:0.49277\teval-logloss:0.58274\n",
      "[187]\ttrain-logloss:0.49252\teval-logloss:0.58269\n",
      "[188]\ttrain-logloss:0.49226\teval-logloss:0.58264\n",
      "[189]\ttrain-logloss:0.49199\teval-logloss:0.58254\n",
      "[190]\ttrain-logloss:0.49174\teval-logloss:0.58247\n",
      "[191]\ttrain-logloss:0.49150\teval-logloss:0.58242\n",
      "[192]\ttrain-logloss:0.49125\teval-logloss:0.58235\n",
      "[193]\ttrain-logloss:0.49100\teval-logloss:0.58230\n",
      "[194]\ttrain-logloss:0.49076\teval-logloss:0.58226\n",
      "[195]\ttrain-logloss:0.49054\teval-logloss:0.58223\n",
      "[196]\ttrain-logloss:0.49029\teval-logloss:0.58213\n",
      "[197]\ttrain-logloss:0.49006\teval-logloss:0.58209\n",
      "[198]\ttrain-logloss:0.48984\teval-logloss:0.58206\n",
      "[199]\ttrain-logloss:0.48960\teval-logloss:0.58196\n",
      "[200]\ttrain-logloss:0.48937\teval-logloss:0.58192\n",
      "[201]\ttrain-logloss:0.48915\teval-logloss:0.58192\n",
      "[202]\ttrain-logloss:0.48893\teval-logloss:0.58188\n",
      "[203]\ttrain-logloss:0.48871\teval-logloss:0.58184\n",
      "[204]\ttrain-logloss:0.48850\teval-logloss:0.58181\n",
      "[205]\ttrain-logloss:0.48826\teval-logloss:0.58174\n",
      "[206]\ttrain-logloss:0.48803\teval-logloss:0.58165\n",
      "[207]\ttrain-logloss:0.48782\teval-logloss:0.58156\n",
      "[208]\ttrain-logloss:0.48760\teval-logloss:0.58155\n",
      "[209]\ttrain-logloss:0.48740\teval-logloss:0.58151\n",
      "[210]\ttrain-logloss:0.48720\teval-logloss:0.58149\n",
      "[211]\ttrain-logloss:0.48698\teval-logloss:0.58147\n",
      "[212]\ttrain-logloss:0.48679\teval-logloss:0.58143\n",
      "[213]\ttrain-logloss:0.48659\teval-logloss:0.58139\n",
      "[214]\ttrain-logloss:0.48638\teval-logloss:0.58130\n",
      "[215]\ttrain-logloss:0.48617\teval-logloss:0.58125\n",
      "[216]\ttrain-logloss:0.48597\teval-logloss:0.58122\n",
      "[217]\ttrain-logloss:0.48579\teval-logloss:0.58120\n",
      "[218]\ttrain-logloss:0.48559\teval-logloss:0.58116\n",
      "[219]\ttrain-logloss:0.48539\teval-logloss:0.58107\n",
      "[220]\ttrain-logloss:0.48519\teval-logloss:0.58103\n",
      "[221]\ttrain-logloss:0.48501\teval-logloss:0.58099\n",
      "[222]\ttrain-logloss:0.48481\teval-logloss:0.58091\n",
      "[223]\ttrain-logloss:0.48460\teval-logloss:0.58080\n",
      "[224]\ttrain-logloss:0.48441\teval-logloss:0.58076\n",
      "[225]\ttrain-logloss:0.48423\teval-logloss:0.58073\n",
      "[226]\ttrain-logloss:0.48404\teval-logloss:0.58072\n",
      "[227]\ttrain-logloss:0.48387\teval-logloss:0.58070\n",
      "[228]\ttrain-logloss:0.48367\teval-logloss:0.58061\n",
      "[229]\ttrain-logloss:0.48350\teval-logloss:0.58057\n",
      "[230]\ttrain-logloss:0.48331\teval-logloss:0.58056\n",
      "[231]\ttrain-logloss:0.48315\teval-logloss:0.58054\n",
      "[232]\ttrain-logloss:0.48296\teval-logloss:0.58043\n",
      "[233]\ttrain-logloss:0.48278\teval-logloss:0.58040\n",
      "[234]\ttrain-logloss:0.48261\teval-logloss:0.58036\n",
      "[235]\ttrain-logloss:0.48242\teval-logloss:0.58032\n",
      "[236]\ttrain-logloss:0.48227\teval-logloss:0.58030\n",
      "[237]\ttrain-logloss:0.48211\teval-logloss:0.58031\n",
      "[238]\ttrain-logloss:0.48191\teval-logloss:0.58025\n",
      "[239]\ttrain-logloss:0.48173\teval-logloss:0.58017\n",
      "[240]\ttrain-logloss:0.48156\teval-logloss:0.58013\n",
      "[241]\ttrain-logloss:0.48139\teval-logloss:0.58012\n",
      "[242]\ttrain-logloss:0.48123\teval-logloss:0.58012\n",
      "[243]\ttrain-logloss:0.48108\teval-logloss:0.58010\n",
      "[244]\ttrain-logloss:0.48089\teval-logloss:0.58004\n",
      "[245]\ttrain-logloss:0.48072\teval-logloss:0.57994\n",
      "[246]\ttrain-logloss:0.48056\teval-logloss:0.57991\n",
      "[247]\ttrain-logloss:0.48040\teval-logloss:0.57992\n",
      "[248]\ttrain-logloss:0.48022\teval-logloss:0.57987\n",
      "[249]\ttrain-logloss:0.48008\teval-logloss:0.57985\n",
      "[250]\ttrain-logloss:0.47990\teval-logloss:0.57980\n",
      "[251]\ttrain-logloss:0.47976\teval-logloss:0.57979\n",
      "[252]\ttrain-logloss:0.47959\teval-logloss:0.57974\n",
      "[253]\ttrain-logloss:0.47944\teval-logloss:0.57972\n",
      "[254]\ttrain-logloss:0.47929\teval-logloss:0.57971\n",
      "[255]\ttrain-logloss:0.47914\teval-logloss:0.57967\n",
      "[256]\ttrain-logloss:0.47899\teval-logloss:0.57964\n",
      "[257]\ttrain-logloss:0.47883\teval-logloss:0.57955\n",
      "[258]\ttrain-logloss:0.47869\teval-logloss:0.57955\n",
      "[259]\ttrain-logloss:0.47856\teval-logloss:0.57954\n",
      "[260]\ttrain-logloss:0.47841\teval-logloss:0.57952\n",
      "[261]\ttrain-logloss:0.47825\teval-logloss:0.57948\n",
      "[262]\ttrain-logloss:0.47811\teval-logloss:0.57944\n",
      "[263]\ttrain-logloss:0.47793\teval-logloss:0.57937\n",
      "[264]\ttrain-logloss:0.47778\teval-logloss:0.57932\n",
      "[265]\ttrain-logloss:0.47763\teval-logloss:0.57929\n",
      "[266]\ttrain-logloss:0.47751\teval-logloss:0.57927\n",
      "[267]\ttrain-logloss:0.47737\teval-logloss:0.57928\n",
      "[268]\ttrain-logloss:0.47724\teval-logloss:0.57927\n",
      "[269]\ttrain-logloss:0.47705\teval-logloss:0.57915\n",
      "[270]\ttrain-logloss:0.47690\teval-logloss:0.57913\n",
      "[271]\ttrain-logloss:0.47675\teval-logloss:0.57905\n",
      "[272]\ttrain-logloss:0.47661\teval-logloss:0.57900\n",
      "[273]\ttrain-logloss:0.47648\teval-logloss:0.57899\n",
      "[274]\ttrain-logloss:0.47634\teval-logloss:0.57896\n",
      "[275]\ttrain-logloss:0.47622\teval-logloss:0.57895\n",
      "[276]\ttrain-logloss:0.47609\teval-logloss:0.57896\n",
      "[277]\ttrain-logloss:0.47595\teval-logloss:0.57893\n",
      "[278]\ttrain-logloss:0.47578\teval-logloss:0.57882\n",
      "[279]\ttrain-logloss:0.47565\teval-logloss:0.57878\n",
      "[280]\ttrain-logloss:0.47552\teval-logloss:0.57877\n",
      "[281]\ttrain-logloss:0.47538\teval-logloss:0.57874\n",
      "[282]\ttrain-logloss:0.47525\teval-logloss:0.57870\n",
      "[283]\ttrain-logloss:0.47509\teval-logloss:0.57861\n",
      "[284]\ttrain-logloss:0.47498\teval-logloss:0.57861\n",
      "[285]\ttrain-logloss:0.47485\teval-logloss:0.57857\n",
      "[286]\ttrain-logloss:0.47473\teval-logloss:0.57856\n",
      "[287]\ttrain-logloss:0.47460\teval-logloss:0.57852\n",
      "[288]\ttrain-logloss:0.47444\teval-logloss:0.57843\n",
      "[289]\ttrain-logloss:0.47431\teval-logloss:0.57837\n",
      "[290]\ttrain-logloss:0.47417\teval-logloss:0.57832\n",
      "[291]\ttrain-logloss:0.47406\teval-logloss:0.57831\n",
      "[292]\ttrain-logloss:0.47391\teval-logloss:0.57823\n",
      "[293]\ttrain-logloss:0.47379\teval-logloss:0.57819\n",
      "[294]\ttrain-logloss:0.47364\teval-logloss:0.57808\n",
      "[295]\ttrain-logloss:0.47351\teval-logloss:0.57806\n",
      "[296]\ttrain-logloss:0.47338\teval-logloss:0.57801\n",
      "[297]\ttrain-logloss:0.47326\teval-logloss:0.57798\n",
      "[298]\ttrain-logloss:0.47316\teval-logloss:0.57798\n",
      "[299]\ttrain-logloss:0.47304\teval-logloss:0.57795\n",
      "[300]\ttrain-logloss:0.47291\teval-logloss:0.57790\n",
      "[301]\ttrain-logloss:0.47280\teval-logloss:0.57791\n",
      "[302]\ttrain-logloss:0.47266\teval-logloss:0.57782\n",
      "[303]\ttrain-logloss:0.47254\teval-logloss:0.57777\n",
      "[304]\ttrain-logloss:0.47242\teval-logloss:0.57772\n",
      "[305]\ttrain-logloss:0.47230\teval-logloss:0.57767\n",
      "[306]\ttrain-logloss:0.47218\teval-logloss:0.57762\n",
      "[307]\ttrain-logloss:0.47207\teval-logloss:0.57760\n",
      "[308]\ttrain-logloss:0.47193\teval-logloss:0.57752\n",
      "[309]\ttrain-logloss:0.47182\teval-logloss:0.57750\n",
      "[310]\ttrain-logloss:0.47170\teval-logloss:0.57747\n",
      "[311]\ttrain-logloss:0.47161\teval-logloss:0.57748\n",
      "[312]\ttrain-logloss:0.47148\teval-logloss:0.57739\n",
      "[313]\ttrain-logloss:0.47136\teval-logloss:0.57734\n",
      "[314]\ttrain-logloss:0.47125\teval-logloss:0.57731\n",
      "[315]\ttrain-logloss:0.47114\teval-logloss:0.57728\n",
      "[316]\ttrain-logloss:0.47103\teval-logloss:0.57726\n",
      "[317]\ttrain-logloss:0.47092\teval-logloss:0.57725\n",
      "[318]\ttrain-logloss:0.47081\teval-logloss:0.57722\n",
      "[319]\ttrain-logloss:0.47069\teval-logloss:0.57712\n",
      "[320]\ttrain-logloss:0.47058\teval-logloss:0.57712\n",
      "[321]\ttrain-logloss:0.47047\teval-logloss:0.57708\n",
      "[322]\ttrain-logloss:0.47036\teval-logloss:0.57704\n",
      "[323]\ttrain-logloss:0.47028\teval-logloss:0.57705\n",
      "[324]\ttrain-logloss:0.47018\teval-logloss:0.57703\n",
      "[325]\ttrain-logloss:0.47006\teval-logloss:0.57695\n",
      "[326]\ttrain-logloss:0.46996\teval-logloss:0.57693\n",
      "[327]\ttrain-logloss:0.46985\teval-logloss:0.57688\n",
      "[328]\ttrain-logloss:0.46975\teval-logloss:0.57687\n",
      "[329]\ttrain-logloss:0.46963\teval-logloss:0.57678\n",
      "[330]\ttrain-logloss:0.46953\teval-logloss:0.57676\n",
      "[331]\ttrain-logloss:0.46943\teval-logloss:0.57673\n",
      "[332]\ttrain-logloss:0.46932\teval-logloss:0.57670\n",
      "[333]\ttrain-logloss:0.46923\teval-logloss:0.57669\n",
      "[334]\ttrain-logloss:0.46912\teval-logloss:0.57665\n",
      "[335]\ttrain-logloss:0.46901\teval-logloss:0.57657\n",
      "[336]\ttrain-logloss:0.46891\teval-logloss:0.57655\n",
      "[337]\ttrain-logloss:0.46882\teval-logloss:0.57654\n",
      "[338]\ttrain-logloss:0.46873\teval-logloss:0.57651\n",
      "[339]\ttrain-logloss:0.46864\teval-logloss:0.57649\n",
      "[340]\ttrain-logloss:0.46854\teval-logloss:0.57646\n",
      "[341]\ttrain-logloss:0.46844\teval-logloss:0.57644\n",
      "[342]\ttrain-logloss:0.46836\teval-logloss:0.57642\n",
      "[343]\ttrain-logloss:0.46825\teval-logloss:0.57634\n",
      "[344]\ttrain-logloss:0.46816\teval-logloss:0.57632\n",
      "[345]\ttrain-logloss:0.46806\teval-logloss:0.57629\n",
      "[346]\ttrain-logloss:0.46797\teval-logloss:0.57626\n",
      "[347]\ttrain-logloss:0.46787\teval-logloss:0.57623\n",
      "[348]\ttrain-logloss:0.46779\teval-logloss:0.57621\n",
      "[349]\ttrain-logloss:0.46771\teval-logloss:0.57621\n",
      "[350]\ttrain-logloss:0.46760\teval-logloss:0.57613\n",
      "[351]\ttrain-logloss:0.46751\teval-logloss:0.57610\n",
      "[352]\ttrain-logloss:0.46742\teval-logloss:0.57608\n",
      "[353]\ttrain-logloss:0.46734\teval-logloss:0.57605\n",
      "[354]\ttrain-logloss:0.46724\teval-logloss:0.57602\n",
      "[355]\ttrain-logloss:0.46715\teval-logloss:0.57601\n",
      "[356]\ttrain-logloss:0.46706\teval-logloss:0.57599\n",
      "[357]\ttrain-logloss:0.46697\teval-logloss:0.57596\n",
      "[358]\ttrain-logloss:0.46690\teval-logloss:0.57594\n",
      "[359]\ttrain-logloss:0.46681\teval-logloss:0.57591\n",
      "[360]\ttrain-logloss:0.46671\teval-logloss:0.57584\n",
      "[361]\ttrain-logloss:0.46663\teval-logloss:0.57583\n",
      "[362]\ttrain-logloss:0.46656\teval-logloss:0.57581\n",
      "[363]\ttrain-logloss:0.46647\teval-logloss:0.57578\n",
      "[364]\ttrain-logloss:0.46639\teval-logloss:0.57579\n",
      "[365]\ttrain-logloss:0.46630\teval-logloss:0.57574\n",
      "[366]\ttrain-logloss:0.46621\teval-logloss:0.57572\n",
      "[367]\ttrain-logloss:0.46613\teval-logloss:0.57570\n",
      "[368]\ttrain-logloss:0.46604\teval-logloss:0.57567\n",
      "[369]\ttrain-logloss:0.46596\teval-logloss:0.57566\n",
      "[370]\ttrain-logloss:0.46589\teval-logloss:0.57564\n",
      "[371]\ttrain-logloss:0.46582\teval-logloss:0.57562\n",
      "[372]\ttrain-logloss:0.46575\teval-logloss:0.57557\n",
      "[373]\ttrain-logloss:0.46565\teval-logloss:0.57553\n",
      "[374]\ttrain-logloss:0.46557\teval-logloss:0.57550\n",
      "[375]\ttrain-logloss:0.46547\teval-logloss:0.57545\n",
      "[376]\ttrain-logloss:0.46539\teval-logloss:0.57544\n",
      "[377]\ttrain-logloss:0.46531\teval-logloss:0.57540\n",
      "[378]\ttrain-logloss:0.46524\teval-logloss:0.57538\n",
      "[379]\ttrain-logloss:0.46518\teval-logloss:0.57540\n",
      "[380]\ttrain-logloss:0.46511\teval-logloss:0.57538\n",
      "[381]\ttrain-logloss:0.46501\teval-logloss:0.57533\n",
      "[382]\ttrain-logloss:0.46493\teval-logloss:0.57531\n",
      "[383]\ttrain-logloss:0.46484\teval-logloss:0.57527\n",
      "[384]\ttrain-logloss:0.46475\teval-logloss:0.57521\n",
      "[385]\ttrain-logloss:0.46466\teval-logloss:0.57515\n",
      "[386]\ttrain-logloss:0.46460\teval-logloss:0.57512\n",
      "[387]\ttrain-logloss:0.46452\teval-logloss:0.57509\n",
      "[388]\ttrain-logloss:0.46444\teval-logloss:0.57506\n",
      "[389]\ttrain-logloss:0.46436\teval-logloss:0.57503\n",
      "[390]\ttrain-logloss:0.46427\teval-logloss:0.57498\n",
      "[391]\ttrain-logloss:0.46422\teval-logloss:0.57498\n",
      "[392]\ttrain-logloss:0.46415\teval-logloss:0.57497\n",
      "[393]\ttrain-logloss:0.46409\teval-logloss:0.57495\n",
      "[394]\ttrain-logloss:0.46404\teval-logloss:0.57494\n",
      "[395]\ttrain-logloss:0.46397\teval-logloss:0.57491\n",
      "[396]\ttrain-logloss:0.46389\teval-logloss:0.57492\n",
      "[397]\ttrain-logloss:0.46381\teval-logloss:0.57487\n",
      "[398]\ttrain-logloss:0.46376\teval-logloss:0.57487\n",
      "[399]\ttrain-logloss:0.46369\teval-logloss:0.57484\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     'booster' :'gbtree',\n",
    "#     'silent' : 0,\n",
    "#     'nthread': 10\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'max_depth' : 3,\n",
    "    'eta' : 0.01,\n",
    "    'booster' :'gbtree',\n",
    "    'eval_metric' : 'logloss'\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(d_train,'train'),(d_val,'eval')]\n",
    "xgb_model = xgb.train(params =params,dtrain = d_train , num_boost_round = num_rounds,\n",
    "         early_stopping_rounds= 100, evals = wlist)\n",
    "# print(\"훈련 세트 정확도 : {:.3f}\".format(xgb_model.score(X_train, y_train)))\n",
    "# print(\"validation 세트 정확도 : {:.3f}\".format(xgb_model.score(X_val, y_val)))\n",
    "# xgb_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678707a-cac0-415e-b363-40d20cb20bdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 훈련 ver 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366568b-f9f9-4e21-a97f-b7e033e73531",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 30%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    훈련 ver1 과 parameter는 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b47fd8-eb5d-4d49-8cd9-09882153cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760d43c7-a4b0-4935-81f2-ac1d596a3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30139c7d-f660-4068-a2fe-719d37e0611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,y_train)\n",
    "dval = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1d1f41-bbf7-483e-9bac-3f19e3fdca90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.69011\teval-logloss:0.69006\n",
      "[1]\ttrain-logloss:0.68710\teval-logloss:0.68705\n",
      "[2]\ttrain-logloss:0.68417\teval-logloss:0.68409\n",
      "[3]\ttrain-logloss:0.68128\teval-logloss:0.68119\n",
      "[4]\ttrain-logloss:0.67844\teval-logloss:0.67836\n",
      "[5]\ttrain-logloss:0.67565\teval-logloss:0.67558\n",
      "[6]\ttrain-logloss:0.67292\teval-logloss:0.67285\n",
      "[7]\ttrain-logloss:0.67025\teval-logloss:0.67018\n",
      "[8]\ttrain-logloss:0.66765\teval-logloss:0.66753\n",
      "[9]\ttrain-logloss:0.66507\teval-logloss:0.66496\n",
      "[10]\ttrain-logloss:0.66254\teval-logloss:0.66243\n",
      "[11]\ttrain-logloss:0.66005\teval-logloss:0.65996\n",
      "[12]\ttrain-logloss:0.65763\teval-logloss:0.65751\n",
      "[13]\ttrain-logloss:0.65523\teval-logloss:0.65512\n",
      "[14]\ttrain-logloss:0.65290\teval-logloss:0.65276\n",
      "[15]\ttrain-logloss:0.65059\teval-logloss:0.65047\n",
      "[16]\ttrain-logloss:0.64833\teval-logloss:0.64818\n",
      "[17]\ttrain-logloss:0.64611\teval-logloss:0.64597\n",
      "[18]\ttrain-logloss:0.64393\teval-logloss:0.64377\n",
      "[19]\ttrain-logloss:0.64180\teval-logloss:0.64166\n",
      "[20]\ttrain-logloss:0.63969\teval-logloss:0.63952\n",
      "[21]\ttrain-logloss:0.63763\teval-logloss:0.63747\n",
      "[22]\ttrain-logloss:0.63560\teval-logloss:0.63541\n",
      "[23]\ttrain-logloss:0.63360\teval-logloss:0.63340\n",
      "[24]\ttrain-logloss:0.63163\teval-logloss:0.63144\n",
      "[25]\ttrain-logloss:0.62971\teval-logloss:0.62955\n",
      "[26]\ttrain-logloss:0.62782\teval-logloss:0.62762\n",
      "[27]\ttrain-logloss:0.62596\teval-logloss:0.62577\n",
      "[28]\ttrain-logloss:0.62412\teval-logloss:0.62391\n",
      "[29]\ttrain-logloss:0.62232\teval-logloss:0.62208\n",
      "[30]\ttrain-logloss:0.62053\teval-logloss:0.62031\n",
      "[31]\ttrain-logloss:0.61880\teval-logloss:0.61858\n",
      "[32]\ttrain-logloss:0.61707\teval-logloss:0.61685\n",
      "[33]\ttrain-logloss:0.61538\teval-logloss:0.61514\n",
      "[34]\ttrain-logloss:0.61373\teval-logloss:0.61352\n",
      "[35]\ttrain-logloss:0.61210\teval-logloss:0.61185\n",
      "[36]\ttrain-logloss:0.61050\teval-logloss:0.61028\n",
      "[37]\ttrain-logloss:0.60893\teval-logloss:0.60867\n",
      "[38]\ttrain-logloss:0.60736\teval-logloss:0.60713\n",
      "[39]\ttrain-logloss:0.60583\teval-logloss:0.60560\n",
      "[40]\ttrain-logloss:0.60433\teval-logloss:0.60407\n",
      "[41]\ttrain-logloss:0.60286\teval-logloss:0.60262\n",
      "[42]\ttrain-logloss:0.60141\teval-logloss:0.60113\n",
      "[43]\ttrain-logloss:0.59998\teval-logloss:0.59966\n",
      "[44]\ttrain-logloss:0.59855\teval-logloss:0.59827\n",
      "[45]\ttrain-logloss:0.59717\teval-logloss:0.59691\n",
      "[46]\ttrain-logloss:0.59580\teval-logloss:0.59552\n",
      "[47]\ttrain-logloss:0.59447\teval-logloss:0.59421\n",
      "[48]\ttrain-logloss:0.59314\teval-logloss:0.59287\n",
      "[49]\ttrain-logloss:0.59184\teval-logloss:0.59153\n",
      "[50]\ttrain-logloss:0.59057\teval-logloss:0.59024\n",
      "[51]\ttrain-logloss:0.58931\teval-logloss:0.58901\n",
      "[52]\ttrain-logloss:0.58805\teval-logloss:0.58776\n",
      "[53]\ttrain-logloss:0.58683\teval-logloss:0.58653\n",
      "[54]\ttrain-logloss:0.58563\teval-logloss:0.58535\n",
      "[55]\ttrain-logloss:0.58445\teval-logloss:0.58414\n",
      "[56]\ttrain-logloss:0.58326\teval-logloss:0.58297\n",
      "[57]\ttrain-logloss:0.58211\teval-logloss:0.58181\n",
      "[58]\ttrain-logloss:0.58099\teval-logloss:0.58071\n",
      "[59]\ttrain-logloss:0.57988\teval-logloss:0.57960\n",
      "[60]\ttrain-logloss:0.57879\teval-logloss:0.57854\n",
      "[61]\ttrain-logloss:0.57768\teval-logloss:0.57746\n",
      "[62]\ttrain-logloss:0.57662\teval-logloss:0.57637\n",
      "[63]\ttrain-logloss:0.57557\teval-logloss:0.57532\n",
      "[64]\ttrain-logloss:0.57454\teval-logloss:0.57431\n",
      "[65]\ttrain-logloss:0.57353\teval-logloss:0.57329\n",
      "[66]\ttrain-logloss:0.57252\teval-logloss:0.57233\n",
      "[67]\ttrain-logloss:0.57151\teval-logloss:0.57133\n",
      "[68]\ttrain-logloss:0.57053\teval-logloss:0.57042\n",
      "[69]\ttrain-logloss:0.56957\teval-logloss:0.56950\n",
      "[70]\ttrain-logloss:0.56862\teval-logloss:0.56853\n",
      "[71]\ttrain-logloss:0.56769\teval-logloss:0.56761\n",
      "[72]\ttrain-logloss:0.56675\teval-logloss:0.56668\n",
      "[73]\ttrain-logloss:0.56584\teval-logloss:0.56581\n",
      "[74]\ttrain-logloss:0.56494\teval-logloss:0.56496\n",
      "[75]\ttrain-logloss:0.56406\teval-logloss:0.56410\n",
      "[76]\ttrain-logloss:0.56319\teval-logloss:0.56327\n",
      "[77]\ttrain-logloss:0.56234\teval-logloss:0.56242\n",
      "[78]\ttrain-logloss:0.56150\teval-logloss:0.56161\n",
      "[79]\ttrain-logloss:0.56064\teval-logloss:0.56078\n",
      "[80]\ttrain-logloss:0.55981\teval-logloss:0.55999\n",
      "[81]\ttrain-logloss:0.55901\teval-logloss:0.55920\n",
      "[82]\ttrain-logloss:0.55820\teval-logloss:0.55841\n",
      "[83]\ttrain-logloss:0.55743\teval-logloss:0.55766\n",
      "[84]\ttrain-logloss:0.55662\teval-logloss:0.55687\n",
      "[85]\ttrain-logloss:0.55585\teval-logloss:0.55615\n",
      "[86]\ttrain-logloss:0.55510\teval-logloss:0.55542\n",
      "[87]\ttrain-logloss:0.55436\teval-logloss:0.55469\n",
      "[88]\ttrain-logloss:0.55363\teval-logloss:0.55399\n",
      "[89]\ttrain-logloss:0.55291\teval-logloss:0.55325\n",
      "[90]\ttrain-logloss:0.55219\teval-logloss:0.55258\n",
      "[91]\ttrain-logloss:0.55150\teval-logloss:0.55192\n",
      "[92]\ttrain-logloss:0.55078\teval-logloss:0.55121\n",
      "[93]\ttrain-logloss:0.55010\teval-logloss:0.55054\n",
      "[94]\ttrain-logloss:0.54942\teval-logloss:0.54988\n",
      "[95]\ttrain-logloss:0.54876\teval-logloss:0.54923\n",
      "[96]\ttrain-logloss:0.54810\teval-logloss:0.54855\n",
      "[97]\ttrain-logloss:0.54746\teval-logloss:0.54794\n",
      "[98]\ttrain-logloss:0.54682\teval-logloss:0.54731\n",
      "[99]\ttrain-logloss:0.54618\teval-logloss:0.54672\n",
      "[100]\ttrain-logloss:0.54557\teval-logloss:0.54617\n",
      "[101]\ttrain-logloss:0.54493\teval-logloss:0.54554\n",
      "[102]\ttrain-logloss:0.54432\teval-logloss:0.54492\n",
      "[103]\ttrain-logloss:0.54372\teval-logloss:0.54434\n",
      "[104]\ttrain-logloss:0.54314\teval-logloss:0.54377\n",
      "[105]\ttrain-logloss:0.54256\teval-logloss:0.54324\n",
      "[106]\ttrain-logloss:0.54195\teval-logloss:0.54263\n",
      "[107]\ttrain-logloss:0.54139\teval-logloss:0.54210\n",
      "[108]\ttrain-logloss:0.54083\teval-logloss:0.54155\n",
      "[109]\ttrain-logloss:0.54028\teval-logloss:0.54100\n",
      "[110]\ttrain-logloss:0.53974\teval-logloss:0.54052\n",
      "[111]\ttrain-logloss:0.53918\teval-logloss:0.53995\n",
      "[112]\ttrain-logloss:0.53864\teval-logloss:0.53942\n",
      "[113]\ttrain-logloss:0.53813\teval-logloss:0.53892\n",
      "[114]\ttrain-logloss:0.53758\teval-logloss:0.53843\n",
      "[115]\ttrain-logloss:0.53707\teval-logloss:0.53795\n",
      "[116]\ttrain-logloss:0.53656\teval-logloss:0.53744\n",
      "[117]\ttrain-logloss:0.53605\teval-logloss:0.53698\n",
      "[118]\ttrain-logloss:0.53556\teval-logloss:0.53652\n",
      "[119]\ttrain-logloss:0.53507\teval-logloss:0.53604\n",
      "[120]\ttrain-logloss:0.53456\teval-logloss:0.53559\n",
      "[121]\ttrain-logloss:0.53409\teval-logloss:0.53514\n",
      "[122]\ttrain-logloss:0.53363\teval-logloss:0.53471\n",
      "[123]\ttrain-logloss:0.53316\teval-logloss:0.53425\n",
      "[124]\ttrain-logloss:0.53269\teval-logloss:0.53383\n",
      "[125]\ttrain-logloss:0.53225\teval-logloss:0.53340\n",
      "[126]\ttrain-logloss:0.53180\teval-logloss:0.53301\n",
      "[127]\ttrain-logloss:0.53134\teval-logloss:0.53254\n",
      "[128]\ttrain-logloss:0.53090\teval-logloss:0.53211\n",
      "[129]\ttrain-logloss:0.53048\teval-logloss:0.53172\n",
      "[130]\ttrain-logloss:0.53005\teval-logloss:0.53131\n",
      "[131]\ttrain-logloss:0.52961\teval-logloss:0.53093\n",
      "[132]\ttrain-logloss:0.52920\teval-logloss:0.53053\n",
      "[133]\ttrain-logloss:0.52879\teval-logloss:0.53012\n",
      "[134]\ttrain-logloss:0.52837\teval-logloss:0.52975\n",
      "[135]\ttrain-logloss:0.52798\teval-logloss:0.52940\n",
      "[136]\ttrain-logloss:0.52757\teval-logloss:0.52906\n",
      "[137]\ttrain-logloss:0.52718\teval-logloss:0.52868\n",
      "[138]\ttrain-logloss:0.52676\teval-logloss:0.52826\n",
      "[139]\ttrain-logloss:0.52639\teval-logloss:0.52791\n",
      "[140]\ttrain-logloss:0.52598\teval-logloss:0.52749\n",
      "[141]\ttrain-logloss:0.52559\teval-logloss:0.52715\n",
      "[142]\ttrain-logloss:0.52523\teval-logloss:0.52681\n",
      "[143]\ttrain-logloss:0.52487\teval-logloss:0.52648\n",
      "[144]\ttrain-logloss:0.52451\teval-logloss:0.52613\n",
      "[145]\ttrain-logloss:0.52415\teval-logloss:0.52578\n",
      "[146]\ttrain-logloss:0.52379\teval-logloss:0.52547\n",
      "[147]\ttrain-logloss:0.52346\teval-logloss:0.52517\n",
      "[148]\ttrain-logloss:0.52308\teval-logloss:0.52480\n",
      "[149]\ttrain-logloss:0.52271\teval-logloss:0.52444\n",
      "[150]\ttrain-logloss:0.52236\teval-logloss:0.52414\n",
      "[151]\ttrain-logloss:0.52203\teval-logloss:0.52382\n",
      "[152]\ttrain-logloss:0.52171\teval-logloss:0.52350\n",
      "[153]\ttrain-logloss:0.52139\teval-logloss:0.52318\n",
      "[154]\ttrain-logloss:0.52106\teval-logloss:0.52287\n",
      "[155]\ttrain-logloss:0.52074\teval-logloss:0.52256\n",
      "[156]\ttrain-logloss:0.52040\teval-logloss:0.52225\n",
      "[157]\ttrain-logloss:0.52009\teval-logloss:0.52195\n",
      "[158]\ttrain-logloss:0.51976\teval-logloss:0.52167\n",
      "[159]\ttrain-logloss:0.51943\teval-logloss:0.52137\n",
      "[160]\ttrain-logloss:0.51911\teval-logloss:0.52107\n",
      "[161]\ttrain-logloss:0.51880\teval-logloss:0.52081\n",
      "[162]\ttrain-logloss:0.51848\teval-logloss:0.52052\n",
      "[163]\ttrain-logloss:0.51817\teval-logloss:0.52025\n",
      "[164]\ttrain-logloss:0.51788\teval-logloss:0.52001\n",
      "[165]\ttrain-logloss:0.51757\teval-logloss:0.51974\n",
      "[166]\ttrain-logloss:0.51729\teval-logloss:0.51948\n",
      "[167]\ttrain-logloss:0.51700\teval-logloss:0.51918\n",
      "[168]\ttrain-logloss:0.51670\teval-logloss:0.51891\n",
      "[169]\ttrain-logloss:0.51641\teval-logloss:0.51867\n",
      "[170]\ttrain-logloss:0.51612\teval-logloss:0.51841\n",
      "[171]\ttrain-logloss:0.51586\teval-logloss:0.51820\n",
      "[172]\ttrain-logloss:0.51557\teval-logloss:0.51794\n",
      "[173]\ttrain-logloss:0.51528\teval-logloss:0.51770\n",
      "[174]\ttrain-logloss:0.51501\teval-logloss:0.51745\n",
      "[175]\ttrain-logloss:0.51472\teval-logloss:0.51720\n",
      "[176]\ttrain-logloss:0.51445\teval-logloss:0.51695\n",
      "[177]\ttrain-logloss:0.51418\teval-logloss:0.51673\n",
      "[178]\ttrain-logloss:0.51391\teval-logloss:0.51650\n",
      "[179]\ttrain-logloss:0.51364\teval-logloss:0.51626\n",
      "[180]\ttrain-logloss:0.51337\teval-logloss:0.51602\n",
      "[181]\ttrain-logloss:0.51311\teval-logloss:0.51580\n",
      "[182]\ttrain-logloss:0.51285\teval-logloss:0.51557\n",
      "[183]\ttrain-logloss:0.51261\teval-logloss:0.51539\n",
      "[184]\ttrain-logloss:0.51235\teval-logloss:0.51518\n",
      "[185]\ttrain-logloss:0.51210\teval-logloss:0.51496\n",
      "[186]\ttrain-logloss:0.51185\teval-logloss:0.51471\n",
      "[187]\ttrain-logloss:0.51161\teval-logloss:0.51454\n",
      "[188]\ttrain-logloss:0.51136\teval-logloss:0.51434\n",
      "[189]\ttrain-logloss:0.51112\teval-logloss:0.51413\n",
      "[190]\ttrain-logloss:0.51088\teval-logloss:0.51389\n",
      "[191]\ttrain-logloss:0.51064\teval-logloss:0.51369\n",
      "[192]\ttrain-logloss:0.51042\teval-logloss:0.51351\n",
      "[193]\ttrain-logloss:0.51018\teval-logloss:0.51330\n",
      "[194]\ttrain-logloss:0.50994\teval-logloss:0.51311\n",
      "[195]\ttrain-logloss:0.50971\teval-logloss:0.51292\n",
      "[196]\ttrain-logloss:0.50948\teval-logloss:0.51270\n",
      "[197]\ttrain-logloss:0.50925\teval-logloss:0.51252\n",
      "[198]\ttrain-logloss:0.50903\teval-logloss:0.51233\n",
      "[199]\ttrain-logloss:0.50877\teval-logloss:0.51211\n",
      "[200]\ttrain-logloss:0.50855\teval-logloss:0.51189\n",
      "[201]\ttrain-logloss:0.50833\teval-logloss:0.51167\n",
      "[202]\ttrain-logloss:0.50807\teval-logloss:0.51145\n",
      "[203]\ttrain-logloss:0.50784\teval-logloss:0.51127\n",
      "[204]\ttrain-logloss:0.50763\teval-logloss:0.51109\n",
      "[205]\ttrain-logloss:0.50740\teval-logloss:0.51089\n",
      "[206]\ttrain-logloss:0.50719\teval-logloss:0.51072\n",
      "[207]\ttrain-logloss:0.50699\teval-logloss:0.51057\n",
      "[208]\ttrain-logloss:0.50678\teval-logloss:0.51041\n",
      "[209]\ttrain-logloss:0.50657\teval-logloss:0.51023\n",
      "[210]\ttrain-logloss:0.50637\teval-logloss:0.51009\n",
      "[211]\ttrain-logloss:0.50615\teval-logloss:0.50992\n",
      "[212]\ttrain-logloss:0.50597\teval-logloss:0.50977\n",
      "[213]\ttrain-logloss:0.50572\teval-logloss:0.50955\n",
      "[214]\ttrain-logloss:0.50552\teval-logloss:0.50939\n",
      "[215]\ttrain-logloss:0.50533\teval-logloss:0.50924\n",
      "[216]\ttrain-logloss:0.50511\teval-logloss:0.50905\n",
      "[217]\ttrain-logloss:0.50492\teval-logloss:0.50888\n",
      "[218]\ttrain-logloss:0.50472\teval-logloss:0.50869\n",
      "[219]\ttrain-logloss:0.50453\teval-logloss:0.50855\n",
      "[220]\ttrain-logloss:0.50434\teval-logloss:0.50840\n",
      "[221]\ttrain-logloss:0.50411\teval-logloss:0.50819\n",
      "[222]\ttrain-logloss:0.50392\teval-logloss:0.50804\n",
      "[223]\ttrain-logloss:0.50371\teval-logloss:0.50787\n",
      "[224]\ttrain-logloss:0.50354\teval-logloss:0.50774\n",
      "[225]\ttrain-logloss:0.50336\teval-logloss:0.50761\n",
      "[226]\ttrain-logloss:0.50316\teval-logloss:0.50743\n",
      "[227]\ttrain-logloss:0.50299\teval-logloss:0.50730\n",
      "[228]\ttrain-logloss:0.50279\teval-logloss:0.50714\n",
      "[229]\ttrain-logloss:0.50261\teval-logloss:0.50702\n",
      "[230]\ttrain-logloss:0.50242\teval-logloss:0.50682\n",
      "[231]\ttrain-logloss:0.50225\teval-logloss:0.50667\n",
      "[232]\ttrain-logloss:0.50203\teval-logloss:0.50647\n",
      "[233]\ttrain-logloss:0.50186\teval-logloss:0.50635\n",
      "[234]\ttrain-logloss:0.50168\teval-logloss:0.50622\n",
      "[235]\ttrain-logloss:0.50150\teval-logloss:0.50609\n",
      "[236]\ttrain-logloss:0.50135\teval-logloss:0.50597\n",
      "[237]\ttrain-logloss:0.50117\teval-logloss:0.50580\n",
      "[238]\ttrain-logloss:0.50099\teval-logloss:0.50566\n",
      "[239]\ttrain-logloss:0.50080\teval-logloss:0.50552\n",
      "[240]\ttrain-logloss:0.50064\teval-logloss:0.50542\n",
      "[241]\ttrain-logloss:0.50046\teval-logloss:0.50528\n",
      "[242]\ttrain-logloss:0.50029\teval-logloss:0.50513\n",
      "[243]\ttrain-logloss:0.50012\teval-logloss:0.50502\n",
      "[244]\ttrain-logloss:0.49993\teval-logloss:0.50489\n",
      "[245]\ttrain-logloss:0.49978\teval-logloss:0.50474\n",
      "[246]\ttrain-logloss:0.49960\teval-logloss:0.50461\n",
      "[247]\ttrain-logloss:0.49945\teval-logloss:0.50451\n",
      "[248]\ttrain-logloss:0.49928\teval-logloss:0.50439\n",
      "[249]\ttrain-logloss:0.49911\teval-logloss:0.50424\n",
      "[250]\ttrain-logloss:0.49896\teval-logloss:0.50413\n",
      "[251]\ttrain-logloss:0.49879\teval-logloss:0.50401\n",
      "[252]\ttrain-logloss:0.49862\teval-logloss:0.50389\n",
      "[253]\ttrain-logloss:0.49846\teval-logloss:0.50377\n",
      "[254]\ttrain-logloss:0.49832\teval-logloss:0.50365\n",
      "[255]\ttrain-logloss:0.49814\teval-logloss:0.50350\n",
      "[256]\ttrain-logloss:0.49797\teval-logloss:0.50339\n",
      "[257]\ttrain-logloss:0.49781\teval-logloss:0.50325\n",
      "[258]\ttrain-logloss:0.49764\teval-logloss:0.50312\n",
      "[259]\ttrain-logloss:0.49750\teval-logloss:0.50300\n",
      "[260]\ttrain-logloss:0.49733\teval-logloss:0.50290\n",
      "[261]\ttrain-logloss:0.49717\teval-logloss:0.50275\n",
      "[262]\ttrain-logloss:0.49702\teval-logloss:0.50262\n",
      "[263]\ttrain-logloss:0.49688\teval-logloss:0.50249\n",
      "[264]\ttrain-logloss:0.49675\teval-logloss:0.50238\n",
      "[265]\ttrain-logloss:0.49659\teval-logloss:0.50228\n",
      "[266]\ttrain-logloss:0.49646\teval-logloss:0.50218\n",
      "[267]\ttrain-logloss:0.49631\teval-logloss:0.50205\n",
      "[268]\ttrain-logloss:0.49617\teval-logloss:0.50197\n",
      "[269]\ttrain-logloss:0.49600\teval-logloss:0.50182\n",
      "[270]\ttrain-logloss:0.49585\teval-logloss:0.50170\n",
      "[271]\ttrain-logloss:0.49571\teval-logloss:0.50161\n",
      "[272]\ttrain-logloss:0.49552\teval-logloss:0.50143\n",
      "[273]\ttrain-logloss:0.49538\teval-logloss:0.50134\n",
      "[274]\ttrain-logloss:0.49524\teval-logloss:0.50122\n",
      "[275]\ttrain-logloss:0.49510\teval-logloss:0.50113\n",
      "[276]\ttrain-logloss:0.49498\teval-logloss:0.50104\n",
      "[277]\ttrain-logloss:0.49484\teval-logloss:0.50095\n",
      "[278]\ttrain-logloss:0.49467\teval-logloss:0.50078\n",
      "[279]\ttrain-logloss:0.49455\teval-logloss:0.50068\n",
      "[280]\ttrain-logloss:0.49441\teval-logloss:0.50060\n",
      "[281]\ttrain-logloss:0.49428\teval-logloss:0.50052\n",
      "[282]\ttrain-logloss:0.49415\teval-logloss:0.50041\n",
      "[283]\ttrain-logloss:0.49402\teval-logloss:0.50030\n",
      "[284]\ttrain-logloss:0.49389\teval-logloss:0.50022\n",
      "[285]\ttrain-logloss:0.49377\teval-logloss:0.50014\n",
      "[286]\ttrain-logloss:0.49361\teval-logloss:0.50000\n",
      "[287]\ttrain-logloss:0.49345\teval-logloss:0.49985\n",
      "[288]\ttrain-logloss:0.49332\teval-logloss:0.49976\n",
      "[289]\ttrain-logloss:0.49319\teval-logloss:0.49968\n",
      "[290]\ttrain-logloss:0.49306\teval-logloss:0.49958\n",
      "[291]\ttrain-logloss:0.49294\teval-logloss:0.49951\n",
      "[292]\ttrain-logloss:0.49282\teval-logloss:0.49940\n",
      "[293]\ttrain-logloss:0.49270\teval-logloss:0.49932\n",
      "[294]\ttrain-logloss:0.49258\teval-logloss:0.49925\n",
      "[295]\ttrain-logloss:0.49246\teval-logloss:0.49918\n",
      "[296]\ttrain-logloss:0.49235\teval-logloss:0.49909\n",
      "[297]\ttrain-logloss:0.49221\teval-logloss:0.49894\n",
      "[298]\ttrain-logloss:0.49209\teval-logloss:0.49885\n",
      "[299]\ttrain-logloss:0.49197\teval-logloss:0.49877\n",
      "[300]\ttrain-logloss:0.49185\teval-logloss:0.49871\n",
      "[301]\ttrain-logloss:0.49173\teval-logloss:0.49864\n",
      "[302]\ttrain-logloss:0.49162\teval-logloss:0.49855\n",
      "[303]\ttrain-logloss:0.49148\teval-logloss:0.49841\n",
      "[304]\ttrain-logloss:0.49137\teval-logloss:0.49834\n",
      "[305]\ttrain-logloss:0.49127\teval-logloss:0.49828\n",
      "[306]\ttrain-logloss:0.49113\teval-logloss:0.49814\n",
      "[307]\ttrain-logloss:0.49100\teval-logloss:0.49806\n",
      "[308]\ttrain-logloss:0.49089\teval-logloss:0.49799\n",
      "[309]\ttrain-logloss:0.49077\teval-logloss:0.49789\n",
      "[310]\ttrain-logloss:0.49065\teval-logloss:0.49780\n",
      "[311]\ttrain-logloss:0.49055\teval-logloss:0.49773\n",
      "[312]\ttrain-logloss:0.49045\teval-logloss:0.49766\n",
      "[313]\ttrain-logloss:0.49034\teval-logloss:0.49760\n",
      "[314]\ttrain-logloss:0.49021\teval-logloss:0.49751\n",
      "[315]\ttrain-logloss:0.49011\teval-logloss:0.49747\n",
      "[316]\ttrain-logloss:0.49000\teval-logloss:0.49738\n",
      "[317]\ttrain-logloss:0.48990\teval-logloss:0.49729\n",
      "[318]\ttrain-logloss:0.48980\teval-logloss:0.49725\n",
      "[319]\ttrain-logloss:0.48968\teval-logloss:0.49717\n",
      "[320]\ttrain-logloss:0.48959\teval-logloss:0.49711\n",
      "[321]\ttrain-logloss:0.48948\teval-logloss:0.49703\n",
      "[322]\ttrain-logloss:0.48937\teval-logloss:0.49697\n",
      "[323]\ttrain-logloss:0.48925\teval-logloss:0.49690\n",
      "[324]\ttrain-logloss:0.48915\teval-logloss:0.49686\n",
      "[325]\ttrain-logloss:0.48906\teval-logloss:0.49678\n",
      "[326]\ttrain-logloss:0.48895\teval-logloss:0.49671\n",
      "[327]\ttrain-logloss:0.48884\teval-logloss:0.49664\n",
      "[328]\ttrain-logloss:0.48875\teval-logloss:0.49659\n",
      "[329]\ttrain-logloss:0.48865\teval-logloss:0.49650\n",
      "[330]\ttrain-logloss:0.48856\teval-logloss:0.49647\n",
      "[331]\ttrain-logloss:0.48847\teval-logloss:0.49640\n",
      "[332]\ttrain-logloss:0.48838\teval-logloss:0.49637\n",
      "[333]\ttrain-logloss:0.48826\teval-logloss:0.49625\n",
      "[334]\ttrain-logloss:0.48815\teval-logloss:0.49618\n",
      "[335]\ttrain-logloss:0.48805\teval-logloss:0.49610\n",
      "[336]\ttrain-logloss:0.48797\teval-logloss:0.49608\n",
      "[337]\ttrain-logloss:0.48788\teval-logloss:0.49604\n",
      "[338]\ttrain-logloss:0.48778\teval-logloss:0.49598\n",
      "[339]\ttrain-logloss:0.48769\teval-logloss:0.49589\n",
      "[340]\ttrain-logloss:0.48758\teval-logloss:0.49578\n",
      "[341]\ttrain-logloss:0.48747\teval-logloss:0.49571\n",
      "[342]\ttrain-logloss:0.48739\teval-logloss:0.49567\n",
      "[343]\ttrain-logloss:0.48729\teval-logloss:0.49559\n",
      "[344]\ttrain-logloss:0.48722\teval-logloss:0.49558\n",
      "[345]\ttrain-logloss:0.48713\teval-logloss:0.49554\n",
      "[346]\ttrain-logloss:0.48702\teval-logloss:0.49543\n",
      "[347]\ttrain-logloss:0.48694\teval-logloss:0.49540\n",
      "[348]\ttrain-logloss:0.48683\teval-logloss:0.49535\n",
      "[349]\ttrain-logloss:0.48674\teval-logloss:0.49528\n",
      "[350]\ttrain-logloss:0.48666\teval-logloss:0.49522\n",
      "[351]\ttrain-logloss:0.48658\teval-logloss:0.49517\n",
      "[352]\ttrain-logloss:0.48648\teval-logloss:0.49512\n",
      "[353]\ttrain-logloss:0.48638\teval-logloss:0.49507\n",
      "[354]\ttrain-logloss:0.48627\teval-logloss:0.49496\n",
      "[355]\ttrain-logloss:0.48619\teval-logloss:0.49494\n",
      "[356]\ttrain-logloss:0.48610\teval-logloss:0.49487\n",
      "[357]\ttrain-logloss:0.48602\teval-logloss:0.49480\n",
      "[358]\ttrain-logloss:0.48592\teval-logloss:0.49474\n",
      "[359]\ttrain-logloss:0.48585\teval-logloss:0.49471\n",
      "[360]\ttrain-logloss:0.48577\teval-logloss:0.49469\n",
      "[361]\ttrain-logloss:0.48569\teval-logloss:0.49463\n",
      "[362]\ttrain-logloss:0.48557\teval-logloss:0.49455\n",
      "[363]\ttrain-logloss:0.48550\teval-logloss:0.49449\n",
      "[364]\ttrain-logloss:0.48540\teval-logloss:0.49439\n",
      "[365]\ttrain-logloss:0.48532\teval-logloss:0.49435\n",
      "[366]\ttrain-logloss:0.48523\teval-logloss:0.49430\n",
      "[367]\ttrain-logloss:0.48514\teval-logloss:0.49426\n",
      "[368]\ttrain-logloss:0.48504\teval-logloss:0.49421\n",
      "[369]\ttrain-logloss:0.48494\teval-logloss:0.49414\n",
      "[370]\ttrain-logloss:0.48485\teval-logloss:0.49406\n",
      "[371]\ttrain-logloss:0.48479\teval-logloss:0.49405\n",
      "[372]\ttrain-logloss:0.48469\teval-logloss:0.49400\n",
      "[373]\ttrain-logloss:0.48458\teval-logloss:0.49391\n",
      "[374]\ttrain-logloss:0.48448\teval-logloss:0.49381\n",
      "[375]\ttrain-logloss:0.48439\teval-logloss:0.49376\n",
      "[376]\ttrain-logloss:0.48431\teval-logloss:0.49370\n",
      "[377]\ttrain-logloss:0.48421\teval-logloss:0.49363\n",
      "[378]\ttrain-logloss:0.48413\teval-logloss:0.49362\n",
      "[379]\ttrain-logloss:0.48404\teval-logloss:0.49356\n",
      "[380]\ttrain-logloss:0.48395\teval-logloss:0.49350\n",
      "[381]\ttrain-logloss:0.48388\teval-logloss:0.49344\n",
      "[382]\ttrain-logloss:0.48379\teval-logloss:0.49339\n",
      "[383]\ttrain-logloss:0.48372\teval-logloss:0.49338\n",
      "[384]\ttrain-logloss:0.48362\teval-logloss:0.49333\n",
      "[385]\ttrain-logloss:0.48355\teval-logloss:0.49327\n",
      "[386]\ttrain-logloss:0.48347\teval-logloss:0.49322\n",
      "[387]\ttrain-logloss:0.48340\teval-logloss:0.49321\n",
      "[388]\ttrain-logloss:0.48331\teval-logloss:0.49315\n",
      "[389]\ttrain-logloss:0.48324\teval-logloss:0.49310\n",
      "[390]\ttrain-logloss:0.48317\teval-logloss:0.49306\n",
      "[391]\ttrain-logloss:0.48310\teval-logloss:0.49306\n",
      "[392]\ttrain-logloss:0.48303\teval-logloss:0.49304\n",
      "[393]\ttrain-logloss:0.48295\teval-logloss:0.49299\n",
      "[394]\ttrain-logloss:0.48288\teval-logloss:0.49293\n",
      "[395]\ttrain-logloss:0.48280\teval-logloss:0.49288\n",
      "[396]\ttrain-logloss:0.48274\teval-logloss:0.49287\n",
      "[397]\ttrain-logloss:0.48265\teval-logloss:0.49282\n",
      "[398]\ttrain-logloss:0.48257\teval-logloss:0.49277\n",
      "[399]\ttrain-logloss:0.48250\teval-logloss:0.49274\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth' : 3,\n",
    "    'eta' : 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'logloss'\n",
    "}\n",
    "num_rounds2 = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model2 = xgb.train(params = params, dtrain = dtrain , num_boost_round= num_rounds2, early_stopping_rounds= 100, evals = wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a72cc68-612b-45b9-9ed5-4c33007170e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs2 = xgb_model.predict(dval)\n",
    "preds2 = np.where(pred_probs2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47491780-2032-474c-aca0-0efb079e10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬: \n",
      " [[2945  111]\n",
      " [ 893  551]]\n",
      "\n",
      "정확도:0.7769\n",
      "정밀도:0.8323\n",
      "재현율:0.3816\n",
      "F1:0.5233\n",
      "AUC:0.6726\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬: \\n', confusion)\n",
    "    print(f'\\n정확도:{accuracy:.4f}')\n",
    "    print(f'정밀도:{precision:.4f}') \n",
    "    print(f'재현율:{recall:.4f}') \n",
    "    print(f'F1:{F1:.4f}')\n",
    "    print(f'AUC:{AUC:.4f}') \n",
    "    \n",
    "get_clf_eval(y_val, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4ea8c-fbf9-4330-b9bf-2d891375b17b",
   "metadata": {},
   "source": [
    "#### 훈련 ver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666c163-e085-4b3f-84a4-49d803bcfa9d",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 20%\n",
    "- parameter\n",
    "    1. 'max_depth' : 6(default),\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    - max_depth 만 변경\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b40c8e62-9db0-481c-ad21-c21e921550ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 42), (3000, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2 , random_state= 42)\n",
    "\n",
    "# xgb.DMatrix(train_x,train_y)\n",
    "X_train.shape , y_train.shape\n",
    "X_val.shape , y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ae9a224-e439-4b86-92f1-d1576b65f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fce51ca-67b4-400e-abe8-843dc2e077c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68920\teval-logloss:0.69034\n",
      "[1]\ttrain-logloss:0.68532\teval-logloss:0.68764\n",
      "[2]\ttrain-logloss:0.68151\teval-logloss:0.68495\n",
      "[3]\ttrain-logloss:0.67780\teval-logloss:0.68236\n",
      "[4]\ttrain-logloss:0.67415\teval-logloss:0.67979\n",
      "[5]\ttrain-logloss:0.67060\teval-logloss:0.67729\n",
      "[6]\ttrain-logloss:0.66710\teval-logloss:0.67486\n",
      "[7]\ttrain-logloss:0.66367\teval-logloss:0.67249\n",
      "[8]\ttrain-logloss:0.66032\teval-logloss:0.67018\n",
      "[9]\ttrain-logloss:0.65700\teval-logloss:0.66794\n",
      "[10]\ttrain-logloss:0.65375\teval-logloss:0.66573\n",
      "[11]\ttrain-logloss:0.65056\teval-logloss:0.66356\n",
      "[12]\ttrain-logloss:0.64744\teval-logloss:0.66142\n",
      "[13]\ttrain-logloss:0.64439\teval-logloss:0.65937\n",
      "[14]\ttrain-logloss:0.64136\teval-logloss:0.65734\n",
      "[15]\ttrain-logloss:0.63841\teval-logloss:0.65535\n",
      "[16]\ttrain-logloss:0.63550\teval-logloss:0.65344\n",
      "[17]\ttrain-logloss:0.63263\teval-logloss:0.65151\n",
      "[18]\ttrain-logloss:0.62984\teval-logloss:0.64963\n",
      "[19]\ttrain-logloss:0.62706\teval-logloss:0.64780\n",
      "[20]\ttrain-logloss:0.62435\teval-logloss:0.64600\n",
      "[21]\ttrain-logloss:0.62170\teval-logloss:0.64422\n",
      "[22]\ttrain-logloss:0.61907\teval-logloss:0.64251\n",
      "[23]\ttrain-logloss:0.61650\teval-logloss:0.64084\n",
      "[24]\ttrain-logloss:0.61396\teval-logloss:0.63923\n",
      "[25]\ttrain-logloss:0.61147\teval-logloss:0.63760\n",
      "[26]\ttrain-logloss:0.60898\teval-logloss:0.63599\n",
      "[27]\ttrain-logloss:0.60654\teval-logloss:0.63446\n",
      "[28]\ttrain-logloss:0.60412\teval-logloss:0.63292\n",
      "[29]\ttrain-logloss:0.60175\teval-logloss:0.63140\n",
      "[30]\ttrain-logloss:0.59941\teval-logloss:0.62992\n",
      "[31]\ttrain-logloss:0.59711\teval-logloss:0.62847\n",
      "[32]\ttrain-logloss:0.59485\teval-logloss:0.62707\n",
      "[33]\ttrain-logloss:0.59262\teval-logloss:0.62575\n",
      "[34]\ttrain-logloss:0.59043\teval-logloss:0.62440\n",
      "[35]\ttrain-logloss:0.58827\teval-logloss:0.62314\n",
      "[36]\ttrain-logloss:0.58614\teval-logloss:0.62190\n",
      "[37]\ttrain-logloss:0.58407\teval-logloss:0.62064\n",
      "[38]\ttrain-logloss:0.58203\teval-logloss:0.61945\n",
      "[39]\ttrain-logloss:0.58001\teval-logloss:0.61825\n",
      "[40]\ttrain-logloss:0.57802\teval-logloss:0.61713\n",
      "[41]\ttrain-logloss:0.57606\teval-logloss:0.61598\n",
      "[42]\ttrain-logloss:0.57413\teval-logloss:0.61491\n",
      "[43]\ttrain-logloss:0.57223\teval-logloss:0.61381\n",
      "[44]\ttrain-logloss:0.57036\teval-logloss:0.61276\n",
      "[45]\ttrain-logloss:0.56852\teval-logloss:0.61171\n",
      "[46]\ttrain-logloss:0.56671\teval-logloss:0.61071\n",
      "[47]\ttrain-logloss:0.56490\teval-logloss:0.60971\n",
      "[48]\ttrain-logloss:0.56316\teval-logloss:0.60875\n",
      "[49]\ttrain-logloss:0.56142\teval-logloss:0.60780\n",
      "[50]\ttrain-logloss:0.55973\teval-logloss:0.60682\n",
      "[51]\ttrain-logloss:0.55797\teval-logloss:0.60581\n",
      "[52]\ttrain-logloss:0.55627\teval-logloss:0.60498\n",
      "[53]\ttrain-logloss:0.55465\teval-logloss:0.60413\n",
      "[54]\ttrain-logloss:0.55296\teval-logloss:0.60317\n",
      "[55]\ttrain-logloss:0.55132\teval-logloss:0.60228\n",
      "[56]\ttrain-logloss:0.54973\teval-logloss:0.60150\n",
      "[57]\ttrain-logloss:0.54818\teval-logloss:0.60073\n",
      "[58]\ttrain-logloss:0.54661\teval-logloss:0.59988\n",
      "[59]\ttrain-logloss:0.54504\teval-logloss:0.59903\n",
      "[60]\ttrain-logloss:0.54353\teval-logloss:0.59819\n",
      "[61]\ttrain-logloss:0.54200\teval-logloss:0.59741\n",
      "[62]\ttrain-logloss:0.54058\teval-logloss:0.59672\n",
      "[63]\ttrain-logloss:0.53910\teval-logloss:0.59592\n",
      "[64]\ttrain-logloss:0.53765\teval-logloss:0.59522\n",
      "[65]\ttrain-logloss:0.53627\teval-logloss:0.59455\n",
      "[66]\ttrain-logloss:0.53486\teval-logloss:0.59382\n",
      "[67]\ttrain-logloss:0.53348\teval-logloss:0.59310\n",
      "[68]\ttrain-logloss:0.53211\teval-logloss:0.59240\n",
      "[69]\ttrain-logloss:0.53077\teval-logloss:0.59179\n",
      "[70]\ttrain-logloss:0.52951\teval-logloss:0.59120\n",
      "[71]\ttrain-logloss:0.52820\teval-logloss:0.59053\n",
      "[72]\ttrain-logloss:0.52691\teval-logloss:0.58989\n",
      "[73]\ttrain-logloss:0.52565\teval-logloss:0.58924\n",
      "[74]\ttrain-logloss:0.52439\teval-logloss:0.58865\n",
      "[75]\ttrain-logloss:0.52316\teval-logloss:0.58809\n",
      "[76]\ttrain-logloss:0.52199\teval-logloss:0.58760\n",
      "[77]\ttrain-logloss:0.52079\teval-logloss:0.58703\n",
      "[78]\ttrain-logloss:0.51963\teval-logloss:0.58653\n",
      "[79]\ttrain-logloss:0.51845\teval-logloss:0.58594\n",
      "[80]\ttrain-logloss:0.51731\teval-logloss:0.58541\n",
      "[81]\ttrain-logloss:0.51617\teval-logloss:0.58487\n",
      "[82]\ttrain-logloss:0.51506\teval-logloss:0.58442\n",
      "[83]\ttrain-logloss:0.51393\teval-logloss:0.58393\n",
      "[84]\ttrain-logloss:0.51290\teval-logloss:0.58350\n",
      "[85]\ttrain-logloss:0.51180\teval-logloss:0.58308\n",
      "[86]\ttrain-logloss:0.51074\teval-logloss:0.58259\n",
      "[87]\ttrain-logloss:0.50974\teval-logloss:0.58217\n",
      "[88]\ttrain-logloss:0.50871\teval-logloss:0.58172\n",
      "[89]\ttrain-logloss:0.50768\teval-logloss:0.58134\n",
      "[90]\ttrain-logloss:0.50666\teval-logloss:0.58097\n",
      "[91]\ttrain-logloss:0.50567\teval-logloss:0.58059\n",
      "[92]\ttrain-logloss:0.50474\teval-logloss:0.58019\n",
      "[93]\ttrain-logloss:0.50377\teval-logloss:0.57979\n",
      "[94]\ttrain-logloss:0.50281\teval-logloss:0.57938\n",
      "[95]\ttrain-logloss:0.50186\teval-logloss:0.57905\n",
      "[96]\ttrain-logloss:0.50092\teval-logloss:0.57867\n",
      "[97]\ttrain-logloss:0.49999\teval-logloss:0.57834\n",
      "[98]\ttrain-logloss:0.49909\teval-logloss:0.57799\n",
      "[99]\ttrain-logloss:0.49819\teval-logloss:0.57766\n",
      "[100]\ttrain-logloss:0.49731\teval-logloss:0.57735\n",
      "[101]\ttrain-logloss:0.49644\teval-logloss:0.57703\n",
      "[102]\ttrain-logloss:0.49553\teval-logloss:0.57664\n",
      "[103]\ttrain-logloss:0.49467\teval-logloss:0.57631\n",
      "[104]\ttrain-logloss:0.49385\teval-logloss:0.57601\n",
      "[105]\ttrain-logloss:0.49297\teval-logloss:0.57564\n",
      "[106]\ttrain-logloss:0.49215\teval-logloss:0.57533\n",
      "[107]\ttrain-logloss:0.49130\teval-logloss:0.57503\n",
      "[108]\ttrain-logloss:0.49049\teval-logloss:0.57477\n",
      "[109]\ttrain-logloss:0.48965\teval-logloss:0.57443\n",
      "[110]\ttrain-logloss:0.48888\teval-logloss:0.57419\n",
      "[111]\ttrain-logloss:0.48813\teval-logloss:0.57393\n",
      "[112]\ttrain-logloss:0.48732\teval-logloss:0.57366\n",
      "[113]\ttrain-logloss:0.48656\teval-logloss:0.57344\n",
      "[114]\ttrain-logloss:0.48578\teval-logloss:0.57313\n",
      "[115]\ttrain-logloss:0.48506\teval-logloss:0.57289\n",
      "[116]\ttrain-logloss:0.48430\teval-logloss:0.57264\n",
      "[117]\ttrain-logloss:0.48358\teval-logloss:0.57241\n",
      "[118]\ttrain-logloss:0.48283\teval-logloss:0.57220\n",
      "[119]\ttrain-logloss:0.48213\teval-logloss:0.57198\n",
      "[120]\ttrain-logloss:0.48140\teval-logloss:0.57172\n",
      "[121]\ttrain-logloss:0.48073\teval-logloss:0.57153\n",
      "[122]\ttrain-logloss:0.48006\teval-logloss:0.57137\n",
      "[123]\ttrain-logloss:0.47937\teval-logloss:0.57122\n",
      "[124]\ttrain-logloss:0.47869\teval-logloss:0.57098\n",
      "[125]\ttrain-logloss:0.47804\teval-logloss:0.57076\n",
      "[126]\ttrain-logloss:0.47736\teval-logloss:0.57052\n",
      "[127]\ttrain-logloss:0.47673\teval-logloss:0.57036\n",
      "[128]\ttrain-logloss:0.47608\teval-logloss:0.57016\n",
      "[129]\ttrain-logloss:0.47540\teval-logloss:0.56998\n",
      "[130]\ttrain-logloss:0.47475\teval-logloss:0.56980\n",
      "[131]\ttrain-logloss:0.47409\teval-logloss:0.56961\n",
      "[132]\ttrain-logloss:0.47353\teval-logloss:0.56946\n",
      "[133]\ttrain-logloss:0.47293\teval-logloss:0.56929\n",
      "[134]\ttrain-logloss:0.47230\teval-logloss:0.56912\n",
      "[135]\ttrain-logloss:0.47167\teval-logloss:0.56896\n",
      "[136]\ttrain-logloss:0.47109\teval-logloss:0.56881\n",
      "[137]\ttrain-logloss:0.47046\teval-logloss:0.56866\n",
      "[138]\ttrain-logloss:0.46990\teval-logloss:0.56854\n",
      "[139]\ttrain-logloss:0.46934\teval-logloss:0.56842\n",
      "[140]\ttrain-logloss:0.46875\teval-logloss:0.56826\n",
      "[141]\ttrain-logloss:0.46818\teval-logloss:0.56813\n",
      "[142]\ttrain-logloss:0.46762\teval-logloss:0.56799\n",
      "[143]\ttrain-logloss:0.46708\teval-logloss:0.56790\n",
      "[144]\ttrain-logloss:0.46651\teval-logloss:0.56778\n",
      "[145]\ttrain-logloss:0.46596\teval-logloss:0.56767\n",
      "[146]\ttrain-logloss:0.46541\teval-logloss:0.56758\n",
      "[147]\ttrain-logloss:0.46490\teval-logloss:0.56751\n",
      "[148]\ttrain-logloss:0.46435\teval-logloss:0.56736\n",
      "[149]\ttrain-logloss:0.46383\teval-logloss:0.56728\n",
      "[150]\ttrain-logloss:0.46328\teval-logloss:0.56713\n",
      "[151]\ttrain-logloss:0.46277\teval-logloss:0.56705\n",
      "[152]\ttrain-logloss:0.46226\teval-logloss:0.56699\n",
      "[153]\ttrain-logloss:0.46172\teval-logloss:0.56685\n",
      "[154]\ttrain-logloss:0.46124\teval-logloss:0.56674\n",
      "[155]\ttrain-logloss:0.46071\teval-logloss:0.56666\n",
      "[156]\ttrain-logloss:0.46022\teval-logloss:0.56656\n",
      "[157]\ttrain-logloss:0.45972\teval-logloss:0.56645\n",
      "[158]\ttrain-logloss:0.45922\teval-logloss:0.56637\n",
      "[159]\ttrain-logloss:0.45875\teval-logloss:0.56631\n",
      "[160]\ttrain-logloss:0.45829\teval-logloss:0.56627\n",
      "[161]\ttrain-logloss:0.45785\teval-logloss:0.56614\n",
      "[162]\ttrain-logloss:0.45736\teval-logloss:0.56605\n",
      "[163]\ttrain-logloss:0.45694\teval-logloss:0.56600\n",
      "[164]\ttrain-logloss:0.45647\teval-logloss:0.56590\n",
      "[165]\ttrain-logloss:0.45599\teval-logloss:0.56580\n",
      "[166]\ttrain-logloss:0.45557\teval-logloss:0.56572\n",
      "[167]\ttrain-logloss:0.45513\teval-logloss:0.56569\n",
      "[168]\ttrain-logloss:0.45468\teval-logloss:0.56564\n",
      "[169]\ttrain-logloss:0.45424\teval-logloss:0.56559\n",
      "[170]\ttrain-logloss:0.45380\teval-logloss:0.56558\n",
      "[171]\ttrain-logloss:0.45337\teval-logloss:0.56551\n",
      "[172]\ttrain-logloss:0.45299\teval-logloss:0.56549\n",
      "[173]\ttrain-logloss:0.45257\teval-logloss:0.56545\n",
      "[174]\ttrain-logloss:0.45217\teval-logloss:0.56541\n",
      "[175]\ttrain-logloss:0.45174\teval-logloss:0.56533\n",
      "[176]\ttrain-logloss:0.45134\teval-logloss:0.56526\n",
      "[177]\ttrain-logloss:0.45091\teval-logloss:0.56524\n",
      "[178]\ttrain-logloss:0.45056\teval-logloss:0.56517\n",
      "[179]\ttrain-logloss:0.45016\teval-logloss:0.56515\n",
      "[180]\ttrain-logloss:0.44975\teval-logloss:0.56505\n",
      "[181]\ttrain-logloss:0.44936\teval-logloss:0.56502\n",
      "[182]\ttrain-logloss:0.44900\teval-logloss:0.56495\n",
      "[183]\ttrain-logloss:0.44863\teval-logloss:0.56492\n",
      "[184]\ttrain-logloss:0.44822\teval-logloss:0.56489\n",
      "[185]\ttrain-logloss:0.44784\teval-logloss:0.56487\n",
      "[186]\ttrain-logloss:0.44748\teval-logloss:0.56483\n",
      "[187]\ttrain-logloss:0.44714\teval-logloss:0.56478\n",
      "[188]\ttrain-logloss:0.44675\teval-logloss:0.56476\n",
      "[189]\ttrain-logloss:0.44640\teval-logloss:0.56474\n",
      "[190]\ttrain-logloss:0.44605\teval-logloss:0.56473\n",
      "[191]\ttrain-logloss:0.44569\teval-logloss:0.56467\n",
      "[192]\ttrain-logloss:0.44534\teval-logloss:0.56462\n",
      "[193]\ttrain-logloss:0.44495\teval-logloss:0.56460\n",
      "[194]\ttrain-logloss:0.44463\teval-logloss:0.56458\n",
      "[195]\ttrain-logloss:0.44431\teval-logloss:0.56453\n",
      "[196]\ttrain-logloss:0.44397\teval-logloss:0.56453\n",
      "[197]\ttrain-logloss:0.44365\teval-logloss:0.56448\n",
      "[198]\ttrain-logloss:0.44333\teval-logloss:0.56444\n",
      "[199]\ttrain-logloss:0.44298\teval-logloss:0.56443\n",
      "[200]\ttrain-logloss:0.44267\teval-logloss:0.56443\n",
      "[201]\ttrain-logloss:0.44237\teval-logloss:0.56443\n",
      "[202]\ttrain-logloss:0.44203\teval-logloss:0.56434\n",
      "[203]\ttrain-logloss:0.44172\teval-logloss:0.56433\n",
      "[204]\ttrain-logloss:0.44141\teval-logloss:0.56434\n",
      "[205]\ttrain-logloss:0.44110\teval-logloss:0.56431\n",
      "[206]\ttrain-logloss:0.44081\teval-logloss:0.56429\n",
      "[207]\ttrain-logloss:0.44048\teval-logloss:0.56424\n",
      "[208]\ttrain-logloss:0.44017\teval-logloss:0.56425\n",
      "[209]\ttrain-logloss:0.43985\teval-logloss:0.56420\n",
      "[210]\ttrain-logloss:0.43951\teval-logloss:0.56421\n",
      "[211]\ttrain-logloss:0.43923\teval-logloss:0.56420\n",
      "[212]\ttrain-logloss:0.43895\teval-logloss:0.56422\n",
      "[213]\ttrain-logloss:0.43869\teval-logloss:0.56420\n",
      "[214]\ttrain-logloss:0.43840\teval-logloss:0.56420\n",
      "[215]\ttrain-logloss:0.43812\teval-logloss:0.56420\n",
      "[216]\ttrain-logloss:0.43783\teval-logloss:0.56418\n",
      "[217]\ttrain-logloss:0.43756\teval-logloss:0.56418\n",
      "[218]\ttrain-logloss:0.43730\teval-logloss:0.56422\n",
      "[219]\ttrain-logloss:0.43703\teval-logloss:0.56420\n",
      "[220]\ttrain-logloss:0.43673\teval-logloss:0.56418\n",
      "[221]\ttrain-logloss:0.43648\teval-logloss:0.56418\n",
      "[222]\ttrain-logloss:0.43621\teval-logloss:0.56421\n",
      "[223]\ttrain-logloss:0.43594\teval-logloss:0.56424\n",
      "[224]\ttrain-logloss:0.43571\teval-logloss:0.56425\n",
      "[225]\ttrain-logloss:0.43547\teval-logloss:0.56424\n",
      "[226]\ttrain-logloss:0.43518\teval-logloss:0.56427\n",
      "[227]\ttrain-logloss:0.43495\teval-logloss:0.56431\n",
      "[228]\ttrain-logloss:0.43468\teval-logloss:0.56432\n",
      "[229]\ttrain-logloss:0.43446\teval-logloss:0.56431\n",
      "[230]\ttrain-logloss:0.43421\teval-logloss:0.56430\n",
      "[231]\ttrain-logloss:0.43391\teval-logloss:0.56428\n",
      "[232]\ttrain-logloss:0.43368\teval-logloss:0.56428\n",
      "[233]\ttrain-logloss:0.43345\teval-logloss:0.56431\n",
      "[234]\ttrain-logloss:0.43320\teval-logloss:0.56435\n",
      "[235]\ttrain-logloss:0.43293\teval-logloss:0.56432\n",
      "[236]\ttrain-logloss:0.43271\teval-logloss:0.56432\n",
      "[237]\ttrain-logloss:0.43245\teval-logloss:0.56433\n",
      "[238]\ttrain-logloss:0.43223\teval-logloss:0.56438\n",
      "[239]\ttrain-logloss:0.43197\teval-logloss:0.56435\n",
      "[240]\ttrain-logloss:0.43171\teval-logloss:0.56434\n",
      "[241]\ttrain-logloss:0.43148\teval-logloss:0.56433\n",
      "[242]\ttrain-logloss:0.43119\teval-logloss:0.56435\n",
      "[243]\ttrain-logloss:0.43098\teval-logloss:0.56432\n",
      "[244]\ttrain-logloss:0.43075\teval-logloss:0.56435\n",
      "[245]\ttrain-logloss:0.43051\teval-logloss:0.56432\n",
      "[246]\ttrain-logloss:0.43024\teval-logloss:0.56433\n",
      "[247]\ttrain-logloss:0.43004\teval-logloss:0.56433\n",
      "[248]\ttrain-logloss:0.42985\teval-logloss:0.56438\n",
      "[249]\ttrain-logloss:0.42961\teval-logloss:0.56442\n",
      "[250]\ttrain-logloss:0.42936\teval-logloss:0.56443\n",
      "[251]\ttrain-logloss:0.42916\teval-logloss:0.56442\n",
      "[252]\ttrain-logloss:0.42887\teval-logloss:0.56443\n",
      "[253]\ttrain-logloss:0.42866\teval-logloss:0.56446\n",
      "[254]\ttrain-logloss:0.42838\teval-logloss:0.56449\n",
      "[255]\ttrain-logloss:0.42817\teval-logloss:0.56453\n",
      "[256]\ttrain-logloss:0.42790\teval-logloss:0.56455\n",
      "[257]\ttrain-logloss:0.42771\teval-logloss:0.56460\n",
      "[258]\ttrain-logloss:0.42744\teval-logloss:0.56464\n",
      "[259]\ttrain-logloss:0.42715\teval-logloss:0.56464\n",
      "[260]\ttrain-logloss:0.42696\teval-logloss:0.56469\n",
      "[261]\ttrain-logloss:0.42673\teval-logloss:0.56469\n",
      "[262]\ttrain-logloss:0.42647\teval-logloss:0.56473\n",
      "[263]\ttrain-logloss:0.42629\teval-logloss:0.56469\n",
      "[264]\ttrain-logloss:0.42604\teval-logloss:0.56471\n",
      "[265]\ttrain-logloss:0.42576\teval-logloss:0.56475\n",
      "[266]\ttrain-logloss:0.42550\teval-logloss:0.56477\n",
      "[267]\ttrain-logloss:0.42520\teval-logloss:0.56479\n",
      "[268]\ttrain-logloss:0.42495\teval-logloss:0.56480\n",
      "[269]\ttrain-logloss:0.42467\teval-logloss:0.56480\n",
      "[270]\ttrain-logloss:0.42440\teval-logloss:0.56483\n",
      "[271]\ttrain-logloss:0.42411\teval-logloss:0.56484\n",
      "[272]\ttrain-logloss:0.42387\teval-logloss:0.56486\n",
      "[273]\ttrain-logloss:0.42369\teval-logloss:0.56489\n",
      "[274]\ttrain-logloss:0.42343\teval-logloss:0.56491\n",
      "[275]\ttrain-logloss:0.42314\teval-logloss:0.56493\n",
      "[276]\ttrain-logloss:0.42291\teval-logloss:0.56493\n",
      "[277]\ttrain-logloss:0.42271\teval-logloss:0.56490\n",
      "[278]\ttrain-logloss:0.42246\teval-logloss:0.56493\n",
      "[279]\ttrain-logloss:0.42219\teval-logloss:0.56492\n",
      "[280]\ttrain-logloss:0.42195\teval-logloss:0.56494\n",
      "[281]\ttrain-logloss:0.42172\teval-logloss:0.56495\n",
      "[282]\ttrain-logloss:0.42145\teval-logloss:0.56498\n",
      "[283]\ttrain-logloss:0.42123\teval-logloss:0.56498\n",
      "[284]\ttrain-logloss:0.42101\teval-logloss:0.56500\n",
      "[285]\ttrain-logloss:0.42077\teval-logloss:0.56502\n",
      "[286]\ttrain-logloss:0.42055\teval-logloss:0.56499\n",
      "[287]\ttrain-logloss:0.42033\teval-logloss:0.56499\n",
      "[288]\ttrain-logloss:0.42012\teval-logloss:0.56497\n",
      "[289]\ttrain-logloss:0.41986\teval-logloss:0.56496\n",
      "[290]\ttrain-logloss:0.41965\teval-logloss:0.56498\n",
      "[291]\ttrain-logloss:0.41939\teval-logloss:0.56496\n",
      "[292]\ttrain-logloss:0.41913\teval-logloss:0.56497\n",
      "[293]\ttrain-logloss:0.41895\teval-logloss:0.56497\n",
      "[294]\ttrain-logloss:0.41876\teval-logloss:0.56498\n",
      "[295]\ttrain-logloss:0.41852\teval-logloss:0.56498\n",
      "[296]\ttrain-logloss:0.41833\teval-logloss:0.56501\n",
      "[297]\ttrain-logloss:0.41810\teval-logloss:0.56502\n",
      "[298]\ttrain-logloss:0.41785\teval-logloss:0.56508\n",
      "[299]\ttrain-logloss:0.41766\teval-logloss:0.56511\n",
      "[300]\ttrain-logloss:0.41748\teval-logloss:0.56512\n",
      "[301]\ttrain-logloss:0.41725\teval-logloss:0.56513\n",
      "[302]\ttrain-logloss:0.41701\teval-logloss:0.56519\n",
      "[303]\ttrain-logloss:0.41684\teval-logloss:0.56523\n",
      "[304]\ttrain-logloss:0.41662\teval-logloss:0.56520\n",
      "[305]\ttrain-logloss:0.41641\teval-logloss:0.56520\n",
      "[306]\ttrain-logloss:0.41617\teval-logloss:0.56525\n",
      "[307]\ttrain-logloss:0.41598\teval-logloss:0.56524\n",
      "[308]\ttrain-logloss:0.41578\teval-logloss:0.56527\n",
      "[309]\ttrain-logloss:0.41556\teval-logloss:0.56527\n",
      "[310]\ttrain-logloss:0.41533\teval-logloss:0.56534\n",
      "[311]\ttrain-logloss:0.41512\teval-logloss:0.56537\n",
      "[312]\ttrain-logloss:0.41490\teval-logloss:0.56542\n",
      "[313]\ttrain-logloss:0.41473\teval-logloss:0.56543\n",
      "[314]\ttrain-logloss:0.41451\teval-logloss:0.56549\n",
      "[315]\ttrain-logloss:0.41431\teval-logloss:0.56549\n",
      "[316]\ttrain-logloss:0.41407\teval-logloss:0.56546\n",
      "[317]\ttrain-logloss:0.41389\teval-logloss:0.56547\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'logloss',\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4768ea64-6862-4e68-b815-e8dade13fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7422670-8329-446e-8e6d-c5ac7b294139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[1555   78]\n",
      " [ 790  577]]\n",
      "\n",
      "정확도: 0.7107\n",
      "정밀도: 0.8809\n",
      "재현율: 0.4221\n",
      "F1: 0.5707\n",
      "AUC: 0.6872\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ffd70-2c17-4a4c-8cca-557d84fb75b7",
   "metadata": {},
   "source": [
    "#### 훈련 ver 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de652f0-81ea-4213-9a24-7c1753629480",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 20%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'err'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    - eval_metric 만 변경\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72f8b9a1-da01-4463-bfcb-81b7efa47021",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.22125\teval-error:0.31733\n",
      "[1]\ttrain-error:0.22108\teval-error:0.31967\n",
      "[2]\ttrain-error:0.22058\teval-error:0.31867\n",
      "[3]\ttrain-error:0.22058\teval-error:0.31867\n",
      "[4]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[5]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[6]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[7]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[8]\ttrain-error:0.21917\teval-error:0.31600\n",
      "[9]\ttrain-error:0.21917\teval-error:0.31600\n",
      "[10]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[11]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[12]\ttrain-error:0.22042\teval-error:0.31933\n",
      "[13]\ttrain-error:0.22042\teval-error:0.31933\n",
      "[14]\ttrain-error:0.22042\teval-error:0.32000\n",
      "[15]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[16]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[17]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[18]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[19]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[20]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[21]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[22]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[23]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[24]\ttrain-error:0.22117\teval-error:0.31700\n",
      "[25]\ttrain-error:0.22033\teval-error:0.31533\n",
      "[26]\ttrain-error:0.22042\teval-error:0.31600\n",
      "[27]\ttrain-error:0.22042\teval-error:0.31600\n",
      "[28]\ttrain-error:0.22033\teval-error:0.31533\n",
      "[29]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[30]\ttrain-error:0.22008\teval-error:0.31500\n",
      "[31]\ttrain-error:0.22008\teval-error:0.31500\n",
      "[32]\ttrain-error:0.22033\teval-error:0.31533\n",
      "[33]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[34]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[35]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[36]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[37]\ttrain-error:0.22008\teval-error:0.31500\n",
      "[38]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[39]\ttrain-error:0.21983\teval-error:0.31467\n",
      "[40]\ttrain-error:0.22192\teval-error:0.32067\n",
      "[41]\ttrain-error:0.22208\teval-error:0.32067\n",
      "[42]\ttrain-error:0.22183\teval-error:0.32033\n",
      "[43]\ttrain-error:0.21917\teval-error:0.31767\n",
      "[44]\ttrain-error:0.22075\teval-error:0.32100\n",
      "[45]\ttrain-error:0.21925\teval-error:0.31800\n",
      "[46]\ttrain-error:0.21917\teval-error:0.31767\n",
      "[47]\ttrain-error:0.21900\teval-error:0.31800\n",
      "[48]\ttrain-error:0.22058\teval-error:0.32167\n",
      "[49]\ttrain-error:0.22067\teval-error:0.32067\n",
      "[50]\ttrain-error:0.21892\teval-error:0.31900\n",
      "[51]\ttrain-error:0.22075\teval-error:0.32167\n",
      "[52]\ttrain-error:0.21908\teval-error:0.31867\n",
      "[53]\ttrain-error:0.21917\teval-error:0.32000\n",
      "[54]\ttrain-error:0.22075\teval-error:0.32167\n",
      "[55]\ttrain-error:0.21917\teval-error:0.32000\n",
      "[56]\ttrain-error:0.21925\teval-error:0.31967\n",
      "[57]\ttrain-error:0.21933\teval-error:0.32033\n",
      "[58]\ttrain-error:0.21908\teval-error:0.32000\n",
      "[59]\ttrain-error:0.21908\teval-error:0.32067\n",
      "[60]\ttrain-error:0.21908\teval-error:0.32000\n",
      "[61]\ttrain-error:0.21975\teval-error:0.32167\n",
      "[62]\ttrain-error:0.21975\teval-error:0.32167\n",
      "[63]\ttrain-error:0.21917\teval-error:0.32000\n",
      "[64]\ttrain-error:0.21983\teval-error:0.32133\n",
      "[65]\ttrain-error:0.21975\teval-error:0.32167\n",
      "[66]\ttrain-error:0.21992\teval-error:0.32100\n",
      "[67]\ttrain-error:0.21983\teval-error:0.32067\n",
      "[68]\ttrain-error:0.21958\teval-error:0.32100\n",
      "[69]\ttrain-error:0.21983\teval-error:0.32100\n",
      "[70]\ttrain-error:0.21950\teval-error:0.32167\n",
      "[71]\ttrain-error:0.21983\teval-error:0.32133\n",
      "[72]\ttrain-error:0.21958\teval-error:0.32167\n",
      "[73]\ttrain-error:0.21950\teval-error:0.32167\n",
      "[74]\ttrain-error:0.21925\teval-error:0.32267\n",
      "[75]\ttrain-error:0.21933\teval-error:0.32233\n",
      "[76]\ttrain-error:0.21942\teval-error:0.32233\n",
      "[77]\ttrain-error:0.21967\teval-error:0.32333\n",
      "[78]\ttrain-error:0.21975\teval-error:0.32333\n",
      "[79]\ttrain-error:0.21967\teval-error:0.32333\n",
      "[80]\ttrain-error:0.21950\teval-error:0.32300\n",
      "[81]\ttrain-error:0.21958\teval-error:0.32333\n",
      "[82]\ttrain-error:0.21942\teval-error:0.32267\n",
      "[83]\ttrain-error:0.21942\teval-error:0.32233\n",
      "[84]\ttrain-error:0.21950\teval-error:0.32200\n",
      "[85]\ttrain-error:0.21950\teval-error:0.32200\n",
      "[86]\ttrain-error:0.21958\teval-error:0.32267\n",
      "[87]\ttrain-error:0.21950\teval-error:0.32267\n",
      "[88]\ttrain-error:0.21950\teval-error:0.32267\n",
      "[89]\ttrain-error:0.21908\teval-error:0.32233\n",
      "[90]\ttrain-error:0.21900\teval-error:0.32300\n",
      "[91]\ttrain-error:0.21917\teval-error:0.32300\n",
      "[92]\ttrain-error:0.21908\teval-error:0.32267\n",
      "[93]\ttrain-error:0.21892\teval-error:0.32267\n",
      "[94]\ttrain-error:0.21900\teval-error:0.32300\n",
      "[95]\ttrain-error:0.21917\teval-error:0.32300\n",
      "[96]\ttrain-error:0.21908\teval-error:0.32267\n",
      "[97]\ttrain-error:0.21908\teval-error:0.32333\n",
      "[98]\ttrain-error:0.21917\teval-error:0.32333\n",
      "[99]\ttrain-error:0.21917\teval-error:0.32233\n",
      "[100]\ttrain-error:0.21933\teval-error:0.32233\n",
      "[101]\ttrain-error:0.21925\teval-error:0.32200\n",
      "[102]\ttrain-error:0.21900\teval-error:0.32200\n",
      "[103]\ttrain-error:0.21900\teval-error:0.32200\n",
      "[104]\ttrain-error:0.21908\teval-error:0.32233\n",
      "[105]\ttrain-error:0.21883\teval-error:0.32167\n",
      "[106]\ttrain-error:0.21883\teval-error:0.32233\n",
      "[107]\ttrain-error:0.21875\teval-error:0.32167\n",
      "[108]\ttrain-error:0.21892\teval-error:0.32167\n",
      "[109]\ttrain-error:0.21892\teval-error:0.32167\n",
      "[110]\ttrain-error:0.21908\teval-error:0.32167\n",
      "[111]\ttrain-error:0.21892\teval-error:0.32167\n",
      "[112]\ttrain-error:0.21900\teval-error:0.32167\n",
      "[113]\ttrain-error:0.21908\teval-error:0.32167\n",
      "[114]\ttrain-error:0.21883\teval-error:0.32167\n",
      "[115]\ttrain-error:0.21883\teval-error:0.32167\n",
      "[116]\ttrain-error:0.21867\teval-error:0.32200\n",
      "오차행렬:\n",
      " [[1580   53]\n",
      " [ 913  454]]\n",
      "\n",
      "정확도: 0.6780\n",
      "정밀도: 0.8955\n",
      "재현율: 0.3321\n",
      "F1: 0.4845\n",
      "AUC: 0.6498\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2 , random_state= 42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)\n",
    "\n",
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'error',\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=100)\n",
    "\n",
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1db01-8656-46ab-9fd4-ef4277b44b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 훈련 ver 5\n",
    "\n",
    "- train_test_split 의 test_size를 30%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'err'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    - eval_metric -> error , val_data = 30%\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceedf2d6-c587-404b-904d-e00ac098deea",
   "metadata": {},
   "source": [
    "#### 훈련 ver 6\n",
    "\n",
    "- train_test_split 의 test_size를 30%\n",
    "- parameter\n",
    "    1. 'max_depth' : 5,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d3c43-40d0-461f-a17e-c97b707b9292",
   "metadata": {},
   "source": [
    "분할 기준 \n",
    "\n",
    "한번 분기 마다 변수 영역을 두 개로 구분하는 모델\n",
    "\n",
    "분류나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가 , 불순도(impurity) 혹은 불확실성(uncertainty) 이 최대한 감소하도록 하는 방향으로 학습을 진행한다. 순도가 증가/ 불확실성이 감소하는 두고 정보 이론에서는\n",
    "\n",
    "정보 획득(information gain) 이라고 한다.\n",
    "\n",
    "데이터가 균일한 정도를 나타내는 지표 , 즉 순도를 계산하는 3가지 방식 \n",
    "\n",
    "엔트로피 감소 (= 불확실성 감소=  순도증가 =정보획득)\n",
    "\n",
    "분할 한것이 분할 전보다 낫다는 판단 하에 데이터를 두 개의 부분집합으로 나누게 된다.\n",
    "\n",
    "의사결정나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가/ 불확실성(엔트로피)가 최대한 감소하도록 하는 방향으로 학습을 진행합니다.\n",
    "\n",
    "**순도와 관련해 부연설명을 드리면 A 영역에 속한 모든 레코드가 동일한 범주에 속할 경우(=불확실성 최소=순도 최대) 엔트로피는 0입니다.** \n",
    "\n",
    "**반대로 범주가 둘뿐이고 해당 개체의 수가 동일하게 반반씩 섞여 있을 경우(=불확실성 최대=순도 최소) 엔트로피는 1의 값을 갖습니다. 엔트로피 외에 불순도 지표로 많이 쓰이는 지니계수(Gini Index) 공식은 아래와 같습니다.**\n",
    "\n",
    "**이 예시에서 terminal node는 C,D, E 세 개 인데요, 이를 데이터 공간과 연관지어 생각해보면 전체 데이터 A가 세 개의 부분집합으로 분할된 것 또한 알 수 있습니다.**\n",
    "\n",
    " **D 특성을 갖고 있는 새로운 데이터가 주어졌을 때 의사결정나무는 D 집합을 대표할 수 있는 값(분류=최빈값, 회귀=평균)을 반환하는 방식으로 예측합니다.**\n",
    "\n",
    "분기 지점을 두번째 레코드로 두고 처음 두 개 레코드와 나머지 22개 레코드 간의 엔트로피를 계산한 뒤 정보획득을 알아봅니다. 이렇게 순차적으로 계산한 뒤, 이번엔\n",
    "다른 변수인 소득을 기준으로 정렬하고 다시 같은 작업을 반복합니다. 모든 경우의 수 가운데 정보획득이 가장 큰 변수와 그 지점을\n",
    "택해 첫번째 분기를 하게 됩니다. 이후 또 같은 작업을 반복해 두번째, 세번째… 이렇게 분기를 계속 해 나가는 과정이 바로\n",
    "의사결정나무의 학습입니다.그렇다면 1회 분기를 위해 계산해야 하는 경우의 수는 총 몇 번일까요? 개체가 *𝑛*개, 변수가 *𝑑*개라고 할 때 경우의 수는 *𝑑*(*𝑛*−1) 개가 됩니다. 분기를 하지 않는 경우를 제외하고 모든 개체와 변수를 고려해 보는 것입니다.\n",
    "\n",
    "**의사결정나무는 결정경계(decision boundary)가 데이터 축에 수직이어서 특정 데이터에만 잘 작동할 가능성이 높습니다.**\n",
    "\n",
    "- 보팅과 배깅은 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식인데, 차이점은 보팅은 서로 다른 알고리즘을 가진 분류기를 결합하는 것이고, 배깅은 각각의 분류기가 모두 같은 유형의 알고리즘 기반이지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 보팅을 수행한다. 대표적인 배깅은 랜덤 포레스트 알고리즘이다.\n",
    "    부스팅은 여러 개의 분류기가 순차적으로 학습을 수행하되, 예측이 틀린 데이터에 대해 올바르게 예측하도록 가중치를 부여하면서 학습과 예측을 진행하는 것이다.\n",
    "- 보팅 - Hard vs Soft\n",
    "\n",
    "    하드 보팅(Hard Voting)은 다수결 원칙과 유사하다. 즉, 예측한 결괏값들중 다수의 분류기가 결정한 예측값을 최종 보팅 결괏값으로 선정한다.\n",
    "    소프트 보팅(Soft Voting)은 분류기들의 레이블 값 결정 확률을 모두 더해 이를 평균내서 확률이 가장 높은 레이블 값을 최종 보팅 결괏값을 선정한다\n",
    "- XGBoost site : https://injo.tistory.com/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748e3598-48ee-4c31-b6db-7d17498d40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/'\n",
    "train_X = pd.read_csv(PATH+'train_X.csv')\n",
    "train_y = pd.read_csv(PATH+'label.csv')\n",
    "# test_X = pd.read_csv(PATH+'test_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba768b1-dd47-439b-abb6-1e8496213950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[2893  163]\n",
      " [ 802  642]]\n",
      "\n",
      "정확도: 0.7856\n",
      "정밀도: 0.7975\n",
      "재현율: 0.4446\n",
      "F1: 0.5709\n",
      "AUC: 0.6956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmax_depth = 5\\n오차행렬:\\n [[2888  168]\\n [ 797  647]] \\n\\n정확도: 0.7856\\n정밀도: 0.7939\\n재현율: 0.4481\\nF1: 0.5728\\nAUC: 0.6965\\n\\nmax_depth = 4\\n오차행렬:\\n [[2891  165]\\n [ 829  615]]\\n\\n정확도: 0.7791\\n정밀도: 0.7885\\n재현율: 0.4259\\nF1: 0.5531\\nAUC: 0.6860\\n\\nmax_depth= 6\\n\\n오차행렬:\\n [[2874  182]\\n [ 799  645]]\\n\\n정확도: 0.7820\\n정밀도: 0.7799\\n재현율: 0.4467\\nF1: 0.5680\\nAUC: 0.6936\\n\\nmax_depth =5 , early_stopping_rounds=10\\n\\n오차행렬:\\n [[2893  163]\\n [ 802  642]]\\n\\n정확도: 0.7856\\n정밀도: 0.7975\\n재현율: 0.4446\\nF1: 0.5709\\nAUC: 0.6956\\n\\n\\nmax_depth =5 , num_rounds = 500\\n\\n오차행렬:\\n [[2886  170]\\n [ 794  650]]\\n\\n정확도: 0.7858\\n정밀도: 0.7927\\n재현율: 0.4501\\nF1: 0.5742\\nAUC: 0.6973\\n\\nmax_depth =5 , num_rounds = 1000\\n\\n오차행렬:\\n [[2886  170]\\n [ 794  650]]\\n\\n정확도: 0.7858\\n정밀도: 0.7927\\n재현율: 0.4501\\nF1: 0.5742\\nAUC: 0.6973\\n\\nmax_depth =5 , num_rounds = 1000 early_stopping_rounds=10\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)\n",
    "\n",
    "params = {\n",
    "    'max_depth':5,\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'logloss',\n",
    "}\n",
    "num_rounds = 1000\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=10,verbose_eval= 0)\n",
    "\n",
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)\n",
    "'''\n",
    "max_depth = 5\n",
    "오차행렬:\n",
    " [[2888  168]\n",
    " [ 797  647]] \n",
    "\n",
    "정확도: 0.7856\n",
    "정밀도: 0.7939\n",
    "재현율: 0.4481\n",
    "F1: 0.5728\n",
    "AUC: 0.6965\n",
    "\n",
    "max_depth = 4\n",
    "오차행렬:\n",
    " [[2891  165]\n",
    " [ 829  615]]\n",
    "\n",
    "정확도: 0.7791\n",
    "정밀도: 0.7885\n",
    "재현율: 0.4259\n",
    "F1: 0.5531\n",
    "AUC: 0.6860\n",
    "\n",
    "max_depth= 6\n",
    "\n",
    "오차행렬:\n",
    " [[2874  182]\n",
    " [ 799  645]]\n",
    "\n",
    "정확도: 0.7820\n",
    "정밀도: 0.7799\n",
    "재현율: 0.4467\n",
    "F1: 0.5680\n",
    "AUC: 0.6936\n",
    "\n",
    "max_depth =5 , early_stopping_rounds=10\n",
    "\n",
    "오차행렬:\n",
    " [[2893  163]\n",
    " [ 802  642]]\n",
    "\n",
    "정확도: 0.7856\n",
    "정밀도: 0.7975\n",
    "재현율: 0.4446\n",
    "F1: 0.5709\n",
    "AUC: 0.6956\n",
    "\n",
    "\n",
    "max_depth =5 , num_rounds = 500\n",
    "\n",
    "오차행렬:\n",
    " [[2886  170]\n",
    " [ 794  650]]\n",
    "\n",
    "정확도: 0.7858\n",
    "정밀도: 0.7927\n",
    "재현율: 0.4501\n",
    "F1: 0.5742\n",
    "AUC: 0.6973\n",
    "\n",
    "max_depth =5 , num_rounds = 1000\n",
    "\n",
    "오차행렬:\n",
    " [[2886  170]\n",
    " [ 794  650]]\n",
    "\n",
    "정확도: 0.7858\n",
    "정밀도: 0.7927\n",
    "재현율: 0.4501\n",
    "F1: 0.5742\n",
    "AUC: 0.6973\n",
    "\n",
    "max_depth =5 , num_rounds = 1000 early_stopping_rounds=10\n",
    "\n",
    "오차행렬:\n",
    " [[2893  163]\n",
    " [ 802  642]]\n",
    "\n",
    "정확도: 0.7856\n",
    "정밀도: 0.7975\n",
    "재현율: 0.4446\n",
    "F1: 0.5709\n",
    "AUC: 0.6956\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3e7bf68-93eb-418a-9a63-2805a93b3ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[2902  154]\n",
      " [ 854  590]]\n",
      "\n",
      "정확도: 0.7760\n",
      "정밀도: 0.7930\n",
      "재현율: 0.4086\n",
      "F1: 0.5393\n",
      "AUC: 0.6791\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)\n",
    "\n",
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'error',\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=100, verbose_eval=0)\n",
    "\n",
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf63a5-c80a-4c2c-b9c4-ef404727022f",
   "metadata": {},
   "source": [
    "### 교차검증 점수 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb2e2b-3098-4784-a03d-1f6e777302ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a8ecaaa-a039-4b9b-a2b6-9d7d80bbf1ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Test & measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dea7474-5cf4-4ad0-a148-7d27bbe724d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시된다\n",
      "[0.353 0.192 0.623 0.42  0.161 0.759 0.553 0.268 0.374 0.129]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(d_val)\n",
    "# pred_probs = xgb_model.predict(d_test)\n",
    "print('predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시된다')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "\n",
    "# 예측 확률이 0.5보다 크면 1 , 그렇지 않으면 0으로 예측값 결정해 리스트 객체인 preds에 저장\n",
    "# 라벨이 1일 확률이네 그러면\n",
    "preds = np.where(pred_probs > 0.5, 1, 0) \n",
    "# len(preds)\n",
    "# y_val = np.array(y_val)\n",
    "# preds.dtype\n",
    "preds\n",
    "# y_val = y_val.reshape(-1).astype('int64')\n",
    "# pd.Series(y_val).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d8c9087-85de-4e77-934e-5a16001e8fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[1569   64]\n",
      " [ 845  522]]\n",
      "\n",
      "정확도:: 0.6970\n",
      "정밀도: 0.8908\n",
      "재현율: 0.3819\n",
      "F1: 0.5346\n",
      "AUC: 0.6713\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print(f'\\n정확도:: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "get_clf_eval(y_val, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe26ee-c8f1-4a16-9a6f-1e8eff070dab",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Feature importance를 시각화할 때,\n",
    "- 기본 평가 지료로 f1스코어를 기반으로 각 feature의 중요도를 나타냅니다.\n",
    "- 사이킷런 래퍼는 estimator 객체의 featureimportances 속성을 이용해 시각화 코드를 직접 작성해야 합니다.\n",
    "- 반면, 파이썬 래퍼는 plot_importance()를 이용해 바로 피처 중요 코드를 시각화 할 수 있습니다.\n",
    "\n",
    "\n",
    "    - 다만, xgboost 넘파이 기반의 피처 데이터로 학습 시에 피처명을 제대로 알 수 없으므로\n",
    "      피처별로 f자 뒤에 순서를 붙여 X축에 피처들로 나열합니다.(f0는 첫번째 피처, f1는 두번째 피처를 의미)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5af98b31-7573-4b40-9e39-349f35e5ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(figsize = (10,12))\n",
    "plot_importance(xgb_model, ax=ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca2e0c-5b78-49aa-9e2c-03744ec72cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475e7eb-c424-4331-80d0-b8a023f57762",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 제출 파일 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053ef7b7-a991-48d2-aa05-ce661dce33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5bbc95-935b-499d-b461-01545c1e6fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 16532648/16532648 [00:15<00:00, 1079829.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_error = test_err[['user_id','errtype']].values\n",
    "test_x = np.zeros((test_user_number,42))\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "    test_x[person_idx - test_user_id_min,err - 1] += 1\n",
    "test_x = test_x.reshape(test_x.shape[0],-1)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128d42f-9c73-4733-a4fb-489a6e8681b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_x)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b40c03-b58d-4c64-8692-43e6351f6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c87b82-cc2b-4ede-9b1f-71e897113626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submssion = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"../data/dacon_baseline.csv\", index = False)\n",
    "sample_submssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a3aa7-16be-41eb-83f6-1c6ff6195f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
