{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f549d5ea-fcc0-4ce1-a3d6-50286e151b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "PATH = '/Users/krc/Desktop/project/system_quality_project/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3bfe0c-faee-494e-8cc4-ee4db7b0fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 16554663/16554663 [00:14<00:00, 1130080.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_45596_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45596\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_45596_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_45596_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_45596_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_45596_row0_col1\" class=\"data row0 col1\" >6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_45596_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_45596_row1_col1\" class=\"data row1 col1\" >problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_45596_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_45596_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_45596_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_45596_row3_col1\" class=\"data row3 col1\" >(15000, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_45596_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_45596_row4_col1\" class=\"data row4 col1\" >(15000, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_45596_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_45596_row5_col1\" class=\"data row5 col1\" >(10499, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_45596_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_45596_row6_col1\" class=\"data row6 col1\" >(4501, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_45596_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_45596_row7_col1\" class=\"data row7 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_45596_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_45596_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_45596_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_45596_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_45596_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_45596_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_45596_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_45596_row11_col1\" class=\"data row11 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_45596_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_45596_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_45596_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_45596_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_45596_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_45596_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_45596_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_45596_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_45596_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_45596_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_45596_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_45596_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45596_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_45596_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_45596_row18_col1\" class=\"data row18 col1\" >d036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28cbc3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_err = pd.read_csv(PATH + 'train_err_data.csv')\n",
    "id_error = train_err[['user_id','errtype']].values\n",
    "error = np.zeros((15000,42))\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    error[person_idx - 10000,err - 1] += 1\n",
    "\n",
    "train_prob = pd.read_csv(PATH + 'train_problem_data.csv')\n",
    "problem = np.zeros(15000)\n",
    "problem[train_prob.user_id.unique()-10000] = 1\n",
    "\n",
    "train = pd.DataFrame(data=error)\n",
    "train['problem'] = problem\n",
    "del error,problem\n",
    "\n",
    "clf = setup(data = train, target='problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7a9b29-221b-40d7-a158-86e47d0cfe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a169d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a169d_row0_col0, #T_a169d_row0_col2, #T_a169d_row0_col3, #T_a169d_row0_col4, #T_a169d_row1_col0, #T_a169d_row1_col1, #T_a169d_row1_col3, #T_a169d_row1_col4, #T_a169d_row1_col5, #T_a169d_row1_col6, #T_a169d_row1_col7, #T_a169d_row2_col0, #T_a169d_row2_col1, #T_a169d_row2_col2, #T_a169d_row2_col3, #T_a169d_row2_col4, #T_a169d_row2_col5, #T_a169d_row2_col6, #T_a169d_row2_col7, #T_a169d_row3_col0, #T_a169d_row3_col1, #T_a169d_row3_col2, #T_a169d_row3_col3, #T_a169d_row3_col4, #T_a169d_row3_col5, #T_a169d_row3_col6, #T_a169d_row3_col7, #T_a169d_row4_col0, #T_a169d_row4_col1, #T_a169d_row4_col2, #T_a169d_row4_col3, #T_a169d_row4_col4, #T_a169d_row4_col5, #T_a169d_row4_col6, #T_a169d_row4_col7, #T_a169d_row5_col0, #T_a169d_row5_col1, #T_a169d_row5_col2, #T_a169d_row5_col3, #T_a169d_row5_col4, #T_a169d_row5_col5, #T_a169d_row5_col6, #T_a169d_row5_col7, #T_a169d_row6_col0, #T_a169d_row6_col1, #T_a169d_row6_col2, #T_a169d_row6_col3, #T_a169d_row6_col4, #T_a169d_row6_col5, #T_a169d_row6_col6, #T_a169d_row6_col7, #T_a169d_row7_col0, #T_a169d_row7_col1, #T_a169d_row7_col2, #T_a169d_row7_col3, #T_a169d_row7_col4, #T_a169d_row7_col5, #T_a169d_row7_col6, #T_a169d_row7_col7, #T_a169d_row8_col0, #T_a169d_row8_col1, #T_a169d_row8_col2, #T_a169d_row8_col3, #T_a169d_row8_col5, #T_a169d_row8_col6, #T_a169d_row8_col7, #T_a169d_row9_col0, #T_a169d_row9_col1, #T_a169d_row9_col2, #T_a169d_row9_col3, #T_a169d_row9_col4, #T_a169d_row9_col5, #T_a169d_row9_col6, #T_a169d_row9_col7, #T_a169d_row10_col0, #T_a169d_row10_col1, #T_a169d_row10_col2, #T_a169d_row10_col4, #T_a169d_row10_col5, #T_a169d_row10_col6, #T_a169d_row10_col7, #T_a169d_row11_col0, #T_a169d_row11_col1, #T_a169d_row11_col2, #T_a169d_row11_col3, #T_a169d_row11_col4, #T_a169d_row11_col5, #T_a169d_row11_col6, #T_a169d_row11_col7, #T_a169d_row12_col0, #T_a169d_row12_col1, #T_a169d_row12_col2, #T_a169d_row12_col3, #T_a169d_row12_col4, #T_a169d_row12_col5, #T_a169d_row12_col6, #T_a169d_row12_col7, #T_a169d_row13_col0, #T_a169d_row13_col1, #T_a169d_row13_col2, #T_a169d_row13_col3, #T_a169d_row13_col4, #T_a169d_row13_col5, #T_a169d_row13_col6, #T_a169d_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a169d_row0_col1, #T_a169d_row0_col5, #T_a169d_row0_col6, #T_a169d_row0_col7, #T_a169d_row1_col2, #T_a169d_row8_col4, #T_a169d_row10_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_a169d_row0_col8, #T_a169d_row1_col8, #T_a169d_row2_col8, #T_a169d_row3_col8, #T_a169d_row4_col8, #T_a169d_row5_col8, #T_a169d_row6_col8, #T_a169d_row7_col8, #T_a169d_row8_col8, #T_a169d_row10_col8, #T_a169d_row11_col8, #T_a169d_row12_col8, #T_a169d_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_a169d_row9_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a169d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a169d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a169d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_a169d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_a169d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_a169d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_a169d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_a169d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_a169d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_a169d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_a169d_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_a169d_row0_col1\" class=\"data row0 col1\" >0.7786</td>\n",
       "      <td id=\"T_a169d_row0_col2\" class=\"data row0 col2\" >0.8006</td>\n",
       "      <td id=\"T_a169d_row0_col3\" class=\"data row0 col3\" >0.4951</td>\n",
       "      <td id=\"T_a169d_row0_col4\" class=\"data row0 col4\" >0.7564</td>\n",
       "      <td id=\"T_a169d_row0_col5\" class=\"data row0 col5\" >0.5983</td>\n",
       "      <td id=\"T_a169d_row0_col6\" class=\"data row0 col6\" >0.4546</td>\n",
       "      <td id=\"T_a169d_row0_col7\" class=\"data row0 col7\" >0.4741</td>\n",
       "      <td id=\"T_a169d_row0_col8\" class=\"data row0 col8\" >0.1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_a169d_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_a169d_row1_col1\" class=\"data row1 col1\" >0.7761</td>\n",
       "      <td id=\"T_a169d_row1_col2\" class=\"data row1 col2\" >0.8007</td>\n",
       "      <td id=\"T_a169d_row1_col3\" class=\"data row1 col3\" >0.4583</td>\n",
       "      <td id=\"T_a169d_row1_col4\" class=\"data row1 col4\" >0.7789</td>\n",
       "      <td id=\"T_a169d_row1_col5\" class=\"data row1 col5\" >0.5767</td>\n",
       "      <td id=\"T_a169d_row1_col6\" class=\"data row1 col6\" >0.4382</td>\n",
       "      <td id=\"T_a169d_row1_col7\" class=\"data row1 col7\" >0.4668</td>\n",
       "      <td id=\"T_a169d_row1_col8\" class=\"data row1 col8\" >0.4290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row2\" class=\"row_heading level0 row2\" >et</th>\n",
       "      <td id=\"T_a169d_row2_col0\" class=\"data row2 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_a169d_row2_col1\" class=\"data row2 col1\" >0.7756</td>\n",
       "      <td id=\"T_a169d_row2_col2\" class=\"data row2 col2\" >0.7977</td>\n",
       "      <td id=\"T_a169d_row2_col3\" class=\"data row2 col3\" >0.4806</td>\n",
       "      <td id=\"T_a169d_row2_col4\" class=\"data row2 col4\" >0.7579</td>\n",
       "      <td id=\"T_a169d_row2_col5\" class=\"data row2 col5\" >0.5880</td>\n",
       "      <td id=\"T_a169d_row2_col6\" class=\"data row2 col6\" >0.4443</td>\n",
       "      <td id=\"T_a169d_row2_col7\" class=\"data row2 col7\" >0.4661</td>\n",
       "      <td id=\"T_a169d_row2_col8\" class=\"data row2 col8\" >0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_a169d_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_a169d_row3_col1\" class=\"data row3 col1\" >0.7728</td>\n",
       "      <td id=\"T_a169d_row3_col2\" class=\"data row3 col2\" >0.7988</td>\n",
       "      <td id=\"T_a169d_row3_col3\" class=\"data row3 col3\" >0.4686</td>\n",
       "      <td id=\"T_a169d_row3_col4\" class=\"data row3 col4\" >0.7574</td>\n",
       "      <td id=\"T_a169d_row3_col5\" class=\"data row3 col5\" >0.5788</td>\n",
       "      <td id=\"T_a169d_row3_col6\" class=\"data row3 col6\" >0.4349</td>\n",
       "      <td id=\"T_a169d_row3_col7\" class=\"data row3 col7\" >0.4585</td>\n",
       "      <td id=\"T_a169d_row3_col8\" class=\"data row3 col8\" >0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_a169d_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_a169d_row4_col1\" class=\"data row4 col1\" >0.7710</td>\n",
       "      <td id=\"T_a169d_row4_col2\" class=\"data row4 col2\" >0.7901</td>\n",
       "      <td id=\"T_a169d_row4_col3\" class=\"data row4 col3\" >0.4634</td>\n",
       "      <td id=\"T_a169d_row4_col4\" class=\"data row4 col4\" >0.7551</td>\n",
       "      <td id=\"T_a169d_row4_col5\" class=\"data row4 col5\" >0.5742</td>\n",
       "      <td id=\"T_a169d_row4_col6\" class=\"data row4 col6\" >0.4297</td>\n",
       "      <td id=\"T_a169d_row4_col7\" class=\"data row4 col7\" >0.4537</td>\n",
       "      <td id=\"T_a169d_row4_col8\" class=\"data row4 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_a169d_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_a169d_row5_col1\" class=\"data row5 col1\" >0.7507</td>\n",
       "      <td id=\"T_a169d_row5_col2\" class=\"data row5 col2\" >0.7330</td>\n",
       "      <td id=\"T_a169d_row5_col3\" class=\"data row5 col3\" >0.3646</td>\n",
       "      <td id=\"T_a169d_row5_col4\" class=\"data row5 col4\" >0.7639</td>\n",
       "      <td id=\"T_a169d_row5_col5\" class=\"data row5 col5\" >0.4934</td>\n",
       "      <td id=\"T_a169d_row5_col6\" class=\"data row5 col6\" >0.3547</td>\n",
       "      <td id=\"T_a169d_row5_col7\" class=\"data row5 col7\" >0.3974</td>\n",
       "      <td id=\"T_a169d_row5_col8\" class=\"data row5 col8\" >0.3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row6\" class=\"row_heading level0 row6\" >qda</th>\n",
       "      <td id=\"T_a169d_row6_col0\" class=\"data row6 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_a169d_row6_col1\" class=\"data row6 col1\" >0.7502</td>\n",
       "      <td id=\"T_a169d_row6_col2\" class=\"data row6 col2\" >0.7349</td>\n",
       "      <td id=\"T_a169d_row6_col3\" class=\"data row6 col3\" >0.3794</td>\n",
       "      <td id=\"T_a169d_row6_col4\" class=\"data row6 col4\" >0.7467</td>\n",
       "      <td id=\"T_a169d_row6_col5\" class=\"data row6 col5\" >0.5029</td>\n",
       "      <td id=\"T_a169d_row6_col6\" class=\"data row6 col6\" >0.3590</td>\n",
       "      <td id=\"T_a169d_row6_col7\" class=\"data row6 col7\" >0.3958</td>\n",
       "      <td id=\"T_a169d_row6_col8\" class=\"data row6 col8\" >0.0270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row7\" class=\"row_heading level0 row7\" >lda</th>\n",
       "      <td id=\"T_a169d_row7_col0\" class=\"data row7 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_a169d_row7_col1\" class=\"data row7 col1\" >0.7500</td>\n",
       "      <td id=\"T_a169d_row7_col2\" class=\"data row7 col2\" >0.7464</td>\n",
       "      <td id=\"T_a169d_row7_col3\" class=\"data row7 col3\" >0.3329</td>\n",
       "      <td id=\"T_a169d_row7_col4\" class=\"data row7 col4\" >0.8010</td>\n",
       "      <td id=\"T_a169d_row7_col5\" class=\"data row7 col5\" >0.4701</td>\n",
       "      <td id=\"T_a169d_row7_col6\" class=\"data row7 col6\" >0.3412</td>\n",
       "      <td id=\"T_a169d_row7_col7\" class=\"data row7 col7\" >0.3977</td>\n",
       "      <td id=\"T_a169d_row7_col8\" class=\"data row7 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "      <td id=\"T_a169d_row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_a169d_row8_col1\" class=\"data row8 col1\" >0.7494</td>\n",
       "      <td id=\"T_a169d_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row8_col3\" class=\"data row8 col3\" >0.3254</td>\n",
       "      <td id=\"T_a169d_row8_col4\" class=\"data row8 col4\" >0.8087</td>\n",
       "      <td id=\"T_a169d_row8_col5\" class=\"data row8 col5\" >0.4639</td>\n",
       "      <td id=\"T_a169d_row8_col6\" class=\"data row8 col6\" >0.3372</td>\n",
       "      <td id=\"T_a169d_row8_col7\" class=\"data row8 col7\" >0.3968</td>\n",
       "      <td id=\"T_a169d_row8_col8\" class=\"data row8 col8\" >0.0770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_a169d_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_a169d_row9_col1\" class=\"data row9 col1\" >0.7332</td>\n",
       "      <td id=\"T_a169d_row9_col2\" class=\"data row9 col2\" >0.7402</td>\n",
       "      <td id=\"T_a169d_row9_col3\" class=\"data row9 col3\" >0.2800</td>\n",
       "      <td id=\"T_a169d_row9_col4\" class=\"data row9 col4\" >0.7752</td>\n",
       "      <td id=\"T_a169d_row9_col5\" class=\"data row9 col5\" >0.4102</td>\n",
       "      <td id=\"T_a169d_row9_col6\" class=\"data row9 col6\" >0.2850</td>\n",
       "      <td id=\"T_a169d_row9_col7\" class=\"data row9 col7\" >0.3467</td>\n",
       "      <td id=\"T_a169d_row9_col8\" class=\"data row9 col8\" >0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_a169d_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_a169d_row10_col1\" class=\"data row10 col1\" >0.6812</td>\n",
       "      <td id=\"T_a169d_row10_col2\" class=\"data row10 col2\" >0.6440</td>\n",
       "      <td id=\"T_a169d_row10_col3\" class=\"data row10 col3\" >0.5326</td>\n",
       "      <td id=\"T_a169d_row10_col4\" class=\"data row10 col4\" >0.5221</td>\n",
       "      <td id=\"T_a169d_row10_col5\" class=\"data row10 col5\" >0.5270</td>\n",
       "      <td id=\"T_a169d_row10_col6\" class=\"data row10 col6\" >0.2867</td>\n",
       "      <td id=\"T_a169d_row10_col7\" class=\"data row10 col7\" >0.2869</td>\n",
       "      <td id=\"T_a169d_row10_col8\" class=\"data row10 col8\" >0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n",
       "      <td id=\"T_a169d_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_a169d_row11_col1\" class=\"data row11 col1\" >0.6666</td>\n",
       "      <td id=\"T_a169d_row11_col2\" class=\"data row11 col2\" >0.5000</td>\n",
       "      <td id=\"T_a169d_row11_col3\" class=\"data row11 col3\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row11_col4\" class=\"data row11 col4\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row11_col8\" class=\"data row11 col8\" >0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_a169d_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_a169d_row12_col1\" class=\"data row12 col1\" >0.6608</td>\n",
       "      <td id=\"T_a169d_row12_col2\" class=\"data row12 col2\" >0.6313</td>\n",
       "      <td id=\"T_a169d_row12_col3\" class=\"data row12 col3\" >0.3194</td>\n",
       "      <td id=\"T_a169d_row12_col4\" class=\"data row12 col4\" >0.4868</td>\n",
       "      <td id=\"T_a169d_row12_col5\" class=\"data row12 col5\" >0.3856</td>\n",
       "      <td id=\"T_a169d_row12_col6\" class=\"data row12 col6\" >0.1651</td>\n",
       "      <td id=\"T_a169d_row12_col7\" class=\"data row12 col7\" >0.1722</td>\n",
       "      <td id=\"T_a169d_row12_col8\" class=\"data row12 col8\" >0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a169d_level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n",
       "      <td id=\"T_a169d_row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_a169d_row13_col1\" class=\"data row13 col1\" >0.6170</td>\n",
       "      <td id=\"T_a169d_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_a169d_row13_col3\" class=\"data row13 col3\" >0.4723</td>\n",
       "      <td id=\"T_a169d_row13_col4\" class=\"data row13 col4\" >0.4351</td>\n",
       "      <td id=\"T_a169d_row13_col5\" class=\"data row13 col5\" >0.4416</td>\n",
       "      <td id=\"T_a169d_row13_col6\" class=\"data row13 col6\" >0.1567</td>\n",
       "      <td id=\"T_a169d_row13_col7\" class=\"data row13 col7\" >0.1610</td>\n",
       "      <td id=\"T_a169d_row13_col8\" class=\"data row13 col8\" >0.0290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28cd89a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_5 = compare_models(sort='Accuracy' , n_select = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37794102-9880-43b4-b27e-6b9119f25d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c00d5_row5_col0, #T_c00d5_row5_col1, #T_c00d5_row5_col2, #T_c00d5_row5_col3, #T_c00d5_row5_col4, #T_c00d5_row5_col5, #T_c00d5_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c00d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c00d5_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c00d5_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_c00d5_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_c00d5_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_c00d5_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_c00d5_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_c00d5_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c00d5_row0_col0\" class=\"data row0 col0\" >0.7824</td>\n",
       "      <td id=\"T_c00d5_row0_col1\" class=\"data row0 col1\" >0.8145</td>\n",
       "      <td id=\"T_c00d5_row0_col2\" class=\"data row0 col2\" >0.4757</td>\n",
       "      <td id=\"T_c00d5_row0_col3\" class=\"data row0 col3\" >0.7872</td>\n",
       "      <td id=\"T_c00d5_row0_col4\" class=\"data row0 col4\" >0.5931</td>\n",
       "      <td id=\"T_c00d5_row0_col5\" class=\"data row0 col5\" >0.4566</td>\n",
       "      <td id=\"T_c00d5_row0_col6\" class=\"data row0 col6\" >0.4836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c00d5_row1_col0\" class=\"data row1 col0\" >0.7681</td>\n",
       "      <td id=\"T_c00d5_row1_col1\" class=\"data row1 col1\" >0.7897</td>\n",
       "      <td id=\"T_c00d5_row1_col2\" class=\"data row1 col2\" >0.4557</td>\n",
       "      <td id=\"T_c00d5_row1_col3\" class=\"data row1 col3\" >0.7506</td>\n",
       "      <td id=\"T_c00d5_row1_col4\" class=\"data row1 col4\" >0.5671</td>\n",
       "      <td id=\"T_c00d5_row1_col5\" class=\"data row1 col5\" >0.4214</td>\n",
       "      <td id=\"T_c00d5_row1_col6\" class=\"data row1 col6\" >0.4459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c00d5_row2_col0\" class=\"data row2 col0\" >0.7743</td>\n",
       "      <td id=\"T_c00d5_row2_col1\" class=\"data row2 col1\" >0.7956</td>\n",
       "      <td id=\"T_c00d5_row2_col2\" class=\"data row2 col2\" >0.4471</td>\n",
       "      <td id=\"T_c00d5_row2_col3\" class=\"data row2 col3\" >0.7825</td>\n",
       "      <td id=\"T_c00d5_row2_col4\" class=\"data row2 col4\" >0.5691</td>\n",
       "      <td id=\"T_c00d5_row2_col5\" class=\"data row2 col5\" >0.4312</td>\n",
       "      <td id=\"T_c00d5_row2_col6\" class=\"data row2 col6\" >0.4622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c00d5_row3_col0\" class=\"data row3 col0\" >0.7829</td>\n",
       "      <td id=\"T_c00d5_row3_col1\" class=\"data row3 col1\" >0.8132</td>\n",
       "      <td id=\"T_c00d5_row3_col2\" class=\"data row3 col2\" >0.4900</td>\n",
       "      <td id=\"T_c00d5_row3_col3\" class=\"data row3 col3\" >0.7760</td>\n",
       "      <td id=\"T_c00d5_row3_col4\" class=\"data row3 col4\" >0.6007</td>\n",
       "      <td id=\"T_c00d5_row3_col5\" class=\"data row3 col5\" >0.4618</td>\n",
       "      <td id=\"T_c00d5_row3_col6\" class=\"data row3 col6\" >0.4849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c00d5_row4_col0\" class=\"data row4 col0\" >0.7956</td>\n",
       "      <td id=\"T_c00d5_row4_col1\" class=\"data row4 col1\" >0.8175</td>\n",
       "      <td id=\"T_c00d5_row4_col2\" class=\"data row4 col2\" >0.4957</td>\n",
       "      <td id=\"T_c00d5_row4_col3\" class=\"data row4 col3\" >0.8203</td>\n",
       "      <td id=\"T_c00d5_row4_col4\" class=\"data row4 col4\" >0.6180</td>\n",
       "      <td id=\"T_c00d5_row4_col5\" class=\"data row4 col5\" >0.4898</td>\n",
       "      <td id=\"T_c00d5_row4_col6\" class=\"data row4 col6\" >0.5188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_c00d5_row5_col0\" class=\"data row5 col0\" >0.7806</td>\n",
       "      <td id=\"T_c00d5_row5_col1\" class=\"data row5 col1\" >0.8061</td>\n",
       "      <td id=\"T_c00d5_row5_col2\" class=\"data row5 col2\" >0.4729</td>\n",
       "      <td id=\"T_c00d5_row5_col3\" class=\"data row5 col3\" >0.7833</td>\n",
       "      <td id=\"T_c00d5_row5_col4\" class=\"data row5 col4\" >0.5896</td>\n",
       "      <td id=\"T_c00d5_row5_col5\" class=\"data row5 col5\" >0.4522</td>\n",
       "      <td id=\"T_c00d5_row5_col6\" class=\"data row5 col6\" >0.4791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c00d5_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_c00d5_row6_col0\" class=\"data row6 col0\" >0.0093</td>\n",
       "      <td id=\"T_c00d5_row6_col1\" class=\"data row6 col1\" >0.0112</td>\n",
       "      <td id=\"T_c00d5_row6_col2\" class=\"data row6 col2\" >0.0189</td>\n",
       "      <td id=\"T_c00d5_row6_col3\" class=\"data row6 col3\" >0.0224</td>\n",
       "      <td id=\"T_c00d5_row6_col4\" class=\"data row6 col4\" >0.0193</td>\n",
       "      <td id=\"T_c00d5_row6_col5\" class=\"data row6 col5\" >0.0242</td>\n",
       "      <td id=\"T_c00d5_row6_col6\" class=\"data row6 col6\" >0.0246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28cf05d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blended = blend_models(estimator_list= best_5 , fold= 5, method='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b40fba5-d4c8-4ee0-8b77-1ce18ad4645e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a8f04\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a8f04_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a8f04_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_a8f04_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_a8f04_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_a8f04_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_a8f04_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_a8f04_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_a8f04_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a8f04_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a8f04_row0_col0\" class=\"data row0 col0\" >Voting Classifier</td>\n",
       "      <td id=\"T_a8f04_row0_col1\" class=\"data row0 col1\" >0.7805</td>\n",
       "      <td id=\"T_a8f04_row0_col2\" class=\"data row0 col2\" >0.8066</td>\n",
       "      <td id=\"T_a8f04_row0_col3\" class=\"data row0 col3\" >0.4527</td>\n",
       "      <td id=\"T_a8f04_row0_col4\" class=\"data row0 col4\" >0.8026</td>\n",
       "      <td id=\"T_a8f04_row0_col5\" class=\"data row0 col5\" >0.5789</td>\n",
       "      <td id=\"T_a8f04_row0_col6\" class=\"data row0 col6\" >0.4456</td>\n",
       "      <td id=\"T_a8f04_row0_col7\" class=\"data row0 col7\" >0.4790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2896158b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_holdout = predict_model(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aa5842d-799d-4537-b2ee-0bdd83ed2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = finalize_model(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a01ef9dc-dc3e-408f-83e1-7635b1858f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;Light Gradient Boosting Machine&#x27;,\n",
       "                              LGBMClassifier(boosting_type=&#x27;gbdt&#x27;,\n",
       "                                             class_weight=None,\n",
       "                                             colsample_bytree=1.0,\n",
       "                                             importance_type=&#x27;split&#x27;,\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=31, objective=None,\n",
       "                                             random_state=6180, reg_alpha=0.0,\n",
       "                                             reg_lamb...\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=6180,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             (&#x27;Ada Boost Classifier&#x27;,\n",
       "                              AdaBoostClassifier(algorithm=&#x27;SAMME.R&#x27;,\n",
       "                                                 base_estimator=None,\n",
       "                                                 learning_rate=1.0,\n",
       "                                                 n_estimators=50,\n",
       "                                                 random_state=6180))],\n",
       "                 flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                 voting=&#x27;soft&#x27;, weights=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Light Gradient Boosting Machine&#x27;,\n",
       "                              LGBMClassifier(boosting_type=&#x27;gbdt&#x27;,\n",
       "                                             class_weight=None,\n",
       "                                             colsample_bytree=1.0,\n",
       "                                             importance_type=&#x27;split&#x27;,\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=31, objective=None,\n",
       "                                             random_state=6180, reg_alpha=0.0,\n",
       "                                             reg_lamb...\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=6180,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             (&#x27;Ada Boost Classifier&#x27;,\n",
       "                              AdaBoostClassifier(algorithm=&#x27;SAMME.R&#x27;,\n",
       "                                                 base_estimator=None,\n",
       "                                                 learning_rate=1.0,\n",
       "                                                 n_estimators=50,\n",
       "                                                 random_state=6180))],\n",
       "                 flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                 voting=&#x27;soft&#x27;, weights=None)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Light Gradient Boosting Machine</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=6180)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Gradient Boosting Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=6180)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Extra Trees Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=6180)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=6180)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Ada Boost Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(random_state=6180)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('Light Gradient Boosting Machine',\n",
       "                              LGBMClassifier(boosting_type='gbdt',\n",
       "                                             class_weight=None,\n",
       "                                             colsample_bytree=1.0,\n",
       "                                             importance_type='split',\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=31, objective=None,\n",
       "                                             random_state=6180, reg_alpha=0.0,\n",
       "                                             reg_lamb...\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=6180,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('Ada Boost Classifier',\n",
       "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                 base_estimator=None,\n",
       "                                                 learning_rate=1.0,\n",
       "                                                 n_estimators=50,\n",
       "                                                 random_state=6180))],\n",
       "                 flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                 voting='soft', weights=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a8a5367-32dc-4f66-a8b8-1392a51d0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 16532648/16532648 [00:14<00:00, 1103334.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14999, 42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_err = pd.read_csv(PATH + 'test_err_data.csv')\n",
    "id_error = test_err[['user_id','errtype']].values\n",
    "test_x = np.zeros((14999,42))\n",
    "for person_idx , err in tqdm(id_error):\n",
    "    test_x[person_idx - 30000, err -1] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "523fee23-4c53-48fe-8c5c-fed0ef63a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(data=test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3563301-6dd3-448f-a0c8-f4e3960ee9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predict_model(final_model,data = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "907cc5d0-1bda-4ad5-8e0e-11f069677ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.Label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8154e2a7-a619-4180-8363-32004dcc2100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.821,\n",
       " 0.30589999999999995,\n",
       " 0.28590000000000004,\n",
       " 0.6915,\n",
       " 0.5881,\n",
       " 0.43889999999999996,\n",
       " 0.20189999999999997,\n",
       " 0.13029999999999997,\n",
       " 0.6097,\n",
       " 0.3274,\n",
       " 0.2015,\n",
       " 0.23050000000000004,\n",
       " 0.8261,\n",
       " 0.21140000000000003,\n",
       " 0.20130000000000003,\n",
       " 0.3345,\n",
       " 0.3308,\n",
       " 0.4677,\n",
       " 0.384,\n",
       " 0.36339999999999995,\n",
       " 0.7427,\n",
       " 0.5223,\n",
       " 0.2672,\n",
       " 0.17889999999999995,\n",
       " 0.5082,\n",
       " 0.37470000000000003,\n",
       " 0.38639999999999997,\n",
       " 0.2147,\n",
       " 0.28049999999999997,\n",
       " 0.16110000000000002,\n",
       " 0.22929999999999995,\n",
       " 0.3306,\n",
       " 0.2208,\n",
       " 0.24739999999999995,\n",
       " 0.41890000000000005,\n",
       " 0.3125,\n",
       " 0.18489999999999995,\n",
       " 0.4012,\n",
       " 0.2845,\n",
       " 0.16620000000000001,\n",
       " 0.39880000000000004,\n",
       " 0.23340000000000005,\n",
       " 0.15590000000000004,\n",
       " 0.14649999999999996,\n",
       " 0.20389999999999997,\n",
       " 0.3772,\n",
       " 0.3993,\n",
       " 0.2319,\n",
       " 0.3163,\n",
       " 0.17659999999999998,\n",
       " 0.23850000000000005,\n",
       " 0.28969999999999996,\n",
       " 0.3477,\n",
       " 0.18689999999999996,\n",
       " 0.12929999999999997,\n",
       " 0.27180000000000004,\n",
       " 0.35540000000000005,\n",
       " 0.37829999999999997,\n",
       " 0.4275,\n",
       " 0.26480000000000004,\n",
       " 0.5046,\n",
       " 0.7995,\n",
       " 0.8299,\n",
       " 0.126,\n",
       " 0.3285,\n",
       " 0.18600000000000005,\n",
       " 0.21099999999999997,\n",
       " 0.2259,\n",
       " 0.6699,\n",
       " 0.39270000000000005,\n",
       " 0.40890000000000004,\n",
       " 0.6981,\n",
       " 0.36050000000000004,\n",
       " 0.7322,\n",
       " 0.1583,\n",
       " 0.32430000000000003,\n",
       " 0.45320000000000005,\n",
       " 0.2901,\n",
       " 0.8249,\n",
       " 0.2683,\n",
       " 0.5089,\n",
       " 0.11150000000000004,\n",
       " 0.24150000000000005,\n",
       " 0.33140000000000003,\n",
       " 0.4527,\n",
       " 0.20630000000000004,\n",
       " 0.27049999999999996,\n",
       " 0.19110000000000005,\n",
       " 0.22629999999999995,\n",
       " 0.2548,\n",
       " 0.6583,\n",
       " 0.1997,\n",
       " 0.11470000000000002,\n",
       " 0.2157,\n",
       " 0.4061,\n",
       " 0.20020000000000004,\n",
       " 0.15769999999999995,\n",
       " 0.3257,\n",
       " 0.8448,\n",
       " 0.19399999999999995,\n",
       " 0.3204,\n",
       " 0.2993,\n",
       " 0.27590000000000003,\n",
       " 0.22850000000000004,\n",
       " 0.29579999999999995,\n",
       " 0.6938,\n",
       " 0.38949999999999996,\n",
       " 0.20509999999999995,\n",
       " 0.1834,\n",
       " 0.17359999999999998,\n",
       " 0.2911,\n",
       " 0.3157,\n",
       " 0.14590000000000003,\n",
       " 0.706,\n",
       " 0.21440000000000003,\n",
       " 0.14280000000000004,\n",
       " 0.2784,\n",
       " 0.19669999999999999,\n",
       " 0.4587,\n",
       " 0.2852,\n",
       " 0.1331,\n",
       " 0.279,\n",
       " 0.7878,\n",
       " 0.31920000000000004,\n",
       " 0.3107,\n",
       " 0.3709,\n",
       " 0.274,\n",
       " 0.24970000000000003,\n",
       " 0.5165,\n",
       " 0.3598,\n",
       " 0.7702,\n",
       " 0.2308,\n",
       " 0.40480000000000005,\n",
       " 0.8079,\n",
       " 0.3315,\n",
       " 0.8209,\n",
       " 0.2811,\n",
       " 0.2501,\n",
       " 0.8708,\n",
       " 0.19569999999999999,\n",
       " 0.4841,\n",
       " 0.34319999999999995,\n",
       " 0.2299,\n",
       " 0.42300000000000004,\n",
       " 0.16779999999999995,\n",
       " 0.11299999999999999,\n",
       " 0.4284,\n",
       " 0.42379999999999995,\n",
       " 0.817,\n",
       " 0.726,\n",
       " 0.1522,\n",
       " 0.3153,\n",
       " 0.14949999999999997,\n",
       " 0.30910000000000004,\n",
       " 0.19420000000000004,\n",
       " 0.19930000000000003,\n",
       " 0.16800000000000004,\n",
       " 0.16600000000000004,\n",
       " 0.5473,\n",
       " 0.29410000000000003,\n",
       " 0.17159999999999997,\n",
       " 0.33840000000000003,\n",
       " 0.3053,\n",
       " 0.48440000000000005,\n",
       " 0.6595,\n",
       " 0.3651,\n",
       " 0.24119999999999997,\n",
       " 0.5622,\n",
       " 0.3377,\n",
       " 0.4286,\n",
       " 0.4373,\n",
       " 0.265,\n",
       " 0.11980000000000002,\n",
       " 0.41879999999999995,\n",
       " 0.6285,\n",
       " 0.7609,\n",
       " 0.15410000000000001,\n",
       " 0.24509999999999998,\n",
       " 0.4516,\n",
       " 0.2691,\n",
       " 0.35819999999999996,\n",
       " 0.5262,\n",
       " 0.6629,\n",
       " 0.491,\n",
       " 0.22529999999999994,\n",
       " 0.21719999999999995,\n",
       " 0.25329999999999997,\n",
       " 0.2348,\n",
       " 0.2843,\n",
       " 0.27549999999999997,\n",
       " 0.5013,\n",
       " 0.3369,\n",
       " 0.7122,\n",
       " 0.1865,\n",
       " 0.5446,\n",
       " 0.1795,\n",
       " 0.23319999999999996,\n",
       " 0.7153,\n",
       " 0.242,\n",
       " 0.20850000000000002,\n",
       " 0.23129999999999995,\n",
       " 0.14159999999999995,\n",
       " 0.14139999999999997,\n",
       " 0.24309999999999998,\n",
       " 0.26049999999999995,\n",
       " 0.849,\n",
       " 0.2198,\n",
       " 0.24780000000000002,\n",
       " 0.21650000000000003,\n",
       " 0.5087,\n",
       " 0.511,\n",
       " 0.4891,\n",
       " 0.4092,\n",
       " 0.22130000000000005,\n",
       " 0.33520000000000005,\n",
       " 0.3477,\n",
       " 0.7596,\n",
       " 0.3993,\n",
       " 0.8162,\n",
       " 0.11909999999999998,\n",
       " 0.38680000000000003,\n",
       " 0.34419999999999995,\n",
       " 0.35729999999999995,\n",
       " 0.16080000000000005,\n",
       " 0.21189999999999998,\n",
       " 0.19789999999999996,\n",
       " 0.1895,\n",
       " 0.37460000000000004,\n",
       " 0.31299999999999994,\n",
       " 0.2854,\n",
       " 0.4386,\n",
       " 0.24170000000000003,\n",
       " 0.37560000000000004,\n",
       " 0.6526,\n",
       " 0.261,\n",
       " 0.27759999999999996,\n",
       " 0.5164,\n",
       " 0.20120000000000005,\n",
       " 0.29159999999999997,\n",
       " 0.16949999999999998,\n",
       " 0.29990000000000006,\n",
       " 0.34209999999999996,\n",
       " 0.20350000000000001,\n",
       " 0.388,\n",
       " 0.8155,\n",
       " 0.21250000000000002,\n",
       " 0.19330000000000003,\n",
       " 0.2137,\n",
       " 0.5459,\n",
       " 0.3268,\n",
       " 0.31420000000000003,\n",
       " 0.3033,\n",
       " 0.47819999999999996,\n",
       " 0.8149,\n",
       " 0.6938,\n",
       " 0.17290000000000005,\n",
       " 0.4919,\n",
       " 0.16190000000000004,\n",
       " 0.24670000000000003,\n",
       " 0.2921,\n",
       " 0.12460000000000004,\n",
       " 0.3628,\n",
       " 0.33599999999999997,\n",
       " 0.18799999999999994,\n",
       " 0.3367,\n",
       " 0.119,\n",
       " 0.20209999999999995,\n",
       " 0.26170000000000004,\n",
       " 0.46199999999999997,\n",
       " 0.2479,\n",
       " 0.18300000000000005,\n",
       " 0.15400000000000003,\n",
       " 0.244,\n",
       " 0.30369999999999997,\n",
       " 0.27659999999999996,\n",
       " 0.13639999999999997,\n",
       " 0.2056,\n",
       " 0.42100000000000004,\n",
       " 0.2219,\n",
       " 0.34830000000000005,\n",
       " 0.27980000000000005,\n",
       " 0.18469999999999998,\n",
       " 0.3778,\n",
       " 0.1834,\n",
       " 0.8236,\n",
       " 0.11209999999999998,\n",
       " 0.476,\n",
       " 0.5268,\n",
       " 0.6087,\n",
       " 0.23970000000000002,\n",
       " 0.19240000000000002,\n",
       " 0.12519999999999998,\n",
       " 0.16549999999999998,\n",
       " 0.17569999999999997,\n",
       " 0.235,\n",
       " 0.4569,\n",
       " 0.7222,\n",
       " 0.4365,\n",
       " 0.36050000000000004,\n",
       " 0.5928,\n",
       " 0.6912,\n",
       " 0.17710000000000004,\n",
       " 0.8522,\n",
       " 0.8376,\n",
       " 0.34030000000000005,\n",
       " 0.3496,\n",
       " 0.14800000000000002,\n",
       " 0.16590000000000005,\n",
       " 0.3899,\n",
       " 0.7607,\n",
       " 0.43010000000000004,\n",
       " 0.31010000000000004,\n",
       " 0.4647,\n",
       " 0.8719,\n",
       " 0.22250000000000003,\n",
       " 0.4578,\n",
       " 0.2571,\n",
       " 0.30279999999999996,\n",
       " 0.811,\n",
       " 0.42989999999999995,\n",
       " 0.25970000000000004,\n",
       " 0.16100000000000003,\n",
       " 0.6314,\n",
       " 0.4103,\n",
       " 0.15080000000000005,\n",
       " 0.7958,\n",
       " 0.2279,\n",
       " 0.23409999999999997,\n",
       " 0.4738,\n",
       " 0.15480000000000005,\n",
       " 0.37450000000000006,\n",
       " 0.3237,\n",
       " 0.784,\n",
       " 0.3046,\n",
       " 0.2692,\n",
       " 0.23850000000000005,\n",
       " 0.2249,\n",
       " 0.2934,\n",
       " 0.542,\n",
       " 0.7914,\n",
       " 0.18930000000000002,\n",
       " 0.17610000000000003,\n",
       " 0.1915,\n",
       " 0.7738,\n",
       " 0.36719999999999997,\n",
       " 0.2227,\n",
       " 0.3298,\n",
       " 0.5238,\n",
       " 0.3519,\n",
       " 0.3062,\n",
       " 0.35119999999999996,\n",
       " 0.22809999999999997,\n",
       " 0.2772,\n",
       " 0.17500000000000004,\n",
       " 0.271,\n",
       " 0.40169999999999995,\n",
       " 0.18420000000000003,\n",
       " 0.2481,\n",
       " 0.22340000000000004,\n",
       " 0.2017,\n",
       " 0.2763,\n",
       " 0.20989999999999998,\n",
       " 0.5714,\n",
       " 0.3004,\n",
       " 0.2854,\n",
       " 0.3953,\n",
       " 0.271,\n",
       " 0.21819999999999995,\n",
       " 0.5446,\n",
       " 0.11150000000000004,\n",
       " 0.15139999999999998,\n",
       " 0.4305,\n",
       " 0.33209999999999995,\n",
       " 0.20099999999999996,\n",
       " 0.26480000000000004,\n",
       " 0.1904,\n",
       " 0.1532,\n",
       " 0.8106,\n",
       " 0.4041,\n",
       " 0.8273,\n",
       " 0.3647,\n",
       " 0.21109999999999995,\n",
       " 0.2669,\n",
       " 0.20330000000000004,\n",
       " 0.615,\n",
       " 0.22750000000000004,\n",
       " 0.7531,\n",
       " 0.1866,\n",
       " 0.561,\n",
       " 0.11299999999999999,\n",
       " 0.1946,\n",
       " 0.3591,\n",
       " 0.2663,\n",
       " 0.1885,\n",
       " 0.26180000000000003,\n",
       " 0.22240000000000004,\n",
       " 0.2813,\n",
       " 0.23260000000000003,\n",
       " 0.4517,\n",
       " 0.24150000000000005,\n",
       " 0.8079,\n",
       " 0.11670000000000003,\n",
       " 0.8311,\n",
       " 0.4554,\n",
       " 0.24570000000000003,\n",
       " 0.35740000000000005,\n",
       " 0.17149999999999999,\n",
       " 0.2871,\n",
       " 0.47109999999999996,\n",
       " 0.29579999999999995,\n",
       " 0.19920000000000004,\n",
       " 0.36619999999999997,\n",
       " 0.24160000000000004,\n",
       " 0.5023,\n",
       " 0.3891,\n",
       " 0.8365,\n",
       " 0.47850000000000004,\n",
       " 0.5039,\n",
       " 0.4536,\n",
       " 0.8343,\n",
       " 0.1382,\n",
       " 0.7679,\n",
       " 0.486,\n",
       " 0.17110000000000003,\n",
       " 0.8201,\n",
       " 0.6344,\n",
       " 0.4525,\n",
       " 0.24160000000000004,\n",
       " 0.24039999999999995,\n",
       " 0.38049999999999995,\n",
       " 0.3297,\n",
       " 0.1745,\n",
       " 0.28700000000000003,\n",
       " 0.39039999999999997,\n",
       " 0.44989999999999997,\n",
       " 0.5731,\n",
       " 0.42100000000000004,\n",
       " 0.21250000000000002,\n",
       " 0.11209999999999998,\n",
       " 0.6866,\n",
       " 0.21220000000000006,\n",
       " 0.30310000000000004,\n",
       " 0.45630000000000004,\n",
       " 0.83,\n",
       " 0.2037,\n",
       " 0.7433,\n",
       " 0.2521,\n",
       " 0.8474,\n",
       " 0.533,\n",
       " 0.7816,\n",
       " 0.8281,\n",
       " 0.24080000000000001,\n",
       " 0.19240000000000002,\n",
       " 0.19989999999999997,\n",
       " 0.2228,\n",
       " 0.8041,\n",
       " 0.2976,\n",
       " 0.27,\n",
       " 0.4446,\n",
       " 0.31410000000000005,\n",
       " 0.29800000000000004,\n",
       " 0.2147,\n",
       " 0.14290000000000003,\n",
       " 0.19799999999999995,\n",
       " 0.4302,\n",
       " 0.2583,\n",
       " 0.3409,\n",
       " 0.14259999999999995,\n",
       " 0.2741,\n",
       " 0.40800000000000003,\n",
       " 0.7988,\n",
       " 0.31579999999999997,\n",
       " 0.4414,\n",
       " 0.7903,\n",
       " 0.4496,\n",
       " 0.3325,\n",
       " 0.2479,\n",
       " 0.23450000000000004,\n",
       " 0.823,\n",
       " 0.21930000000000005,\n",
       " 0.30269999999999997,\n",
       " 0.7066,\n",
       " 0.26259999999999994,\n",
       " 0.4356,\n",
       " 0.18389999999999995,\n",
       " 0.7069,\n",
       " 0.8009,\n",
       " 0.1673,\n",
       " 0.5004,\n",
       " 0.27780000000000005,\n",
       " 0.2277,\n",
       " 0.13929999999999998,\n",
       " 0.7621,\n",
       " 0.8586,\n",
       " 0.5254,\n",
       " 0.4679,\n",
       " 0.23309999999999997,\n",
       " 0.2582,\n",
       " 0.7481,\n",
       " 0.19110000000000005,\n",
       " 0.21220000000000006,\n",
       " 0.37260000000000004,\n",
       " 0.2047,\n",
       " 0.8344,\n",
       " 0.2693,\n",
       " 0.34650000000000003,\n",
       " 0.14539999999999997,\n",
       " 0.36339999999999995,\n",
       " 0.2924,\n",
       " 0.33109999999999995,\n",
       " 0.5923,\n",
       " 0.6075,\n",
       " 0.24409999999999998,\n",
       " 0.22660000000000002,\n",
       " 0.33930000000000005,\n",
       " 0.26770000000000005,\n",
       " 0.30100000000000005,\n",
       " 0.2682,\n",
       " 0.768,\n",
       " 0.42390000000000005,\n",
       " 0.25780000000000003,\n",
       " 0.7183,\n",
       " 0.48619999999999997,\n",
       " 0.15900000000000003,\n",
       " 0.35519999999999996,\n",
       " 0.11619999999999997,\n",
       " 0.3721,\n",
       " 0.8497,\n",
       " 0.2601,\n",
       " 0.38249999999999995,\n",
       " 0.2147,\n",
       " 0.4353,\n",
       " 0.37450000000000006,\n",
       " 0.8487,\n",
       " 0.2713,\n",
       " 0.34199999999999997,\n",
       " 0.11150000000000004,\n",
       " 0.484,\n",
       " 0.5018,\n",
       " 0.687,\n",
       " 0.7038,\n",
       " 0.47740000000000005,\n",
       " 0.16390000000000005,\n",
       " 0.4827,\n",
       " 0.25329999999999997,\n",
       " 0.42600000000000005,\n",
       " 0.3345,\n",
       " 0.8371,\n",
       " 0.32630000000000003,\n",
       " 0.2148,\n",
       " 0.22130000000000005,\n",
       " 0.7897,\n",
       " 0.3971,\n",
       " 0.1906,\n",
       " 0.34299999999999997,\n",
       " 0.30910000000000004,\n",
       " 0.2227,\n",
       " 0.2863,\n",
       " 0.1997,\n",
       " 0.33309999999999995,\n",
       " 0.25339999999999996,\n",
       " 0.3853,\n",
       " 0.1725,\n",
       " 0.5297,\n",
       " 0.1664,\n",
       " 0.36019999999999996,\n",
       " 0.2953,\n",
       " 0.39170000000000005,\n",
       " 0.23399999999999999,\n",
       " 0.2247,\n",
       " 0.1704,\n",
       " 0.3023,\n",
       " 0.3577,\n",
       " 0.7301,\n",
       " 0.16749999999999998,\n",
       " 0.17869999999999997,\n",
       " 0.2056,\n",
       " 0.30789999999999995,\n",
       " 0.31779999999999997,\n",
       " 0.7572,\n",
       " 0.20809999999999995,\n",
       " 0.33709999999999996,\n",
       " 0.122,\n",
       " 0.43710000000000004,\n",
       " 0.5019,\n",
       " 0.2026,\n",
       " 0.8224,\n",
       " 0.2126,\n",
       " 0.22750000000000004,\n",
       " 0.15490000000000004,\n",
       " 0.24229999999999996,\n",
       " 0.16400000000000003,\n",
       " 0.2538,\n",
       " 0.22619999999999996,\n",
       " 0.7933,\n",
       " 0.1846,\n",
       " 0.24329999999999996,\n",
       " 0.7732,\n",
       " 0.2178,\n",
       " 0.7742,\n",
       " 0.3435,\n",
       " 0.22819999999999996,\n",
       " 0.21430000000000005,\n",
       " 0.7924,\n",
       " 0.22409999999999997,\n",
       " 0.19799999999999995,\n",
       " 0.26570000000000005,\n",
       " 0.3146,\n",
       " 0.29669999999999996,\n",
       " 0.16459999999999997,\n",
       " 0.8412,\n",
       " 0.4918,\n",
       " 0.2188,\n",
       " 0.23109999999999997,\n",
       " 0.624,\n",
       " 0.18679999999999997,\n",
       " 0.4757,\n",
       " 0.3647,\n",
       " 0.14939999999999998,\n",
       " 0.3944,\n",
       " 0.7699,\n",
       " 0.39990000000000003,\n",
       " 0.25549999999999995,\n",
       " 0.11760000000000004,\n",
       " 0.3677,\n",
       " 0.7853,\n",
       " 0.25549999999999995,\n",
       " 0.13949999999999996,\n",
       " 0.40249999999999997,\n",
       " 0.3006,\n",
       " 0.2512,\n",
       " 0.2794,\n",
       " 0.2774,\n",
       " 0.14449999999999996,\n",
       " 0.3699,\n",
       " 0.24009999999999998,\n",
       " 0.7432,\n",
       " 0.11080000000000001,\n",
       " 0.2974,\n",
       " 0.1341,\n",
       " 0.1866,\n",
       " 0.26639999999999997,\n",
       " 0.4103,\n",
       " 0.2924,\n",
       " 0.1904,\n",
       " 0.2469,\n",
       " 0.17820000000000003,\n",
       " 0.7689,\n",
       " 0.3264,\n",
       " 0.19110000000000005,\n",
       " 0.22870000000000001,\n",
       " 0.17679999999999996,\n",
       " 0.23650000000000004,\n",
       " 0.5408,\n",
       " 0.8447,\n",
       " 0.2127,\n",
       " 0.4365,\n",
       " 0.2288,\n",
       " 0.3519,\n",
       " 0.8269,\n",
       " 0.36319999999999997,\n",
       " 0.2671,\n",
       " 0.8393,\n",
       " 0.8247,\n",
       " 0.42290000000000005,\n",
       " 0.32720000000000005,\n",
       " 0.3173,\n",
       " 0.3941,\n",
       " 0.16969999999999996,\n",
       " 0.1977,\n",
       " 0.20740000000000003,\n",
       " 0.34440000000000004,\n",
       " 0.2885,\n",
       " 0.6722,\n",
       " 0.19210000000000005,\n",
       " 0.21799999999999997,\n",
       " 0.6046,\n",
       " 0.32609999999999995,\n",
       " 0.4769,\n",
       " 0.7033,\n",
       " 0.4436,\n",
       " 0.41090000000000004,\n",
       " 0.17059999999999997,\n",
       " 0.18210000000000004,\n",
       " 0.4504,\n",
       " 0.7734,\n",
       " 0.8545,\n",
       " 0.22809999999999997,\n",
       " 0.3466,\n",
       " 0.851,\n",
       " 0.37229999999999996,\n",
       " 0.32830000000000004,\n",
       " 0.27580000000000005,\n",
       " 0.29100000000000004,\n",
       " 0.15139999999999998,\n",
       " 0.25039999999999996,\n",
       " 0.1814,\n",
       " 0.8351,\n",
       " 0.4113,\n",
       " 0.33330000000000004,\n",
       " 0.8464,\n",
       " 0.15349999999999997,\n",
       " 0.17800000000000005,\n",
       " 0.718,\n",
       " 0.8354,\n",
       " 0.16410000000000002,\n",
       " 0.17090000000000005,\n",
       " 0.5954,\n",
       " 0.8224,\n",
       " 0.23270000000000002,\n",
       " 0.7132,\n",
       " 0.48829999999999996,\n",
       " 0.8057,\n",
       " 0.5225,\n",
       " 0.2015,\n",
       " 0.26570000000000005,\n",
       " 0.3285,\n",
       " 0.1664,\n",
       " 0.39580000000000004,\n",
       " 0.2891,\n",
       " 0.21899999999999997,\n",
       " 0.4366,\n",
       " 0.38370000000000004,\n",
       " 0.24170000000000003,\n",
       " 0.35609999999999997,\n",
       " 0.2895,\n",
       " 0.7389,\n",
       " 0.3721,\n",
       " 0.2158,\n",
       " 0.3076,\n",
       " 0.3198,\n",
       " 0.27149999999999996,\n",
       " 0.1925,\n",
       " 0.28369999999999995,\n",
       " 0.27449999999999997,\n",
       " 0.8169,\n",
       " 0.25539999999999996,\n",
       " 0.4181,\n",
       " 0.8071,\n",
       " 0.349,\n",
       " 0.5042,\n",
       " 0.3348,\n",
       " 0.5297,\n",
       " 0.15739999999999998,\n",
       " 0.8499,\n",
       " 0.14790000000000003,\n",
       " 0.20140000000000002,\n",
       " 0.18910000000000005,\n",
       " 0.3268,\n",
       " 0.6661,\n",
       " 0.5112,\n",
       " 0.3355,\n",
       " 0.14749999999999996,\n",
       " 0.32230000000000003,\n",
       " 0.25739999999999996,\n",
       " 0.2562,\n",
       " 0.30889999999999995,\n",
       " 0.24150000000000005,\n",
       " 0.6855,\n",
       " 0.39949999999999997,\n",
       " 0.25849999999999995,\n",
       " 0.16849999999999998,\n",
       " 0.17820000000000003,\n",
       " 0.46030000000000004,\n",
       " 0.7151,\n",
       " 0.30589999999999995,\n",
       " 0.28080000000000005,\n",
       " 0.235,\n",
       " 0.30679999999999996,\n",
       " 0.7759,\n",
       " 0.8322,\n",
       " 0.6711,\n",
       " 0.8241,\n",
       " 0.23329999999999995,\n",
       " 0.2056,\n",
       " 0.3389,\n",
       " 0.1855,\n",
       " 0.18020000000000003,\n",
       " 0.24460000000000004,\n",
       " 0.3226,\n",
       " 0.43720000000000003,\n",
       " 0.31389999999999996,\n",
       " 0.8462,\n",
       " 0.43610000000000004,\n",
       " 0.1664,\n",
       " 0.5248,\n",
       " 0.22699999999999998,\n",
       " 0.4104,\n",
       " 0.4355,\n",
       " 0.41400000000000003,\n",
       " 0.3548,\n",
       " 0.2036,\n",
       " 0.26870000000000005,\n",
       " 0.25880000000000003,\n",
       " 0.16390000000000005,\n",
       " 0.1876,\n",
       " 0.3839,\n",
       " 0.26259999999999994,\n",
       " 0.21009999999999995,\n",
       " 0.5017,\n",
       " 0.2279,\n",
       " 0.34040000000000004,\n",
       " 0.844,\n",
       " 0.16759999999999997,\n",
       " 0.11829999999999996,\n",
       " 0.33640000000000003,\n",
       " 0.21089999999999998,\n",
       " 0.21589999999999998,\n",
       " 0.4508,\n",
       " 0.39659999999999995,\n",
       " 0.15139999999999998,\n",
       " 0.27080000000000004,\n",
       " 0.28,\n",
       " 0.4393,\n",
       " 0.5014,\n",
       " 0.3832,\n",
       " 0.14159999999999995,\n",
       " 0.3305,\n",
       " 0.15810000000000002,\n",
       " 0.3143,\n",
       " 0.7815,\n",
       " 0.2713,\n",
       " 0.12009999999999998,\n",
       " 0.27849999999999997,\n",
       " 0.16310000000000002,\n",
       " 0.5014,\n",
       " 0.19320000000000004,\n",
       " 0.5919,\n",
       " 0.8024,\n",
       " 0.26680000000000004,\n",
       " 0.1301,\n",
       " 0.8446,\n",
       " 0.4859,\n",
       " 0.1642,\n",
       " 0.8226,\n",
       " 0.36439999999999995,\n",
       " 0.21589999999999998,\n",
       " 0.4245,\n",
       " 0.8008,\n",
       " 0.36260000000000003,\n",
       " 0.26060000000000005,\n",
       " 0.2619,\n",
       " 0.2157,\n",
       " 0.4162,\n",
       " 0.3166,\n",
       " 0.8172,\n",
       " 0.23009999999999997,\n",
       " 0.18879999999999997,\n",
       " 0.6767,\n",
       " 0.517,\n",
       " 0.2459,\n",
       " 0.7561,\n",
       " 0.19799999999999995,\n",
       " 0.25670000000000004,\n",
       " 0.254,\n",
       " 0.1906,\n",
       " 0.6442,\n",
       " 0.22809999999999997,\n",
       " 0.26380000000000003,\n",
       " 0.34309999999999996,\n",
       " 0.14649999999999996,\n",
       " 0.2913,\n",
       " 0.21709999999999996,\n",
       " 0.8257,\n",
       " 0.8218,\n",
       " 0.2823,\n",
       " 0.24109999999999998,\n",
       " 0.23519999999999996,\n",
       " 0.7255,\n",
       " 0.43010000000000004,\n",
       " 0.2681,\n",
       " 0.28659999999999997,\n",
       " 0.42569999999999997,\n",
       " 0.1632,\n",
       " 0.16700000000000004,\n",
       " 0.20220000000000005,\n",
       " 0.1906,\n",
       " 0.18059999999999998,\n",
       " 0.18830000000000002,\n",
       " 0.41279999999999994,\n",
       " 0.4083,\n",
       " 0.41900000000000004,\n",
       " 0.8355,\n",
       " 0.36760000000000004,\n",
       " 0.6315,\n",
       " 0.17469999999999997,\n",
       " 0.25539999999999996,\n",
       " 0.48619999999999997,\n",
       " 0.2793,\n",
       " 0.21009999999999995,\n",
       " 0.2723,\n",
       " 0.20699999999999996,\n",
       " 0.8551,\n",
       " 0.43820000000000003,\n",
       " 0.23099999999999998,\n",
       " 0.8146,\n",
       " 0.2619,\n",
       " 0.41259999999999997,\n",
       " 0.30200000000000005,\n",
       " 0.32299999999999995,\n",
       " 0.24,\n",
       " 0.32120000000000004,\n",
       " 0.15410000000000001,\n",
       " 0.259,\n",
       " 0.19010000000000005,\n",
       " 0.40469999999999995,\n",
       " 0.14149999999999996,\n",
       " 0.37639999999999996,\n",
       " 0.34319999999999995,\n",
       " 0.30710000000000004,\n",
       " 0.5176,\n",
       " 0.22950000000000004,\n",
       " 0.4979,\n",
       " 0.7178,\n",
       " 0.8287,\n",
       " 0.2378,\n",
       " 0.361,\n",
       " 0.2136,\n",
       " 0.4284,\n",
       " 0.43610000000000004,\n",
       " 0.6189,\n",
       " 0.25239999999999996,\n",
       " 0.5217,\n",
       " 0.4323,\n",
       " 0.2692,\n",
       " 0.23350000000000004,\n",
       " 0.34940000000000004,\n",
       " 0.4464,\n",
       " 0.29069999999999996,\n",
       " 0.20120000000000005,\n",
       " 0.11129999999999995,\n",
       " 0.6346,\n",
       " 0.4454,\n",
       " 0.8484,\n",
       " 0.3901,\n",
       " 0.23370000000000002,\n",
       " 0.124,\n",
       " 0.8279,\n",
       " 0.6925,\n",
       " 0.1795,\n",
       " 0.5071,\n",
       " 0.634,\n",
       " 0.20909999999999995,\n",
       " 0.4971,\n",
       " 0.5478,\n",
       " 0.16920000000000002,\n",
       " 0.18910000000000005,\n",
       " 0.31279999999999997,\n",
       " 0.366,\n",
       " 0.45620000000000005,\n",
       " 0.7924,\n",
       " 0.3952,\n",
       " 0.7242,\n",
       " 0.358,\n",
       " 0.8039,\n",
       " 0.12860000000000005,\n",
       " 0.20299999999999996,\n",
       " 0.8245,\n",
       " 0.2138,\n",
       " 0.4487,\n",
       " 0.1733,\n",
       " 0.1199,\n",
       " 0.1734,\n",
       " 0.15000000000000002,\n",
       " 0.7973,\n",
       " 0.17059999999999997,\n",
       " 0.4282,\n",
       " 0.3547,\n",
       " 0.26770000000000005,\n",
       " 0.6909,\n",
       " 0.26180000000000003,\n",
       " 0.1945,\n",
       " 0.4569,\n",
       " 0.4881,\n",
       " 0.4768,\n",
       " 0.1604,\n",
       " 0.4226,\n",
       " 0.3813,\n",
       " 0.5323,\n",
       " 0.20730000000000004,\n",
       " 0.3348,\n",
       " 0.14639999999999997,\n",
       " 0.88,\n",
       " 0.23299999999999998,\n",
       " 0.24519999999999997,\n",
       " 0.22150000000000003,\n",
       " 0.5134,\n",
       " 0.7593,\n",
       " 0.2552,\n",
       " 0.4154,\n",
       " 0.7627,\n",
       " 0.7908,\n",
       " 0.30310000000000004,\n",
       " 0.25760000000000005,\n",
       " 0.5337,\n",
       " 0.8257,\n",
       " 0.22529999999999994,\n",
       " 0.23750000000000004,\n",
       " 0.7897,\n",
       " 0.32330000000000003,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "\n",
    "for i in range(len(predictions['Score'])):\n",
    "    if predictions['Label'][i] == 1:\n",
    "        x.append(predictions['Score'][i])\n",
    "    else:\n",
    "        x.append(1-predictions['Score'][i])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92d6cd05-0bdc-4028-993c-8c09fd1dd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submssion = pd.read_csv(PATH+'sample_submission.csv')\n",
    "sample_submssion['problem'] = x\n",
    "sample_submssion.to_csv(PATH+\"AutoML.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaed15-b60d-4977-a030-0fc0d3e932e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
